{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import torch\n",
    "from torch.jit import script, trace\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import codecs\n",
    "from io import open\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_name = \"cornell movie-dialogs corpus\"\n",
    "# corpus = os.path.join(\"data\", corpus_name)\n",
    "\n",
    "def printLines(file, n=10):\n",
    "    with open(file, 'rb') as datafile:\n",
    "        lines = datafile.readlines()\n",
    "    for line in lines[:n]:\n",
    "        print(line)\n",
    "\n",
    "# printLines(os.path.join(corpus, \"movie_lines.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits each line of the file into a dictionary of fields\n",
    "def loadLines(fileName, fields):\n",
    "    lines = {}\n",
    "    with open(fileName, 'r', encoding='iso-8859-1') as f:\n",
    "        for line in f:\n",
    "            values = line.split(\" +++$+++ \")\n",
    "            # Extract fields\n",
    "            lineObj = {}\n",
    "            for i, field in enumerate(fields):\n",
    "                lineObj[field] = values[i]\n",
    "            lines[lineObj['lineID']] = lineObj\n",
    "    return lines\n",
    "\n",
    "\n",
    "# Groups fields of lines from `loadLines` into conversations based on *movie_conversations.txt*\n",
    "def loadConversations(fileName, lines, fields):\n",
    "    conversations = []\n",
    "    with open(fileName, 'r', encoding='iso-8859-1') as f:\n",
    "        for line in f:\n",
    "            values = line.split(\" +++$+++ \")\n",
    "            # Extract fields\n",
    "            convObj = {}\n",
    "            for i, field in enumerate(fields):\n",
    "                convObj[field] = values[i]\n",
    "            # Convert string to list (convObj[\"utteranceIDs\"] == \"['L598485', 'L598486', ...]\")\n",
    "            lineIds = eval(convObj[\"utteranceIDs\"])\n",
    "            # Reassemble lines\n",
    "            convObj[\"lines\"] = []\n",
    "            for lineId in lineIds:\n",
    "                convObj[\"lines\"].append(lines[lineId])\n",
    "            conversations.append(convObj)\n",
    "    return conversations\n",
    "\n",
    "\n",
    "# Extracts pairs of sentences from conversations\n",
    "def extractSentencePairs(conversations):\n",
    "    qa_pairs = []\n",
    "    for conversation in conversations:\n",
    "        # Iterate over all the lines of the conversation\n",
    "        for i in range(len(conversation[\"lines\"]) - 1):  # We ignore the last line (no answer for it)\n",
    "            inputLine = conversation[\"lines\"][i][\"text\"].strip()\n",
    "            targetLine = conversation[\"lines\"][i+1][\"text\"].strip()\n",
    "            # Filter wrong samples (if one of the lists is empty)\n",
    "            if inputLine and targetLine:\n",
    "                qa_pairs.append([inputLine, targetLine])\n",
    "    return qa_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we’ll call these functions and create the file. We’ll call it\n",
    "*formatted_movie_lines.txt*.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default word tokens\n",
    "PAD_token = 0  # Used for padding short sentences\n",
    "SOS_token = 1  # Start-of-sentence token\n",
    "EOS_token = 2  # End-of-sentence token\n",
    "\n",
    "class Voc:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.trimmed = False\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3  # Count SOS, EOS, PAD\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.num_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.num_words] = word\n",
    "            self.num_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "    # Remove words below a certain count threshold\n",
    "    def trim(self, min_count):\n",
    "        if self.trimmed:\n",
    "            return\n",
    "        self.trimmed = True\n",
    "\n",
    "        keep_words = []\n",
    "\n",
    "        for k, v in self.word2count.items():\n",
    "            if v >= min_count:\n",
    "                keep_words.append(k)\n",
    "\n",
    "        print('keep_words {} / {} = {:.4f}'.format(\n",
    "            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n",
    "        ))\n",
    "\n",
    "        # Reinitialize dictionaries\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3 # Count default tokens\n",
    "\n",
    "        for word in keep_words:\n",
    "            self.addWord(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start preparing training data ...\n",
      "Reading lines...\n",
      "Read 156 sentence pairs\n",
      "Trimmed to 156 sentence pairs\n",
      "Counting words...\n",
      "Counted words: 971\n",
      "\n",
      "pairs:\n",
      "['mix crush oreo cooki butter press firmli base inch cake pan put refriger chill firm make oreo hazlenut banana cheesecak', 'specfic space instruct detail']\n",
      "['take pork steak inch thick place one gallon zip loc bag add one cup appl cider bag let marin hour overnight make oven pork steak', 'specfic space instruct detail']\n",
      "['sift flour sugar cocoa larg bowl sift', 'use sifter sift ingredi bowl']\n",
      "['heat ghee fri rava temperatur best pan fri rava', 'temperatur want fri rava exampl medium high heat']\n",
      "['meantim add pasta water boil stir often keep stick togeth pasta cook accord tast drain coland return pot toss tbsp butter cup chop parsley serv chicken pasta green salad desir green salad', 'would green salad consist']\n",
      "['cook dice onion coconut oil transluc keep food stick', 'occasion stir onion prevent stick bottom pan']\n",
      "['mix togeth quich base ingredi set asid make quich fill', 'mix egg add bowl']\n",
      "['place strawberri teaspoon lemon juic cup sugar blender blend high well blend set asid strawberri bar cheesecak bar', 'pint strawberri add zest lemon']\n",
      "['bake minut canola oil substitut', 'coconut oil use instead canola oil']\n",
      "['jeera rice readi serv jeera rice serv idea', 'serv']\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = 10  # Maximum sentence length to consider\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "# Read query/response pairs and return a voc object\n",
    "def readVocs(datafile, corpus_name):\n",
    "    print(\"Reading lines...\")\n",
    "    # Read the file and split into lines\n",
    "    lines = open(datafile, encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split(',')] for l in lines[1:]]\n",
    "    voc = Voc(corpus_name)\n",
    "    return voc, pairs\n",
    "\n",
    "import ipdb\n",
    "# Returns True iff both sentences in a pair 'p' are under the MAX_LENGTH threshold\n",
    "def filterPair(p):\n",
    "    # Input sequences need to preserve the last word for EOS token\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "# Filter pairs using filterPair condition\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "# Using the functions defined above, return a populated voc object and pairs list\n",
    "def loadPrepareData(corpus_name, datafile, save_dir):\n",
    "    print(\"Start preparing training data ...\")\n",
    "    voc, pairs = readVocs(datafile, corpus_name)\n",
    "    print(\"Read {!s} sentence pairs\".format(len(pairs)))\n",
    "#     pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        voc.addSentence(pair[0])\n",
    "        voc.addSentence(pair[1])\n",
    "    print(\"Counted words:\", voc.num_words)\n",
    "    return voc, pairs\n",
    "\n",
    "corpus_name = 'sarch_query'\n",
    "datafile = 'data/Batch_3648643_batch_results_rob/train_step_query.csv'\n",
    "\n",
    "# Load/Assemble voc and pairs\n",
    "save_dir = os.path.join(\"data\", \"save\")\n",
    "voc, pairs = loadPrepareData(corpus_name, datafile, save_dir)\n",
    "# Print some pairs to validate\n",
    "print(\"\\npairs:\")\n",
    "for pair in pairs[:10]:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep_words 407 / 968 = 0.4205\n",
      "Trimmed from 156 pairs to 14, 0.0897 of total\n"
     ]
    }
   ],
   "source": [
    "MIN_COUNT = 3    # Minimum word count threshold for trimming\n",
    "\n",
    "def trimRareWords(voc, pairs, MIN_COUNT):\n",
    "    # Trim words used under the MIN_COUNT from the voc\n",
    "    voc.trim(MIN_COUNT)\n",
    "    # Filter out pairs with trimmed words\n",
    "    keep_pairs = []\n",
    "    for pair in pairs:\n",
    "        input_sentence = pair[0]\n",
    "        output_sentence = pair[1]\n",
    "        keep_input = True\n",
    "        keep_output = True\n",
    "        # Check input sentence\n",
    "        for word in input_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_input = False\n",
    "                break\n",
    "        # Check output sentence\n",
    "        for word in output_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_output = False\n",
    "                break\n",
    "\n",
    "        # Only keep pairs that do not contain trimmed word(s) in their input or output sentence\n",
    "        if keep_input and keep_output:\n",
    "            keep_pairs.append(pair)\n",
    "\n",
    "    print(\"Trimmed from {} pairs to {}, {:.4f} of total\".format(len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs)))\n",
    "    return keep_pairs\n",
    "\n",
    "\n",
    "# Trim voc and pairs\n",
    "pairs = trimRareWords(voc, pairs, MIN_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variable: tensor([[242,  30, 288, 205, 351],\n",
      "        [316,  76, 257,  46,  38],\n",
      "        [129, 127,  70,  93, 108],\n",
      "        [ 30, 142, 126,   3, 297],\n",
      "        [ 41, 127, 219, 107,   2],\n",
      "        [113,  76,  97,  63,   0],\n",
      "        [126,  30,  70,  45,   0],\n",
      "        [227,  16, 223,  93,   0],\n",
      "        [131, 275,  38,   2,   0],\n",
      "        [ 30, 276,   2,   0,   0],\n",
      "        [ 31,   2,   0,   0,   0],\n",
      "        [236,   0,   0,   0,   0],\n",
      "        [ 55,   0,   0,   0,   0],\n",
      "        [136,   0,   0,   0,   0],\n",
      "        [  2,   0,   0,   0,   0]])\n",
      "lengths: tensor([15, 11, 10,  9,  5])\n",
      "target_variable: tensor([[147, 264, 289, 147, 297],\n",
      "        [ 34, 131, 185,  94,   2],\n",
      "        [157, 110,  70,   2,   0],\n",
      "        [170,   2, 290,   0,   0],\n",
      "        [  2,   0,  97,   0,   0],\n",
      "        [  0,   0,   2,   0,   0]])\n",
      "mask: tensor([[1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 0, 0],\n",
      "        [1, 0, 1, 0, 0],\n",
      "        [0, 0, 1, 0, 0]], dtype=torch.uint8)\n",
      "max_target_len: 6\n"
     ]
    }
   ],
   "source": [
    "def indexesFromSentence(voc, sentence):\n",
    "    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n",
    "\n",
    "\n",
    "def zeroPadding(l, fillvalue=PAD_token):\n",
    "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n",
    "\n",
    "def binaryMatrix(l, value=PAD_token):\n",
    "    m = []\n",
    "    for i, seq in enumerate(l):\n",
    "        m.append([])\n",
    "        for token in seq:\n",
    "            if token == PAD_token:\n",
    "                m[i].append(0)\n",
    "            else:\n",
    "                m[i].append(1)\n",
    "    return m\n",
    "\n",
    "# Returns padded input sequence tensor and lengths\n",
    "def inputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, lengths\n",
    "\n",
    "# Returns padded target sequence tensor, padding mask, and max target length\n",
    "def outputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    mask = binaryMatrix(padList)\n",
    "    mask = torch.ByteTensor(mask)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, mask, max_target_len\n",
    "\n",
    "# Returns all items for a given batch of pairs\n",
    "def batch2TrainData(voc, pair_batch):\n",
    "    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n",
    "    input_batch, output_batch = [], []\n",
    "    for pair in pair_batch:\n",
    "        input_batch.append(pair[0])\n",
    "        output_batch.append(pair[1])\n",
    "    inp, lengths = inputVar(input_batch, voc)\n",
    "    output, mask, max_target_len = outputVar(output_batch, voc)\n",
    "    return inp, lengths, output, mask, max_target_len\n",
    "\n",
    "\n",
    "# Example for validation\n",
    "small_batch_size = 5\n",
    "batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
    "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
    "\n",
    "print(\"input_variable:\", input_variable)\n",
    "print(\"lengths:\", lengths)\n",
    "print(\"target_variable:\", target_variable)\n",
    "print(\"mask:\", mask)\n",
    "print(\"max_target_len:\", max_target_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = embedding\n",
    "\n",
    "        # Initialize GRU; the input_size and hidden_size params are both set to 'hidden_size'\n",
    "        #   because our input size is a word embedding with number of features == hidden_size\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,\n",
    "                          dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n",
    "\n",
    "    def forward(self, input_seq, input_lengths, hidden=None):\n",
    "        # Convert word indexes to embeddings\n",
    "        embedded = self.embedding(input_seq)\n",
    "        # Pack padded batch of sequences for RNN module\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "        # Forward pass through GRU\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        # Unpack padding\n",
    "        outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        # Sum bidirectional GRU outputs\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n",
    "        # Return output and final hidden state\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Luong attention layer\n",
    "class Attn(torch.nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        self.method = method\n",
    "        if self.method not in ['dot', 'general', 'concat']:\n",
    "            raise ValueError(self.method, \"is not an appropriate attention method.\")\n",
    "        self.hidden_size = hidden_size\n",
    "        if self.method == 'general':\n",
    "            self.attn = torch.nn.Linear(self.hidden_size, hidden_size)\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = torch.nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.v = torch.nn.Parameter(torch.FloatTensor(hidden_size))\n",
    "\n",
    "    def dot_score(self, hidden, encoder_output):\n",
    "        return torch.sum(hidden * encoder_output, dim=2)\n",
    "\n",
    "    def general_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(encoder_output)\n",
    "        return torch.sum(hidden * energy, dim=2)\n",
    "\n",
    "    def concat_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n",
    "        return torch.sum(self.v * energy, dim=2)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        # Calculate the attention weights (energies) based on the given method\n",
    "        if self.method == 'general':\n",
    "            attn_energies = self.general_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'concat':\n",
    "            attn_energies = self.concat_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'dot':\n",
    "            attn_energies = self.dot_score(hidden, encoder_outputs)\n",
    "\n",
    "        # Transpose max_length and batch_size dimensions\n",
    "        attn_energies = attn_energies.t()\n",
    "\n",
    "        # Return the softmax normalized probability scores (with added dimension)\n",
    "        return F.softmax(attn_energies, dim=1).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(LuongAttnDecoderRNN, self).__init__()\n",
    "\n",
    "        # Keep for reference\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Define layers\n",
    "        self.embedding = embedding\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        self.attn = Attn(attn_model, hidden_size)\n",
    "\n",
    "    def forward(self, input_step, last_hidden, encoder_outputs):\n",
    "        # Note: we run this one step (word) at a time\n",
    "        # Get embedding of current input word\n",
    "        embedded = self.embedding(input_step)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        # Forward through unidirectional GRU\n",
    "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
    "        # Calculate attention weights from the current GRU output\n",
    "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
    "        # Multiply attention weights to encoder outputs to get new \"weighted sum\" context vector\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
    "        # Concatenate weighted context vector and GRU output using Luong eq. 5\n",
    "        rnn_output = rnn_output.squeeze(0)\n",
    "        context = context.squeeze(1)\n",
    "        concat_input = torch.cat((rnn_output, context), 1)\n",
    "        concat_output = torch.tanh(self.concat(concat_input))\n",
    "        # Predict next word using Luong eq. 6\n",
    "        output = self.out(concat_output)\n",
    "        output = F.softmax(output, dim=1)\n",
    "        # Return output and final hidden state\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskNLLLoss(inp, target, mask):\n",
    "    nTotal = mask.sum()\n",
    "    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n",
    "    loss = crossEntropy.masked_select(mask).mean()\n",
    "    loss = loss.to(device)\n",
    "    return loss, nTotal.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding,\n",
    "          encoder_optimizer, decoder_optimizer, batch_size, clip, max_length=MAX_LENGTH):\n",
    "\n",
    "    # Zero gradients\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    # Set device options\n",
    "    input_variable = input_variable.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    target_variable = target_variable.to(device)\n",
    "    mask = mask.to(device)\n",
    "\n",
    "    # Initialize variables\n",
    "    loss = 0\n",
    "    print_losses = []\n",
    "    n_totals = 0\n",
    "\n",
    "    # Forward pass through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
    "\n",
    "    # Create initial decoder input (start with SOS tokens for each sentence)\n",
    "    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n",
    "    decoder_input = decoder_input.to(device)\n",
    "\n",
    "    # Set initial decoder hidden state to the encoder's final hidden state\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "\n",
    "    # Determine if we are using teacher forcing this iteration\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    # Forward batch of sequences through decoder one time step at a time\n",
    "    if use_teacher_forcing:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            # Teacher forcing: next input is current target\n",
    "            decoder_input = target_variable[t].view(1, -1)\n",
    "            # Calculate and accumulate loss\n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals += nTotal\n",
    "    else:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            # No teacher forcing: next input is decoder's own current output\n",
    "            _, topi = decoder_output.topk(1)\n",
    "            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
    "            decoder_input = decoder_input.to(device)\n",
    "            # Calculate and accumulate loss\n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals += nTotal\n",
    "\n",
    "    # Perform backpropatation\n",
    "    loss.backward()\n",
    "\n",
    "    # Clip gradients: gradients are modified in place\n",
    "    _ = torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "    _ = torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "\n",
    "    # Adjust model weights\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return sum(print_losses) / n_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, corpus_name, loadFilename):\n",
    "\n",
    "    # Load batches for each iteration\n",
    "    training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n",
    "                      for _ in range(n_iteration)]\n",
    "\n",
    "    # Initializations\n",
    "    print('Initializing ...')\n",
    "    start_iteration = 1\n",
    "    print_loss = 0\n",
    "    if loadFilename:\n",
    "        start_iteration = checkpoint['iteration'] + 1\n",
    "\n",
    "    # Training loop\n",
    "    print(\"Training...\")\n",
    "    for iteration in range(start_iteration, n_iteration + 1):\n",
    "        training_batch = training_batches[iteration - 1]\n",
    "        # Extract fields from batch\n",
    "        input_variable, lengths, target_variable, mask, max_target_len = training_batch\n",
    "\n",
    "        # Run a training iteration with batch\n",
    "        loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n",
    "                     decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip)\n",
    "        print_loss += loss\n",
    "\n",
    "        # Print progress\n",
    "        if iteration % print_every == 0:\n",
    "            print_loss_avg = print_loss / print_every\n",
    "            print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n",
    "            print_loss = 0\n",
    "\n",
    "        # Save checkpoint\n",
    "        if (iteration % save_every == 0):\n",
    "            directory = os.path.join(save_dir, model_name, corpus_name, '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size))\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            torch.save({\n",
    "                'iteration': iteration,\n",
    "                'en': encoder.state_dict(),\n",
    "                'de': decoder.state_dict(),\n",
    "                'en_opt': encoder_optimizer.state_dict(),\n",
    "                'de_opt': decoder_optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                'voc_dict': voc.__dict__,\n",
    "                'embedding': embedding.state_dict()\n",
    "            }, os.path.join(directory, '{}_{}.tar'.format(iteration, 'checkpoint')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedySearchDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(GreedySearchDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, input_seq, input_length, max_length):\n",
    "        # Forward input through encoder model\n",
    "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
    "        # Prepare encoder's final hidden layer to be first hidden input to the decoder\n",
    "        decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "        # Initialize decoder input with SOS_token\n",
    "        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token\n",
    "        # Initialize tensors to append decoded words to\n",
    "        all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n",
    "        all_scores = torch.zeros([0], device=device)\n",
    "        # Iteratively decode one word token at a time\n",
    "        for _ in range(max_length):\n",
    "            # Forward pass through decoder\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            # Obtain most likely word token and its softmax score\n",
    "            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
    "            # Record token and score\n",
    "            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
    "            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
    "            # Prepare current token to be next decoder input (add a dimension)\n",
    "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
    "        # Return collections of word tokens and scores\n",
    "        return all_tokens, all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, searcher, voc, sentence, max_length=MAX_LENGTH):\n",
    "    ### Format input sentence as a batch\n",
    "    # words -> indexes\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence)]\n",
    "    # Create lengths tensor\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    # Transpose dimensions of batch to match models' expectations\n",
    "    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n",
    "    # Use appropriate device\n",
    "    input_batch = input_batch.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    # Decode sentence with searcher\n",
    "    tokens, scores = searcher(input_batch, lengths, max_length)\n",
    "    # indexes -> words\n",
    "    decoded_words = [voc.index2word[token.item()] for token in tokens]\n",
    "    return decoded_words\n",
    "\n",
    "\n",
    "def evaluateInput(encoder, decoder, searcher, voc):\n",
    "    input_sentence = ''\n",
    "    while(1):\n",
    "        try:\n",
    "            # Get input sentence\n",
    "            input_sentence = input('> ')\n",
    "            # Check if it is quit case\n",
    "            if input_sentence == 'q' or input_sentence == 'quit': break\n",
    "            # Normalize sentence\n",
    "            input_sentence = normalizeString(input_sentence)\n",
    "            # Evaluate sentence\n",
    "            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
    "            # Format and print response sentence\n",
    "            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
    "            print('Bot:', ' '.join(output_words))\n",
    "\n",
    "        except KeyError:\n",
    "            print(\"Error: Encountered unknown word.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start preparing training data ...\n",
      "Reading lines...\n",
      "Read 226 sentence pairs\n",
      "Trimmed to 226 sentence pairs\n",
      "Counting words...\n",
      "Counted words: 1159\n",
      "Start preparing training data ...\n",
      "Reading lines...\n",
      "Read 156 sentence pairs\n",
      "Trimmed to 156 sentence pairs\n",
      "Counting words...\n",
      "Counted words: 971\n",
      "Building encoder and decoder ...\n",
      "Models built and ready to go!\n"
     ]
    }
   ],
   "source": [
    "# Configure models\n",
    "model_name = 'cb_model'\n",
    "attn_model = 'dot'\n",
    "#attn_model = 'general'\n",
    "#attn_model = 'concat'\n",
    "hidden_size = 500\n",
    "encoder_n_layers = 2\n",
    "decoder_n_layers = 2\n",
    "dropout = 0.1\n",
    "batch_size = 64\n",
    "\n",
    "corpus_name = 'search_query'\n",
    "alldatafile = 'data/Batch_3648643_batch_results_rob/all.csv'\n",
    "traindatafile = 'data/Batch_3648643_batch_results_rob/train_step_query.csv'\n",
    "\n",
    "voc, _ = loadPrepareData(corpus_name, alldatafile, save_dir)\n",
    "_, pairs = loadPrepareData(corpus_name, traindatafile, save_dir)\n",
    "\n",
    "voc.addWord('')\n",
    "\n",
    "\n",
    "\n",
    "# Set checkpoint to load from; set to None if starting from scratch\n",
    "loadFilename = None\n",
    "checkpoint_iter = 4000\n",
    "#loadFilename = os.path.join(save_dir, model_name, corpus_name,\n",
    "#                            '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size),\n",
    "#                            '{}_checkpoint.tar'.format(checkpoint_iter))\n",
    "\n",
    "\n",
    "# Load model if a loadFilename is provided\n",
    "if loadFilename:\n",
    "    # If loading on same machine the model was trained on\n",
    "    checkpoint = torch.load(loadFilename)\n",
    "    # If loading a model trained on GPU to CPU\n",
    "    #checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))\n",
    "    encoder_sd = checkpoint['en']\n",
    "    decoder_sd = checkpoint['de']\n",
    "    encoder_optimizer_sd = checkpoint['en_opt']\n",
    "    decoder_optimizer_sd = checkpoint['de_opt']\n",
    "    embedding_sd = checkpoint['embedding']\n",
    "    voc.__dict__ = checkpoint['voc_dict']\n",
    "\n",
    "\n",
    "print('Building encoder and decoder ...')\n",
    "# Initialize word embeddings\n",
    "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
    "if loadFilename:\n",
    "    embedding.load_state_dict(embedding_sd)\n",
    "# Initialize encoder & decoder models\n",
    "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
    "if loadFilename:\n",
    "    encoder.load_state_dict(encoder_sd)\n",
    "    decoder.load_state_dict(decoder_sd)\n",
    "# Use appropriate device\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)\n",
    "print('Models built and ready to go!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateFile(encoder, decoder, searcher, voc, filename, targetname):\n",
    "    text = list(csv.reader(open(filename, 'rt')))\n",
    "    target = list(csv.reader(open(targetname, 'rt')))\n",
    "    responses = []\n",
    "#     input_sentence = ''\n",
    "    for input_sentence in text:\n",
    "        try:\n",
    "            # Get input sentence\n",
    "#             input_sentence = input('> ')\n",
    "            # Check if it is quit case\n",
    "#             if input_sentence == 'q' or input_sentence == 'quit': break\n",
    "            # Normalize sentence\n",
    "            input_sentence = normalizeString(input_sentence[0])\n",
    "            # Evaluate sentence\n",
    "            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
    "            # Format and print response sentence\n",
    "            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
    "            responses.append(' '.join(output_words))\n",
    "#             print('Bot:', ' '.join(output_words))\n",
    "        except KeyError:\n",
    "            responses.append(' ')\n",
    "#             print(\"Error: Encountered unknown word.\")\n",
    "    return text, target, responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building optimizers ...\n",
      "Starting Training!\n",
      "Initializing ...\n",
      "Training...\n",
      "Iteration: 1; Percent complete: 0.0%; Average loss: 7.0627\n",
      "Iteration: 2; Percent complete: 0.1%; Average loss: 7.0437\n",
      "Iteration: 3; Percent complete: 0.1%; Average loss: 7.0024\n",
      "Iteration: 4; Percent complete: 0.1%; Average loss: 6.9281\n",
      "Iteration: 5; Percent complete: 0.1%; Average loss: 6.9019\n",
      "Iteration: 6; Percent complete: 0.1%; Average loss: 6.8447\n",
      "Iteration: 7; Percent complete: 0.2%; Average loss: 6.6096\n",
      "Iteration: 8; Percent complete: 0.2%; Average loss: 6.4029\n",
      "Iteration: 9; Percent complete: 0.2%; Average loss: 6.5052\n",
      "Iteration: 10; Percent complete: 0.2%; Average loss: 6.1473\n",
      "Iteration: 11; Percent complete: 0.3%; Average loss: 6.0708\n",
      "Iteration: 12; Percent complete: 0.3%; Average loss: 6.0141\n",
      "Iteration: 13; Percent complete: 0.3%; Average loss: 6.0534\n",
      "Iteration: 14; Percent complete: 0.4%; Average loss: 6.0314\n",
      "Iteration: 15; Percent complete: 0.4%; Average loss: 6.1948\n",
      "Iteration: 16; Percent complete: 0.4%; Average loss: 5.9272\n",
      "Iteration: 17; Percent complete: 0.4%; Average loss: 5.7547\n",
      "Iteration: 18; Percent complete: 0.4%; Average loss: 5.7141\n",
      "Iteration: 19; Percent complete: 0.5%; Average loss: 5.7001\n",
      "Iteration: 20; Percent complete: 0.5%; Average loss: 5.6251\n",
      "Iteration: 21; Percent complete: 0.5%; Average loss: 5.4642\n",
      "Iteration: 22; Percent complete: 0.5%; Average loss: 5.4264\n",
      "Iteration: 23; Percent complete: 0.6%; Average loss: 5.7042\n",
      "Iteration: 24; Percent complete: 0.6%; Average loss: 5.4915\n",
      "Iteration: 25; Percent complete: 0.6%; Average loss: 5.6159\n",
      "Iteration: 26; Percent complete: 0.7%; Average loss: 5.4766\n",
      "Iteration: 27; Percent complete: 0.7%; Average loss: 5.4189\n",
      "Iteration: 28; Percent complete: 0.7%; Average loss: 5.4635\n",
      "Iteration: 29; Percent complete: 0.7%; Average loss: 5.3306\n",
      "Iteration: 30; Percent complete: 0.8%; Average loss: 5.1926\n",
      "Iteration: 31; Percent complete: 0.8%; Average loss: 5.5358\n",
      "Iteration: 32; Percent complete: 0.8%; Average loss: 5.4445\n",
      "Iteration: 33; Percent complete: 0.8%; Average loss: 5.2350\n",
      "Iteration: 34; Percent complete: 0.9%; Average loss: 5.2076\n",
      "Iteration: 35; Percent complete: 0.9%; Average loss: 5.0343\n",
      "Iteration: 36; Percent complete: 0.9%; Average loss: 5.2924\n",
      "Iteration: 37; Percent complete: 0.9%; Average loss: 5.0307\n",
      "Iteration: 38; Percent complete: 0.9%; Average loss: 4.8973\n",
      "Iteration: 39; Percent complete: 1.0%; Average loss: 5.2679\n",
      "Iteration: 40; Percent complete: 1.0%; Average loss: 5.2153\n",
      "Iteration: 41; Percent complete: 1.0%; Average loss: 5.2477\n",
      "Iteration: 42; Percent complete: 1.1%; Average loss: 5.0029\n",
      "Iteration: 43; Percent complete: 1.1%; Average loss: 5.0500\n",
      "Iteration: 44; Percent complete: 1.1%; Average loss: 4.9416\n",
      "Iteration: 45; Percent complete: 1.1%; Average loss: 4.8157\n",
      "Iteration: 46; Percent complete: 1.1%; Average loss: 4.9529\n",
      "Iteration: 47; Percent complete: 1.2%; Average loss: 4.8213\n",
      "Iteration: 48; Percent complete: 1.2%; Average loss: 4.8138\n",
      "Iteration: 49; Percent complete: 1.2%; Average loss: 4.7717\n",
      "Iteration: 50; Percent complete: 1.2%; Average loss: 4.7581\n",
      "Iteration: 51; Percent complete: 1.3%; Average loss: 4.5726\n",
      "Iteration: 52; Percent complete: 1.3%; Average loss: 4.7246\n",
      "Iteration: 53; Percent complete: 1.3%; Average loss: 4.3745\n",
      "Iteration: 54; Percent complete: 1.4%; Average loss: 4.2518\n",
      "Iteration: 55; Percent complete: 1.4%; Average loss: 4.4183\n",
      "Iteration: 56; Percent complete: 1.4%; Average loss: 4.4165\n",
      "Iteration: 57; Percent complete: 1.4%; Average loss: 4.1711\n",
      "Iteration: 58; Percent complete: 1.5%; Average loss: 4.5637\n",
      "Iteration: 59; Percent complete: 1.5%; Average loss: 4.2706\n",
      "Iteration: 60; Percent complete: 1.5%; Average loss: 4.5143\n",
      "Iteration: 61; Percent complete: 1.5%; Average loss: 4.0732\n",
      "Iteration: 62; Percent complete: 1.6%; Average loss: 4.3621\n",
      "Iteration: 63; Percent complete: 1.6%; Average loss: 4.3422\n",
      "Iteration: 64; Percent complete: 1.6%; Average loss: 4.3776\n",
      "Iteration: 65; Percent complete: 1.6%; Average loss: 3.8982\n",
      "Iteration: 66; Percent complete: 1.7%; Average loss: 4.0126\n",
      "Iteration: 67; Percent complete: 1.7%; Average loss: 3.7522\n",
      "Iteration: 68; Percent complete: 1.7%; Average loss: 3.9556\n",
      "Iteration: 69; Percent complete: 1.7%; Average loss: 3.9599\n",
      "Iteration: 70; Percent complete: 1.8%; Average loss: 4.1257\n",
      "Iteration: 71; Percent complete: 1.8%; Average loss: 4.1332\n",
      "Iteration: 72; Percent complete: 1.8%; Average loss: 3.7467\n",
      "Iteration: 73; Percent complete: 1.8%; Average loss: 3.8801\n",
      "Iteration: 74; Percent complete: 1.8%; Average loss: 4.2074\n",
      "Iteration: 75; Percent complete: 1.9%; Average loss: 3.6759\n",
      "Iteration: 76; Percent complete: 1.9%; Average loss: 3.5057\n",
      "Iteration: 77; Percent complete: 1.9%; Average loss: 3.6446\n",
      "Iteration: 78; Percent complete: 1.9%; Average loss: 3.6807\n",
      "Iteration: 79; Percent complete: 2.0%; Average loss: 3.3116\n",
      "Iteration: 80; Percent complete: 2.0%; Average loss: 3.4238\n",
      "Iteration: 81; Percent complete: 2.0%; Average loss: 3.4229\n",
      "Iteration: 82; Percent complete: 2.1%; Average loss: 3.5183\n",
      "Iteration: 83; Percent complete: 2.1%; Average loss: 3.4991\n",
      "Iteration: 84; Percent complete: 2.1%; Average loss: 3.2205\n",
      "Iteration: 85; Percent complete: 2.1%; Average loss: 3.3580\n",
      "Iteration: 86; Percent complete: 2.1%; Average loss: 3.1364\n",
      "Iteration: 87; Percent complete: 2.2%; Average loss: 3.1121\n",
      "Iteration: 88; Percent complete: 2.2%; Average loss: 3.2033\n",
      "Iteration: 89; Percent complete: 2.2%; Average loss: 3.3556\n",
      "Iteration: 90; Percent complete: 2.2%; Average loss: 3.0575\n",
      "Iteration: 91; Percent complete: 2.3%; Average loss: 2.9638\n",
      "Iteration: 92; Percent complete: 2.3%; Average loss: 2.7449\n",
      "Iteration: 93; Percent complete: 2.3%; Average loss: 2.8420\n",
      "Iteration: 94; Percent complete: 2.4%; Average loss: 2.8990\n",
      "Iteration: 95; Percent complete: 2.4%; Average loss: 2.8666\n",
      "Iteration: 96; Percent complete: 2.4%; Average loss: 2.8890\n",
      "Iteration: 97; Percent complete: 2.4%; Average loss: 2.9495\n",
      "Iteration: 98; Percent complete: 2.5%; Average loss: 2.9871\n",
      "Iteration: 99; Percent complete: 2.5%; Average loss: 2.6974\n",
      "Iteration: 100; Percent complete: 2.5%; Average loss: 3.0463\n",
      "Iteration: 101; Percent complete: 2.5%; Average loss: 2.8010\n",
      "Iteration: 102; Percent complete: 2.5%; Average loss: 2.4091\n",
      "Iteration: 103; Percent complete: 2.6%; Average loss: 2.7534\n",
      "Iteration: 104; Percent complete: 2.6%; Average loss: 2.4902\n",
      "Iteration: 105; Percent complete: 2.6%; Average loss: 2.5867\n",
      "Iteration: 106; Percent complete: 2.6%; Average loss: 2.4527\n",
      "Iteration: 107; Percent complete: 2.7%; Average loss: 2.4303\n",
      "Iteration: 108; Percent complete: 2.7%; Average loss: 2.1451\n",
      "Iteration: 109; Percent complete: 2.7%; Average loss: 2.3657\n",
      "Iteration: 110; Percent complete: 2.8%; Average loss: 2.3414\n",
      "Iteration: 111; Percent complete: 2.8%; Average loss: 2.4630\n",
      "Iteration: 112; Percent complete: 2.8%; Average loss: 2.5234\n",
      "Iteration: 113; Percent complete: 2.8%; Average loss: 2.4349\n",
      "Iteration: 114; Percent complete: 2.9%; Average loss: 2.4039\n",
      "Iteration: 115; Percent complete: 2.9%; Average loss: 2.4331\n",
      "Iteration: 116; Percent complete: 2.9%; Average loss: 1.9621\n",
      "Iteration: 117; Percent complete: 2.9%; Average loss: 2.0109\n",
      "Iteration: 118; Percent complete: 2.9%; Average loss: 2.0143\n",
      "Iteration: 119; Percent complete: 3.0%; Average loss: 2.3051\n",
      "Iteration: 120; Percent complete: 3.0%; Average loss: 1.9936\n",
      "Iteration: 121; Percent complete: 3.0%; Average loss: 2.0018\n",
      "Iteration: 122; Percent complete: 3.0%; Average loss: 1.9255\n",
      "Iteration: 123; Percent complete: 3.1%; Average loss: 2.1083\n",
      "Iteration: 124; Percent complete: 3.1%; Average loss: 1.9358\n",
      "Iteration: 125; Percent complete: 3.1%; Average loss: 1.8385\n",
      "Iteration: 126; Percent complete: 3.1%; Average loss: 1.9104\n",
      "Iteration: 127; Percent complete: 3.2%; Average loss: 1.9220\n",
      "Iteration: 128; Percent complete: 3.2%; Average loss: 1.8866\n",
      "Iteration: 129; Percent complete: 3.2%; Average loss: 1.8944\n",
      "Iteration: 130; Percent complete: 3.2%; Average loss: 1.7263\n",
      "Iteration: 131; Percent complete: 3.3%; Average loss: 1.8183\n",
      "Iteration: 132; Percent complete: 3.3%; Average loss: 1.6196\n",
      "Iteration: 133; Percent complete: 3.3%; Average loss: 1.8018\n",
      "Iteration: 134; Percent complete: 3.4%; Average loss: 1.7102\n",
      "Iteration: 135; Percent complete: 3.4%; Average loss: 1.9263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 136; Percent complete: 3.4%; Average loss: 1.6083\n",
      "Iteration: 137; Percent complete: 3.4%; Average loss: 1.4556\n",
      "Iteration: 138; Percent complete: 3.5%; Average loss: 1.4920\n",
      "Iteration: 139; Percent complete: 3.5%; Average loss: 1.6796\n",
      "Iteration: 140; Percent complete: 3.5%; Average loss: 1.4757\n",
      "Iteration: 141; Percent complete: 3.5%; Average loss: 1.4374\n",
      "Iteration: 142; Percent complete: 3.5%; Average loss: 1.5514\n",
      "Iteration: 143; Percent complete: 3.6%; Average loss: 1.3870\n",
      "Iteration: 144; Percent complete: 3.6%; Average loss: 1.3498\n",
      "Iteration: 145; Percent complete: 3.6%; Average loss: 1.3289\n",
      "Iteration: 146; Percent complete: 3.6%; Average loss: 1.3568\n",
      "Iteration: 147; Percent complete: 3.7%; Average loss: 1.1022\n",
      "Iteration: 148; Percent complete: 3.7%; Average loss: 1.3453\n",
      "Iteration: 149; Percent complete: 3.7%; Average loss: 1.4134\n",
      "Iteration: 150; Percent complete: 3.8%; Average loss: 1.2856\n",
      "Iteration: 151; Percent complete: 3.8%; Average loss: 1.1700\n",
      "Iteration: 152; Percent complete: 3.8%; Average loss: 1.2843\n",
      "Iteration: 153; Percent complete: 3.8%; Average loss: 1.1710\n",
      "Iteration: 154; Percent complete: 3.9%; Average loss: 1.1548\n",
      "Iteration: 155; Percent complete: 3.9%; Average loss: 1.1843\n",
      "Iteration: 156; Percent complete: 3.9%; Average loss: 1.1682\n",
      "Iteration: 157; Percent complete: 3.9%; Average loss: 1.1259\n",
      "Iteration: 158; Percent complete: 4.0%; Average loss: 1.1824\n",
      "Iteration: 159; Percent complete: 4.0%; Average loss: 1.1526\n",
      "Iteration: 160; Percent complete: 4.0%; Average loss: 1.0989\n",
      "Iteration: 161; Percent complete: 4.0%; Average loss: 1.0741\n",
      "Iteration: 162; Percent complete: 4.0%; Average loss: 1.0653\n",
      "Iteration: 163; Percent complete: 4.1%; Average loss: 1.1577\n",
      "Iteration: 164; Percent complete: 4.1%; Average loss: 1.0870\n",
      "Iteration: 165; Percent complete: 4.1%; Average loss: 0.9059\n",
      "Iteration: 166; Percent complete: 4.2%; Average loss: 0.9867\n",
      "Iteration: 167; Percent complete: 4.2%; Average loss: 0.7282\n",
      "Iteration: 168; Percent complete: 4.2%; Average loss: 0.9701\n",
      "Iteration: 169; Percent complete: 4.2%; Average loss: 0.9570\n",
      "Iteration: 170; Percent complete: 4.2%; Average loss: 0.8416\n",
      "Iteration: 171; Percent complete: 4.3%; Average loss: 0.8175\n",
      "Iteration: 172; Percent complete: 4.3%; Average loss: 0.7655\n",
      "Iteration: 173; Percent complete: 4.3%; Average loss: 0.8186\n",
      "Iteration: 174; Percent complete: 4.3%; Average loss: 0.7544\n",
      "Iteration: 175; Percent complete: 4.4%; Average loss: 0.8476\n",
      "Iteration: 176; Percent complete: 4.4%; Average loss: 0.7163\n",
      "Iteration: 177; Percent complete: 4.4%; Average loss: 0.7817\n",
      "Iteration: 178; Percent complete: 4.5%; Average loss: 0.6885\n",
      "Iteration: 179; Percent complete: 4.5%; Average loss: 0.7198\n",
      "Iteration: 180; Percent complete: 4.5%; Average loss: 0.7289\n",
      "Iteration: 181; Percent complete: 4.5%; Average loss: 0.6565\n",
      "Iteration: 182; Percent complete: 4.5%; Average loss: 0.7347\n",
      "Iteration: 183; Percent complete: 4.6%; Average loss: 0.6246\n",
      "Iteration: 184; Percent complete: 4.6%; Average loss: 0.6617\n",
      "Iteration: 185; Percent complete: 4.6%; Average loss: 0.6404\n",
      "Iteration: 186; Percent complete: 4.7%; Average loss: 0.6332\n",
      "Iteration: 187; Percent complete: 4.7%; Average loss: 0.5706\n",
      "Iteration: 188; Percent complete: 4.7%; Average loss: 0.5257\n",
      "Iteration: 189; Percent complete: 4.7%; Average loss: 0.5454\n",
      "Iteration: 190; Percent complete: 4.8%; Average loss: 0.5371\n",
      "Iteration: 191; Percent complete: 4.8%; Average loss: 0.6106\n",
      "Iteration: 192; Percent complete: 4.8%; Average loss: 0.5331\n",
      "Iteration: 193; Percent complete: 4.8%; Average loss: 0.6172\n",
      "Iteration: 194; Percent complete: 4.9%; Average loss: 0.5090\n",
      "Iteration: 195; Percent complete: 4.9%; Average loss: 0.5119\n",
      "Iteration: 196; Percent complete: 4.9%; Average loss: 0.4681\n",
      "Iteration: 197; Percent complete: 4.9%; Average loss: 0.4924\n",
      "Iteration: 198; Percent complete: 5.0%; Average loss: 0.4273\n",
      "Iteration: 199; Percent complete: 5.0%; Average loss: 0.4515\n",
      "Iteration: 200; Percent complete: 5.0%; Average loss: 0.5655\n",
      "Iteration: 201; Percent complete: 5.0%; Average loss: 0.4535\n",
      "Iteration: 202; Percent complete: 5.1%; Average loss: 0.5007\n",
      "Iteration: 203; Percent complete: 5.1%; Average loss: 0.4292\n",
      "Iteration: 204; Percent complete: 5.1%; Average loss: 0.4745\n",
      "Iteration: 205; Percent complete: 5.1%; Average loss: 0.4287\n",
      "Iteration: 206; Percent complete: 5.1%; Average loss: 0.5271\n",
      "Iteration: 207; Percent complete: 5.2%; Average loss: 0.4443\n",
      "Iteration: 208; Percent complete: 5.2%; Average loss: 0.4235\n",
      "Iteration: 209; Percent complete: 5.2%; Average loss: 0.4176\n",
      "Iteration: 210; Percent complete: 5.2%; Average loss: 0.4721\n",
      "Iteration: 211; Percent complete: 5.3%; Average loss: 0.3313\n",
      "Iteration: 212; Percent complete: 5.3%; Average loss: 0.3835\n",
      "Iteration: 213; Percent complete: 5.3%; Average loss: 0.3945\n",
      "Iteration: 214; Percent complete: 5.3%; Average loss: 0.3746\n",
      "Iteration: 215; Percent complete: 5.4%; Average loss: 0.3547\n",
      "Iteration: 216; Percent complete: 5.4%; Average loss: 0.3961\n",
      "Iteration: 217; Percent complete: 5.4%; Average loss: 0.3058\n",
      "Iteration: 218; Percent complete: 5.5%; Average loss: 0.3164\n",
      "Iteration: 219; Percent complete: 5.5%; Average loss: 0.3478\n",
      "Iteration: 220; Percent complete: 5.5%; Average loss: 0.3454\n",
      "Iteration: 221; Percent complete: 5.5%; Average loss: 0.3360\n",
      "Iteration: 222; Percent complete: 5.5%; Average loss: 0.2853\n",
      "Iteration: 223; Percent complete: 5.6%; Average loss: 0.2926\n",
      "Iteration: 224; Percent complete: 5.6%; Average loss: 0.3249\n",
      "Iteration: 225; Percent complete: 5.6%; Average loss: 0.3023\n",
      "Iteration: 226; Percent complete: 5.7%; Average loss: 0.2881\n",
      "Iteration: 227; Percent complete: 5.7%; Average loss: 0.2766\n",
      "Iteration: 228; Percent complete: 5.7%; Average loss: 0.2744\n",
      "Iteration: 229; Percent complete: 5.7%; Average loss: 0.3011\n",
      "Iteration: 230; Percent complete: 5.8%; Average loss: 0.2764\n",
      "Iteration: 231; Percent complete: 5.8%; Average loss: 0.2620\n",
      "Iteration: 232; Percent complete: 5.8%; Average loss: 0.2705\n",
      "Iteration: 233; Percent complete: 5.8%; Average loss: 0.2308\n",
      "Iteration: 234; Percent complete: 5.9%; Average loss: 0.2101\n",
      "Iteration: 235; Percent complete: 5.9%; Average loss: 0.2370\n",
      "Iteration: 236; Percent complete: 5.9%; Average loss: 0.2668\n",
      "Iteration: 237; Percent complete: 5.9%; Average loss: 0.2116\n",
      "Iteration: 238; Percent complete: 5.9%; Average loss: 0.2444\n",
      "Iteration: 239; Percent complete: 6.0%; Average loss: 0.2144\n",
      "Iteration: 240; Percent complete: 6.0%; Average loss: 0.1995\n",
      "Iteration: 241; Percent complete: 6.0%; Average loss: 0.2171\n",
      "Iteration: 242; Percent complete: 6.0%; Average loss: 0.2201\n",
      "Iteration: 243; Percent complete: 6.1%; Average loss: 0.2049\n",
      "Iteration: 244; Percent complete: 6.1%; Average loss: 0.2051\n",
      "Iteration: 245; Percent complete: 6.1%; Average loss: 0.1933\n",
      "Iteration: 246; Percent complete: 6.2%; Average loss: 0.1677\n",
      "Iteration: 247; Percent complete: 6.2%; Average loss: 0.2052\n",
      "Iteration: 248; Percent complete: 6.2%; Average loss: 0.1916\n",
      "Iteration: 249; Percent complete: 6.2%; Average loss: 0.1864\n",
      "Iteration: 250; Percent complete: 6.2%; Average loss: 0.1916\n",
      "Iteration: 251; Percent complete: 6.3%; Average loss: 0.1751\n",
      "Iteration: 252; Percent complete: 6.3%; Average loss: 0.1523\n",
      "Iteration: 253; Percent complete: 6.3%; Average loss: 0.2026\n",
      "Iteration: 254; Percent complete: 6.3%; Average loss: 0.1672\n",
      "Iteration: 255; Percent complete: 6.4%; Average loss: 0.1610\n",
      "Iteration: 256; Percent complete: 6.4%; Average loss: 0.1689\n",
      "Iteration: 257; Percent complete: 6.4%; Average loss: 0.1551\n",
      "Iteration: 258; Percent complete: 6.5%; Average loss: 0.1748\n",
      "Iteration: 259; Percent complete: 6.5%; Average loss: 0.1744\n",
      "Iteration: 260; Percent complete: 6.5%; Average loss: 0.1522\n",
      "Iteration: 261; Percent complete: 6.5%; Average loss: 0.1574\n",
      "Iteration: 262; Percent complete: 6.6%; Average loss: 0.1387\n",
      "Iteration: 263; Percent complete: 6.6%; Average loss: 0.1343\n",
      "Iteration: 264; Percent complete: 6.6%; Average loss: 0.1469\n",
      "Iteration: 265; Percent complete: 6.6%; Average loss: 0.1473\n",
      "Iteration: 266; Percent complete: 6.7%; Average loss: 0.1390\n",
      "Iteration: 267; Percent complete: 6.7%; Average loss: 0.1438\n",
      "Iteration: 268; Percent complete: 6.7%; Average loss: 0.1286\n",
      "Iteration: 269; Percent complete: 6.7%; Average loss: 0.1541\n",
      "Iteration: 270; Percent complete: 6.8%; Average loss: 0.1426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 271; Percent complete: 6.8%; Average loss: 0.1344\n",
      "Iteration: 272; Percent complete: 6.8%; Average loss: 0.1382\n",
      "Iteration: 273; Percent complete: 6.8%; Average loss: 0.1237\n",
      "Iteration: 274; Percent complete: 6.9%; Average loss: 0.1431\n",
      "Iteration: 275; Percent complete: 6.9%; Average loss: 0.1268\n",
      "Iteration: 276; Percent complete: 6.9%; Average loss: 0.1364\n",
      "Iteration: 277; Percent complete: 6.9%; Average loss: 0.1294\n",
      "Iteration: 278; Percent complete: 7.0%; Average loss: 0.1130\n",
      "Iteration: 279; Percent complete: 7.0%; Average loss: 0.1204\n",
      "Iteration: 280; Percent complete: 7.0%; Average loss: 0.1212\n",
      "Iteration: 281; Percent complete: 7.0%; Average loss: 0.0998\n",
      "Iteration: 282; Percent complete: 7.0%; Average loss: 0.1176\n",
      "Iteration: 283; Percent complete: 7.1%; Average loss: 0.1372\n",
      "Iteration: 284; Percent complete: 7.1%; Average loss: 0.1170\n",
      "Iteration: 285; Percent complete: 7.1%; Average loss: 0.1097\n",
      "Iteration: 286; Percent complete: 7.1%; Average loss: 0.1053\n",
      "Iteration: 287; Percent complete: 7.2%; Average loss: 0.1012\n",
      "Iteration: 288; Percent complete: 7.2%; Average loss: 0.1091\n",
      "Iteration: 289; Percent complete: 7.2%; Average loss: 0.1048\n",
      "Iteration: 290; Percent complete: 7.2%; Average loss: 0.1066\n",
      "Iteration: 291; Percent complete: 7.3%; Average loss: 0.1185\n",
      "Iteration: 292; Percent complete: 7.3%; Average loss: 0.1028\n",
      "Iteration: 293; Percent complete: 7.3%; Average loss: 0.1069\n",
      "Iteration: 294; Percent complete: 7.3%; Average loss: 0.1078\n",
      "Iteration: 295; Percent complete: 7.4%; Average loss: 0.0911\n",
      "Iteration: 296; Percent complete: 7.4%; Average loss: 0.1109\n",
      "Iteration: 297; Percent complete: 7.4%; Average loss: 0.1062\n",
      "Iteration: 298; Percent complete: 7.4%; Average loss: 0.1047\n",
      "Iteration: 299; Percent complete: 7.5%; Average loss: 0.0992\n",
      "Iteration: 300; Percent complete: 7.5%; Average loss: 0.1072\n",
      "Iteration: 301; Percent complete: 7.5%; Average loss: 0.0985\n",
      "Iteration: 302; Percent complete: 7.5%; Average loss: 0.0806\n",
      "Iteration: 303; Percent complete: 7.6%; Average loss: 0.0878\n",
      "Iteration: 304; Percent complete: 7.6%; Average loss: 0.0904\n",
      "Iteration: 305; Percent complete: 7.6%; Average loss: 0.0910\n",
      "Iteration: 306; Percent complete: 7.6%; Average loss: 0.0904\n",
      "Iteration: 307; Percent complete: 7.7%; Average loss: 0.0811\n",
      "Iteration: 308; Percent complete: 7.7%; Average loss: 0.0870\n",
      "Iteration: 309; Percent complete: 7.7%; Average loss: 0.0927\n",
      "Iteration: 310; Percent complete: 7.8%; Average loss: 0.0889\n",
      "Iteration: 311; Percent complete: 7.8%; Average loss: 0.0887\n",
      "Iteration: 312; Percent complete: 7.8%; Average loss: 0.0875\n",
      "Iteration: 313; Percent complete: 7.8%; Average loss: 0.0821\n",
      "Iteration: 314; Percent complete: 7.8%; Average loss: 0.0826\n",
      "Iteration: 315; Percent complete: 7.9%; Average loss: 0.0771\n",
      "Iteration: 316; Percent complete: 7.9%; Average loss: 0.0846\n",
      "Iteration: 317; Percent complete: 7.9%; Average loss: 0.0784\n",
      "Iteration: 318; Percent complete: 8.0%; Average loss: 0.0784\n",
      "Iteration: 319; Percent complete: 8.0%; Average loss: 0.0862\n",
      "Iteration: 320; Percent complete: 8.0%; Average loss: 0.0742\n",
      "Iteration: 321; Percent complete: 8.0%; Average loss: 0.0758\n",
      "Iteration: 322; Percent complete: 8.1%; Average loss: 0.0685\n",
      "Iteration: 323; Percent complete: 8.1%; Average loss: 0.0843\n",
      "Iteration: 324; Percent complete: 8.1%; Average loss: 0.0691\n",
      "Iteration: 325; Percent complete: 8.1%; Average loss: 0.0731\n",
      "Iteration: 326; Percent complete: 8.2%; Average loss: 0.0737\n",
      "Iteration: 327; Percent complete: 8.2%; Average loss: 0.0714\n",
      "Iteration: 328; Percent complete: 8.2%; Average loss: 0.0703\n",
      "Iteration: 329; Percent complete: 8.2%; Average loss: 0.0736\n",
      "Iteration: 330; Percent complete: 8.2%; Average loss: 0.0674\n",
      "Iteration: 331; Percent complete: 8.3%; Average loss: 0.0659\n",
      "Iteration: 332; Percent complete: 8.3%; Average loss: 0.0626\n",
      "Iteration: 333; Percent complete: 8.3%; Average loss: 0.0685\n",
      "Iteration: 334; Percent complete: 8.3%; Average loss: 0.0680\n",
      "Iteration: 335; Percent complete: 8.4%; Average loss: 0.0702\n",
      "Iteration: 336; Percent complete: 8.4%; Average loss: 0.0669\n",
      "Iteration: 337; Percent complete: 8.4%; Average loss: 0.0731\n",
      "Iteration: 338; Percent complete: 8.5%; Average loss: 0.0641\n",
      "Iteration: 339; Percent complete: 8.5%; Average loss: 0.0558\n",
      "Iteration: 340; Percent complete: 8.5%; Average loss: 0.0540\n",
      "Iteration: 341; Percent complete: 8.5%; Average loss: 0.0569\n",
      "Iteration: 342; Percent complete: 8.6%; Average loss: 0.0615\n",
      "Iteration: 343; Percent complete: 8.6%; Average loss: 0.0568\n",
      "Iteration: 344; Percent complete: 8.6%; Average loss: 0.0512\n",
      "Iteration: 345; Percent complete: 8.6%; Average loss: 0.0615\n",
      "Iteration: 346; Percent complete: 8.6%; Average loss: 0.0603\n",
      "Iteration: 347; Percent complete: 8.7%; Average loss: 0.0537\n",
      "Iteration: 348; Percent complete: 8.7%; Average loss: 0.0523\n",
      "Iteration: 349; Percent complete: 8.7%; Average loss: 0.0570\n",
      "Iteration: 350; Percent complete: 8.8%; Average loss: 0.0604\n",
      "Iteration: 351; Percent complete: 8.8%; Average loss: 0.0567\n",
      "Iteration: 352; Percent complete: 8.8%; Average loss: 0.0555\n",
      "Iteration: 353; Percent complete: 8.8%; Average loss: 0.0586\n",
      "Iteration: 354; Percent complete: 8.8%; Average loss: 0.0539\n",
      "Iteration: 355; Percent complete: 8.9%; Average loss: 0.0546\n",
      "Iteration: 356; Percent complete: 8.9%; Average loss: 0.0528\n",
      "Iteration: 357; Percent complete: 8.9%; Average loss: 0.0528\n",
      "Iteration: 358; Percent complete: 8.9%; Average loss: 0.0554\n",
      "Iteration: 359; Percent complete: 9.0%; Average loss: 0.0495\n",
      "Iteration: 360; Percent complete: 9.0%; Average loss: 0.0548\n",
      "Iteration: 361; Percent complete: 9.0%; Average loss: 0.0533\n",
      "Iteration: 362; Percent complete: 9.0%; Average loss: 0.0518\n",
      "Iteration: 363; Percent complete: 9.1%; Average loss: 0.0522\n",
      "Iteration: 364; Percent complete: 9.1%; Average loss: 0.0439\n",
      "Iteration: 365; Percent complete: 9.1%; Average loss: 0.0472\n",
      "Iteration: 366; Percent complete: 9.2%; Average loss: 0.0455\n",
      "Iteration: 367; Percent complete: 9.2%; Average loss: 0.0488\n",
      "Iteration: 368; Percent complete: 9.2%; Average loss: 0.0515\n",
      "Iteration: 369; Percent complete: 9.2%; Average loss: 0.0482\n",
      "Iteration: 370; Percent complete: 9.2%; Average loss: 0.0489\n",
      "Iteration: 371; Percent complete: 9.3%; Average loss: 0.0414\n",
      "Iteration: 372; Percent complete: 9.3%; Average loss: 0.0449\n",
      "Iteration: 373; Percent complete: 9.3%; Average loss: 0.0481\n",
      "Iteration: 374; Percent complete: 9.3%; Average loss: 0.0403\n",
      "Iteration: 375; Percent complete: 9.4%; Average loss: 0.0474\n",
      "Iteration: 376; Percent complete: 9.4%; Average loss: 0.0433\n",
      "Iteration: 377; Percent complete: 9.4%; Average loss: 0.0432\n",
      "Iteration: 378; Percent complete: 9.4%; Average loss: 0.0499\n",
      "Iteration: 379; Percent complete: 9.5%; Average loss: 0.0507\n",
      "Iteration: 380; Percent complete: 9.5%; Average loss: 0.0451\n",
      "Iteration: 381; Percent complete: 9.5%; Average loss: 0.0480\n",
      "Iteration: 382; Percent complete: 9.6%; Average loss: 0.0488\n",
      "Iteration: 383; Percent complete: 9.6%; Average loss: 0.0433\n",
      "Iteration: 384; Percent complete: 9.6%; Average loss: 0.0453\n",
      "Iteration: 385; Percent complete: 9.6%; Average loss: 0.0466\n",
      "Iteration: 386; Percent complete: 9.7%; Average loss: 0.0453\n",
      "Iteration: 387; Percent complete: 9.7%; Average loss: 0.0404\n",
      "Iteration: 388; Percent complete: 9.7%; Average loss: 0.0415\n",
      "Iteration: 389; Percent complete: 9.7%; Average loss: 0.0434\n",
      "Iteration: 390; Percent complete: 9.8%; Average loss: 0.0410\n",
      "Iteration: 391; Percent complete: 9.8%; Average loss: 0.0418\n",
      "Iteration: 392; Percent complete: 9.8%; Average loss: 0.0425\n",
      "Iteration: 393; Percent complete: 9.8%; Average loss: 0.0391\n",
      "Iteration: 394; Percent complete: 9.8%; Average loss: 0.0400\n",
      "Iteration: 395; Percent complete: 9.9%; Average loss: 0.0368\n",
      "Iteration: 396; Percent complete: 9.9%; Average loss: 0.0378\n",
      "Iteration: 397; Percent complete: 9.9%; Average loss: 0.0383\n",
      "Iteration: 398; Percent complete: 10.0%; Average loss: 0.0398\n",
      "Iteration: 399; Percent complete: 10.0%; Average loss: 0.0399\n",
      "Iteration: 400; Percent complete: 10.0%; Average loss: 0.0346\n",
      "Iteration: 401; Percent complete: 10.0%; Average loss: 0.0370\n",
      "Iteration: 402; Percent complete: 10.1%; Average loss: 0.0360\n",
      "Iteration: 403; Percent complete: 10.1%; Average loss: 0.0375\n",
      "Iteration: 404; Percent complete: 10.1%; Average loss: 0.0402\n",
      "Iteration: 405; Percent complete: 10.1%; Average loss: 0.0339\n",
      "Iteration: 406; Percent complete: 10.2%; Average loss: 0.0364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 407; Percent complete: 10.2%; Average loss: 0.0353\n",
      "Iteration: 408; Percent complete: 10.2%; Average loss: 0.0360\n",
      "Iteration: 409; Percent complete: 10.2%; Average loss: 0.0361\n",
      "Iteration: 410; Percent complete: 10.2%; Average loss: 0.0360\n",
      "Iteration: 411; Percent complete: 10.3%; Average loss: 0.0325\n",
      "Iteration: 412; Percent complete: 10.3%; Average loss: 0.0360\n",
      "Iteration: 413; Percent complete: 10.3%; Average loss: 0.0342\n",
      "Iteration: 414; Percent complete: 10.3%; Average loss: 0.0341\n",
      "Iteration: 415; Percent complete: 10.4%; Average loss: 0.0345\n",
      "Iteration: 416; Percent complete: 10.4%; Average loss: 0.0349\n",
      "Iteration: 417; Percent complete: 10.4%; Average loss: 0.0386\n",
      "Iteration: 418; Percent complete: 10.4%; Average loss: 0.0307\n",
      "Iteration: 419; Percent complete: 10.5%; Average loss: 0.0351\n",
      "Iteration: 420; Percent complete: 10.5%; Average loss: 0.0348\n",
      "Iteration: 421; Percent complete: 10.5%; Average loss: 0.0337\n",
      "Iteration: 422; Percent complete: 10.5%; Average loss: 0.0275\n",
      "Iteration: 423; Percent complete: 10.6%; Average loss: 0.0342\n",
      "Iteration: 424; Percent complete: 10.6%; Average loss: 0.0302\n",
      "Iteration: 425; Percent complete: 10.6%; Average loss: 0.0318\n",
      "Iteration: 426; Percent complete: 10.7%; Average loss: 0.0324\n",
      "Iteration: 427; Percent complete: 10.7%; Average loss: 0.0313\n",
      "Iteration: 428; Percent complete: 10.7%; Average loss: 0.0339\n",
      "Iteration: 429; Percent complete: 10.7%; Average loss: 0.0336\n",
      "Iteration: 430; Percent complete: 10.8%; Average loss: 0.0322\n",
      "Iteration: 431; Percent complete: 10.8%; Average loss: 0.0335\n",
      "Iteration: 432; Percent complete: 10.8%; Average loss: 0.0298\n",
      "Iteration: 433; Percent complete: 10.8%; Average loss: 0.0325\n",
      "Iteration: 434; Percent complete: 10.8%; Average loss: 0.0323\n",
      "Iteration: 435; Percent complete: 10.9%; Average loss: 0.0300\n",
      "Iteration: 436; Percent complete: 10.9%; Average loss: 0.0321\n",
      "Iteration: 437; Percent complete: 10.9%; Average loss: 0.0304\n",
      "Iteration: 438; Percent complete: 10.9%; Average loss: 0.0310\n",
      "Iteration: 439; Percent complete: 11.0%; Average loss: 0.0300\n",
      "Iteration: 440; Percent complete: 11.0%; Average loss: 0.0314\n",
      "Iteration: 441; Percent complete: 11.0%; Average loss: 0.0299\n",
      "Iteration: 442; Percent complete: 11.1%; Average loss: 0.0279\n",
      "Iteration: 443; Percent complete: 11.1%; Average loss: 0.0299\n",
      "Iteration: 444; Percent complete: 11.1%; Average loss: 0.0297\n",
      "Iteration: 445; Percent complete: 11.1%; Average loss: 0.0257\n",
      "Iteration: 446; Percent complete: 11.2%; Average loss: 0.0288\n",
      "Iteration: 447; Percent complete: 11.2%; Average loss: 0.0302\n",
      "Iteration: 448; Percent complete: 11.2%; Average loss: 0.0268\n",
      "Iteration: 449; Percent complete: 11.2%; Average loss: 0.0277\n",
      "Iteration: 450; Percent complete: 11.2%; Average loss: 0.0308\n",
      "Iteration: 451; Percent complete: 11.3%; Average loss: 0.0306\n",
      "Iteration: 452; Percent complete: 11.3%; Average loss: 0.0266\n",
      "Iteration: 453; Percent complete: 11.3%; Average loss: 0.0286\n",
      "Iteration: 454; Percent complete: 11.3%; Average loss: 0.0241\n",
      "Iteration: 455; Percent complete: 11.4%; Average loss: 0.0275\n",
      "Iteration: 456; Percent complete: 11.4%; Average loss: 0.0266\n",
      "Iteration: 457; Percent complete: 11.4%; Average loss: 0.0310\n",
      "Iteration: 458; Percent complete: 11.5%; Average loss: 0.0279\n",
      "Iteration: 459; Percent complete: 11.5%; Average loss: 0.0283\n",
      "Iteration: 460; Percent complete: 11.5%; Average loss: 0.0262\n",
      "Iteration: 461; Percent complete: 11.5%; Average loss: 0.0297\n",
      "Iteration: 462; Percent complete: 11.6%; Average loss: 0.0261\n",
      "Iteration: 463; Percent complete: 11.6%; Average loss: 0.0266\n",
      "Iteration: 464; Percent complete: 11.6%; Average loss: 0.0264\n",
      "Iteration: 465; Percent complete: 11.6%; Average loss: 0.0285\n",
      "Iteration: 466; Percent complete: 11.7%; Average loss: 0.0250\n",
      "Iteration: 467; Percent complete: 11.7%; Average loss: 0.0253\n",
      "Iteration: 468; Percent complete: 11.7%; Average loss: 0.0281\n",
      "Iteration: 469; Percent complete: 11.7%; Average loss: 0.0263\n",
      "Iteration: 470; Percent complete: 11.8%; Average loss: 0.0250\n",
      "Iteration: 471; Percent complete: 11.8%; Average loss: 0.0255\n",
      "Iteration: 472; Percent complete: 11.8%; Average loss: 0.0263\n",
      "Iteration: 473; Percent complete: 11.8%; Average loss: 0.0261\n",
      "Iteration: 474; Percent complete: 11.8%; Average loss: 0.0237\n",
      "Iteration: 475; Percent complete: 11.9%; Average loss: 0.0266\n",
      "Iteration: 476; Percent complete: 11.9%; Average loss: 0.0262\n",
      "Iteration: 477; Percent complete: 11.9%; Average loss: 0.0263\n",
      "Iteration: 478; Percent complete: 11.9%; Average loss: 0.0273\n",
      "Iteration: 479; Percent complete: 12.0%; Average loss: 0.0255\n",
      "Iteration: 480; Percent complete: 12.0%; Average loss: 0.0257\n",
      "Iteration: 481; Percent complete: 12.0%; Average loss: 0.0240\n",
      "Iteration: 482; Percent complete: 12.0%; Average loss: 0.0226\n",
      "Iteration: 483; Percent complete: 12.1%; Average loss: 0.0227\n",
      "Iteration: 484; Percent complete: 12.1%; Average loss: 0.0247\n",
      "Iteration: 485; Percent complete: 12.1%; Average loss: 0.0257\n",
      "Iteration: 486; Percent complete: 12.2%; Average loss: 0.0241\n",
      "Iteration: 487; Percent complete: 12.2%; Average loss: 0.0232\n",
      "Iteration: 488; Percent complete: 12.2%; Average loss: 0.0243\n",
      "Iteration: 489; Percent complete: 12.2%; Average loss: 0.0252\n",
      "Iteration: 490; Percent complete: 12.2%; Average loss: 0.0222\n",
      "Iteration: 491; Percent complete: 12.3%; Average loss: 0.0232\n",
      "Iteration: 492; Percent complete: 12.3%; Average loss: 0.0230\n",
      "Iteration: 493; Percent complete: 12.3%; Average loss: 0.0216\n",
      "Iteration: 494; Percent complete: 12.3%; Average loss: 0.0199\n",
      "Iteration: 495; Percent complete: 12.4%; Average loss: 0.0208\n",
      "Iteration: 496; Percent complete: 12.4%; Average loss: 0.0202\n",
      "Iteration: 497; Percent complete: 12.4%; Average loss: 0.0245\n",
      "Iteration: 498; Percent complete: 12.4%; Average loss: 0.0207\n",
      "Iteration: 499; Percent complete: 12.5%; Average loss: 0.0223\n",
      "Iteration: 500; Percent complete: 12.5%; Average loss: 0.0237\n",
      "Iteration: 501; Percent complete: 12.5%; Average loss: 0.0224\n",
      "Iteration: 502; Percent complete: 12.6%; Average loss: 0.0242\n",
      "Iteration: 503; Percent complete: 12.6%; Average loss: 0.0230\n",
      "Iteration: 504; Percent complete: 12.6%; Average loss: 0.0209\n",
      "Iteration: 505; Percent complete: 12.6%; Average loss: 0.0212\n",
      "Iteration: 506; Percent complete: 12.7%; Average loss: 0.0210\n",
      "Iteration: 507; Percent complete: 12.7%; Average loss: 0.0250\n",
      "Iteration: 508; Percent complete: 12.7%; Average loss: 0.0230\n",
      "Iteration: 509; Percent complete: 12.7%; Average loss: 0.0194\n",
      "Iteration: 510; Percent complete: 12.8%; Average loss: 0.0208\n",
      "Iteration: 511; Percent complete: 12.8%; Average loss: 0.0202\n",
      "Iteration: 512; Percent complete: 12.8%; Average loss: 0.0221\n",
      "Iteration: 513; Percent complete: 12.8%; Average loss: 0.0212\n",
      "Iteration: 514; Percent complete: 12.8%; Average loss: 0.0223\n",
      "Iteration: 515; Percent complete: 12.9%; Average loss: 0.0211\n",
      "Iteration: 516; Percent complete: 12.9%; Average loss: 0.0213\n",
      "Iteration: 517; Percent complete: 12.9%; Average loss: 0.0196\n",
      "Iteration: 518; Percent complete: 13.0%; Average loss: 0.0200\n",
      "Iteration: 519; Percent complete: 13.0%; Average loss: 0.0205\n",
      "Iteration: 520; Percent complete: 13.0%; Average loss: 0.0208\n",
      "Iteration: 521; Percent complete: 13.0%; Average loss: 0.0219\n",
      "Iteration: 522; Percent complete: 13.1%; Average loss: 0.0207\n",
      "Iteration: 523; Percent complete: 13.1%; Average loss: 0.0202\n",
      "Iteration: 524; Percent complete: 13.1%; Average loss: 0.0217\n",
      "Iteration: 525; Percent complete: 13.1%; Average loss: 0.0200\n",
      "Iteration: 526; Percent complete: 13.2%; Average loss: 0.0202\n",
      "Iteration: 527; Percent complete: 13.2%; Average loss: 0.0187\n",
      "Iteration: 528; Percent complete: 13.2%; Average loss: 0.0195\n",
      "Iteration: 529; Percent complete: 13.2%; Average loss: 0.0177\n",
      "Iteration: 530; Percent complete: 13.2%; Average loss: 0.0196\n",
      "Iteration: 531; Percent complete: 13.3%; Average loss: 0.0197\n",
      "Iteration: 532; Percent complete: 13.3%; Average loss: 0.0186\n",
      "Iteration: 533; Percent complete: 13.3%; Average loss: 0.0220\n",
      "Iteration: 534; Percent complete: 13.4%; Average loss: 0.0180\n",
      "Iteration: 535; Percent complete: 13.4%; Average loss: 0.0201\n",
      "Iteration: 536; Percent complete: 13.4%; Average loss: 0.0185\n",
      "Iteration: 537; Percent complete: 13.4%; Average loss: 0.0176\n",
      "Iteration: 538; Percent complete: 13.5%; Average loss: 0.0183\n",
      "Iteration: 539; Percent complete: 13.5%; Average loss: 0.0186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 540; Percent complete: 13.5%; Average loss: 0.0194\n",
      "Iteration: 541; Percent complete: 13.5%; Average loss: 0.0202\n",
      "Iteration: 542; Percent complete: 13.6%; Average loss: 0.0178\n",
      "Iteration: 543; Percent complete: 13.6%; Average loss: 0.0189\n",
      "Iteration: 544; Percent complete: 13.6%; Average loss: 0.0182\n",
      "Iteration: 545; Percent complete: 13.6%; Average loss: 0.0186\n",
      "Iteration: 546; Percent complete: 13.7%; Average loss: 0.0183\n",
      "Iteration: 547; Percent complete: 13.7%; Average loss: 0.0186\n",
      "Iteration: 548; Percent complete: 13.7%; Average loss: 0.0187\n",
      "Iteration: 549; Percent complete: 13.7%; Average loss: 0.0187\n",
      "Iteration: 550; Percent complete: 13.8%; Average loss: 0.0166\n",
      "Iteration: 551; Percent complete: 13.8%; Average loss: 0.0191\n",
      "Iteration: 552; Percent complete: 13.8%; Average loss: 0.0170\n",
      "Iteration: 553; Percent complete: 13.8%; Average loss: 0.0194\n",
      "Iteration: 554; Percent complete: 13.9%; Average loss: 0.0186\n",
      "Iteration: 555; Percent complete: 13.9%; Average loss: 0.0187\n",
      "Iteration: 556; Percent complete: 13.9%; Average loss: 0.0176\n",
      "Iteration: 557; Percent complete: 13.9%; Average loss: 0.0167\n",
      "Iteration: 558; Percent complete: 14.0%; Average loss: 0.0165\n",
      "Iteration: 559; Percent complete: 14.0%; Average loss: 0.0166\n",
      "Iteration: 560; Percent complete: 14.0%; Average loss: 0.0170\n",
      "Iteration: 561; Percent complete: 14.0%; Average loss: 0.0183\n",
      "Iteration: 562; Percent complete: 14.1%; Average loss: 0.0176\n",
      "Iteration: 563; Percent complete: 14.1%; Average loss: 0.0199\n",
      "Iteration: 564; Percent complete: 14.1%; Average loss: 0.0171\n",
      "Iteration: 565; Percent complete: 14.1%; Average loss: 0.0166\n",
      "Iteration: 566; Percent complete: 14.1%; Average loss: 0.0164\n",
      "Iteration: 567; Percent complete: 14.2%; Average loss: 0.0160\n",
      "Iteration: 568; Percent complete: 14.2%; Average loss: 0.0162\n",
      "Iteration: 569; Percent complete: 14.2%; Average loss: 0.0163\n",
      "Iteration: 570; Percent complete: 14.2%; Average loss: 0.0180\n",
      "Iteration: 571; Percent complete: 14.3%; Average loss: 0.0157\n",
      "Iteration: 572; Percent complete: 14.3%; Average loss: 0.0168\n",
      "Iteration: 573; Percent complete: 14.3%; Average loss: 0.0158\n",
      "Iteration: 574; Percent complete: 14.3%; Average loss: 0.0160\n",
      "Iteration: 575; Percent complete: 14.4%; Average loss: 0.0159\n",
      "Iteration: 576; Percent complete: 14.4%; Average loss: 0.0155\n",
      "Iteration: 577; Percent complete: 14.4%; Average loss: 0.0181\n",
      "Iteration: 578; Percent complete: 14.4%; Average loss: 0.0178\n",
      "Iteration: 579; Percent complete: 14.5%; Average loss: 0.0147\n",
      "Iteration: 580; Percent complete: 14.5%; Average loss: 0.0152\n",
      "Iteration: 581; Percent complete: 14.5%; Average loss: 0.0167\n",
      "Iteration: 582; Percent complete: 14.5%; Average loss: 0.0157\n",
      "Iteration: 583; Percent complete: 14.6%; Average loss: 0.0157\n",
      "Iteration: 584; Percent complete: 14.6%; Average loss: 0.0162\n",
      "Iteration: 585; Percent complete: 14.6%; Average loss: 0.0172\n",
      "Iteration: 586; Percent complete: 14.6%; Average loss: 0.0172\n",
      "Iteration: 587; Percent complete: 14.7%; Average loss: 0.0160\n",
      "Iteration: 588; Percent complete: 14.7%; Average loss: 0.0156\n",
      "Iteration: 589; Percent complete: 14.7%; Average loss: 0.0166\n",
      "Iteration: 590; Percent complete: 14.8%; Average loss: 0.0163\n",
      "Iteration: 591; Percent complete: 14.8%; Average loss: 0.0162\n",
      "Iteration: 592; Percent complete: 14.8%; Average loss: 0.0149\n",
      "Iteration: 593; Percent complete: 14.8%; Average loss: 0.0154\n",
      "Iteration: 594; Percent complete: 14.8%; Average loss: 0.0145\n",
      "Iteration: 595; Percent complete: 14.9%; Average loss: 0.0195\n",
      "Iteration: 596; Percent complete: 14.9%; Average loss: 0.0141\n",
      "Iteration: 597; Percent complete: 14.9%; Average loss: 0.0157\n",
      "Iteration: 598; Percent complete: 14.9%; Average loss: 0.0154\n",
      "Iteration: 599; Percent complete: 15.0%; Average loss: 0.0160\n",
      "Iteration: 600; Percent complete: 15.0%; Average loss: 0.0172\n",
      "Iteration: 601; Percent complete: 15.0%; Average loss: 0.0150\n",
      "Iteration: 602; Percent complete: 15.0%; Average loss: 0.0141\n",
      "Iteration: 603; Percent complete: 15.1%; Average loss: 0.0155\n",
      "Iteration: 604; Percent complete: 15.1%; Average loss: 0.0155\n",
      "Iteration: 605; Percent complete: 15.1%; Average loss: 0.0137\n",
      "Iteration: 606; Percent complete: 15.2%; Average loss: 0.0134\n",
      "Iteration: 607; Percent complete: 15.2%; Average loss: 0.0149\n",
      "Iteration: 608; Percent complete: 15.2%; Average loss: 0.0141\n",
      "Iteration: 609; Percent complete: 15.2%; Average loss: 0.0144\n",
      "Iteration: 610; Percent complete: 15.2%; Average loss: 0.0148\n",
      "Iteration: 611; Percent complete: 15.3%; Average loss: 0.0144\n",
      "Iteration: 612; Percent complete: 15.3%; Average loss: 0.0138\n",
      "Iteration: 613; Percent complete: 15.3%; Average loss: 0.0139\n",
      "Iteration: 614; Percent complete: 15.3%; Average loss: 0.0155\n",
      "Iteration: 615; Percent complete: 15.4%; Average loss: 0.0158\n",
      "Iteration: 616; Percent complete: 15.4%; Average loss: 0.0141\n",
      "Iteration: 617; Percent complete: 15.4%; Average loss: 0.0146\n",
      "Iteration: 618; Percent complete: 15.4%; Average loss: 0.0141\n",
      "Iteration: 619; Percent complete: 15.5%; Average loss: 0.0134\n",
      "Iteration: 620; Percent complete: 15.5%; Average loss: 0.0152\n",
      "Iteration: 621; Percent complete: 15.5%; Average loss: 0.0144\n",
      "Iteration: 622; Percent complete: 15.6%; Average loss: 0.0149\n",
      "Iteration: 623; Percent complete: 15.6%; Average loss: 0.0144\n",
      "Iteration: 624; Percent complete: 15.6%; Average loss: 0.0139\n",
      "Iteration: 625; Percent complete: 15.6%; Average loss: 0.0157\n",
      "Iteration: 626; Percent complete: 15.7%; Average loss: 0.0145\n",
      "Iteration: 627; Percent complete: 15.7%; Average loss: 0.0146\n",
      "Iteration: 628; Percent complete: 15.7%; Average loss: 0.0126\n",
      "Iteration: 629; Percent complete: 15.7%; Average loss: 0.0134\n",
      "Iteration: 630; Percent complete: 15.8%; Average loss: 0.0133\n",
      "Iteration: 631; Percent complete: 15.8%; Average loss: 0.0136\n",
      "Iteration: 632; Percent complete: 15.8%; Average loss: 0.0135\n",
      "Iteration: 633; Percent complete: 15.8%; Average loss: 0.0132\n",
      "Iteration: 634; Percent complete: 15.8%; Average loss: 0.0118\n",
      "Iteration: 635; Percent complete: 15.9%; Average loss: 0.0141\n",
      "Iteration: 636; Percent complete: 15.9%; Average loss: 0.0131\n",
      "Iteration: 637; Percent complete: 15.9%; Average loss: 0.0125\n",
      "Iteration: 638; Percent complete: 16.0%; Average loss: 0.0145\n",
      "Iteration: 639; Percent complete: 16.0%; Average loss: 0.0136\n",
      "Iteration: 640; Percent complete: 16.0%; Average loss: 0.0132\n",
      "Iteration: 641; Percent complete: 16.0%; Average loss: 0.0128\n",
      "Iteration: 642; Percent complete: 16.1%; Average loss: 0.0123\n",
      "Iteration: 643; Percent complete: 16.1%; Average loss: 0.0140\n",
      "Iteration: 644; Percent complete: 16.1%; Average loss: 0.0126\n",
      "Iteration: 645; Percent complete: 16.1%; Average loss: 0.0138\n",
      "Iteration: 646; Percent complete: 16.2%; Average loss: 0.0137\n",
      "Iteration: 647; Percent complete: 16.2%; Average loss: 0.0127\n",
      "Iteration: 648; Percent complete: 16.2%; Average loss: 0.0127\n",
      "Iteration: 649; Percent complete: 16.2%; Average loss: 0.0133\n",
      "Iteration: 650; Percent complete: 16.2%; Average loss: 0.0129\n",
      "Iteration: 651; Percent complete: 16.3%; Average loss: 0.0119\n",
      "Iteration: 652; Percent complete: 16.3%; Average loss: 0.0129\n",
      "Iteration: 653; Percent complete: 16.3%; Average loss: 0.0124\n",
      "Iteration: 654; Percent complete: 16.4%; Average loss: 0.0137\n",
      "Iteration: 655; Percent complete: 16.4%; Average loss: 0.0112\n",
      "Iteration: 656; Percent complete: 16.4%; Average loss: 0.0125\n",
      "Iteration: 657; Percent complete: 16.4%; Average loss: 0.0120\n",
      "Iteration: 658; Percent complete: 16.4%; Average loss: 0.0127\n",
      "Iteration: 659; Percent complete: 16.5%; Average loss: 0.0131\n",
      "Iteration: 660; Percent complete: 16.5%; Average loss: 0.0110\n",
      "Iteration: 661; Percent complete: 16.5%; Average loss: 0.0116\n",
      "Iteration: 662; Percent complete: 16.6%; Average loss: 0.0119\n",
      "Iteration: 663; Percent complete: 16.6%; Average loss: 0.0121\n",
      "Iteration: 664; Percent complete: 16.6%; Average loss: 0.0119\n",
      "Iteration: 665; Percent complete: 16.6%; Average loss: 0.0113\n",
      "Iteration: 666; Percent complete: 16.7%; Average loss: 0.0124\n",
      "Iteration: 667; Percent complete: 16.7%; Average loss: 0.0116\n",
      "Iteration: 668; Percent complete: 16.7%; Average loss: 0.0109\n",
      "Iteration: 669; Percent complete: 16.7%; Average loss: 0.0124\n",
      "Iteration: 670; Percent complete: 16.8%; Average loss: 0.0117\n",
      "Iteration: 671; Percent complete: 16.8%; Average loss: 0.0116\n",
      "Iteration: 672; Percent complete: 16.8%; Average loss: 0.0128\n",
      "Iteration: 673; Percent complete: 16.8%; Average loss: 0.0112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 674; Percent complete: 16.9%; Average loss: 0.0107\n",
      "Iteration: 675; Percent complete: 16.9%; Average loss: 0.0118\n",
      "Iteration: 676; Percent complete: 16.9%; Average loss: 0.0131\n",
      "Iteration: 677; Percent complete: 16.9%; Average loss: 0.0102\n",
      "Iteration: 678; Percent complete: 17.0%; Average loss: 0.0115\n",
      "Iteration: 679; Percent complete: 17.0%; Average loss: 0.0113\n",
      "Iteration: 680; Percent complete: 17.0%; Average loss: 0.0110\n",
      "Iteration: 681; Percent complete: 17.0%; Average loss: 0.0114\n",
      "Iteration: 682; Percent complete: 17.1%; Average loss: 0.0123\n",
      "Iteration: 683; Percent complete: 17.1%; Average loss: 0.0117\n",
      "Iteration: 684; Percent complete: 17.1%; Average loss: 0.0113\n",
      "Iteration: 685; Percent complete: 17.1%; Average loss: 0.0115\n",
      "Iteration: 686; Percent complete: 17.2%; Average loss: 0.0112\n",
      "Iteration: 687; Percent complete: 17.2%; Average loss: 0.0111\n",
      "Iteration: 688; Percent complete: 17.2%; Average loss: 0.0107\n",
      "Iteration: 689; Percent complete: 17.2%; Average loss: 0.0103\n",
      "Iteration: 690; Percent complete: 17.2%; Average loss: 0.0116\n",
      "Iteration: 691; Percent complete: 17.3%; Average loss: 0.0106\n",
      "Iteration: 692; Percent complete: 17.3%; Average loss: 0.0108\n",
      "Iteration: 693; Percent complete: 17.3%; Average loss: 0.0106\n",
      "Iteration: 694; Percent complete: 17.3%; Average loss: 0.0115\n",
      "Iteration: 695; Percent complete: 17.4%; Average loss: 0.0102\n",
      "Iteration: 696; Percent complete: 17.4%; Average loss: 0.0114\n",
      "Iteration: 697; Percent complete: 17.4%; Average loss: 0.0111\n",
      "Iteration: 698; Percent complete: 17.4%; Average loss: 0.0103\n",
      "Iteration: 699; Percent complete: 17.5%; Average loss: 0.0102\n",
      "Iteration: 700; Percent complete: 17.5%; Average loss: 0.0102\n",
      "Iteration: 701; Percent complete: 17.5%; Average loss: 0.0097\n",
      "Iteration: 702; Percent complete: 17.5%; Average loss: 0.0103\n",
      "Iteration: 703; Percent complete: 17.6%; Average loss: 0.0110\n",
      "Iteration: 704; Percent complete: 17.6%; Average loss: 0.0108\n",
      "Iteration: 705; Percent complete: 17.6%; Average loss: 0.0109\n",
      "Iteration: 706; Percent complete: 17.6%; Average loss: 0.0122\n",
      "Iteration: 707; Percent complete: 17.7%; Average loss: 0.0108\n",
      "Iteration: 708; Percent complete: 17.7%; Average loss: 0.0101\n",
      "Iteration: 709; Percent complete: 17.7%; Average loss: 0.0117\n",
      "Iteration: 710; Percent complete: 17.8%; Average loss: 0.0117\n",
      "Iteration: 711; Percent complete: 17.8%; Average loss: 0.0108\n",
      "Iteration: 712; Percent complete: 17.8%; Average loss: 0.0102\n",
      "Iteration: 713; Percent complete: 17.8%; Average loss: 0.0108\n",
      "Iteration: 714; Percent complete: 17.8%; Average loss: 0.0105\n",
      "Iteration: 715; Percent complete: 17.9%; Average loss: 0.0111\n",
      "Iteration: 716; Percent complete: 17.9%; Average loss: 0.0101\n",
      "Iteration: 717; Percent complete: 17.9%; Average loss: 0.0104\n",
      "Iteration: 718; Percent complete: 17.9%; Average loss: 0.0101\n",
      "Iteration: 719; Percent complete: 18.0%; Average loss: 0.0105\n",
      "Iteration: 720; Percent complete: 18.0%; Average loss: 0.0102\n",
      "Iteration: 721; Percent complete: 18.0%; Average loss: 0.0108\n",
      "Iteration: 722; Percent complete: 18.1%; Average loss: 0.0104\n",
      "Iteration: 723; Percent complete: 18.1%; Average loss: 0.0106\n",
      "Iteration: 724; Percent complete: 18.1%; Average loss: 0.0105\n",
      "Iteration: 725; Percent complete: 18.1%; Average loss: 0.0101\n",
      "Iteration: 726; Percent complete: 18.1%; Average loss: 0.0093\n",
      "Iteration: 727; Percent complete: 18.2%; Average loss: 0.0105\n",
      "Iteration: 728; Percent complete: 18.2%; Average loss: 0.0111\n",
      "Iteration: 729; Percent complete: 18.2%; Average loss: 0.0099\n",
      "Iteration: 730; Percent complete: 18.2%; Average loss: 0.0097\n",
      "Iteration: 731; Percent complete: 18.3%; Average loss: 0.0093\n",
      "Iteration: 732; Percent complete: 18.3%; Average loss: 0.0104\n",
      "Iteration: 733; Percent complete: 18.3%; Average loss: 0.0109\n",
      "Iteration: 734; Percent complete: 18.4%; Average loss: 0.0098\n",
      "Iteration: 735; Percent complete: 18.4%; Average loss: 0.0097\n",
      "Iteration: 736; Percent complete: 18.4%; Average loss: 0.0104\n",
      "Iteration: 737; Percent complete: 18.4%; Average loss: 0.0099\n",
      "Iteration: 738; Percent complete: 18.4%; Average loss: 0.0092\n",
      "Iteration: 739; Percent complete: 18.5%; Average loss: 0.0096\n",
      "Iteration: 740; Percent complete: 18.5%; Average loss: 0.0100\n",
      "Iteration: 741; Percent complete: 18.5%; Average loss: 0.0100\n",
      "Iteration: 742; Percent complete: 18.6%; Average loss: 0.0099\n",
      "Iteration: 743; Percent complete: 18.6%; Average loss: 0.0103\n",
      "Iteration: 744; Percent complete: 18.6%; Average loss: 0.0097\n",
      "Iteration: 745; Percent complete: 18.6%; Average loss: 0.0098\n",
      "Iteration: 746; Percent complete: 18.6%; Average loss: 0.0100\n",
      "Iteration: 747; Percent complete: 18.7%; Average loss: 0.0099\n",
      "Iteration: 748; Percent complete: 18.7%; Average loss: 0.0095\n",
      "Iteration: 749; Percent complete: 18.7%; Average loss: 0.0108\n",
      "Iteration: 750; Percent complete: 18.8%; Average loss: 0.0086\n",
      "Iteration: 751; Percent complete: 18.8%; Average loss: 0.0097\n",
      "Iteration: 752; Percent complete: 18.8%; Average loss: 0.0100\n",
      "Iteration: 753; Percent complete: 18.8%; Average loss: 0.0084\n",
      "Iteration: 754; Percent complete: 18.9%; Average loss: 0.0097\n",
      "Iteration: 755; Percent complete: 18.9%; Average loss: 0.0101\n",
      "Iteration: 756; Percent complete: 18.9%; Average loss: 0.0108\n",
      "Iteration: 757; Percent complete: 18.9%; Average loss: 0.0089\n",
      "Iteration: 758; Percent complete: 18.9%; Average loss: 0.0103\n",
      "Iteration: 759; Percent complete: 19.0%; Average loss: 0.0093\n",
      "Iteration: 760; Percent complete: 19.0%; Average loss: 0.0087\n",
      "Iteration: 761; Percent complete: 19.0%; Average loss: 0.0095\n",
      "Iteration: 762; Percent complete: 19.1%; Average loss: 0.0106\n",
      "Iteration: 763; Percent complete: 19.1%; Average loss: 0.0085\n",
      "Iteration: 764; Percent complete: 19.1%; Average loss: 0.0096\n",
      "Iteration: 765; Percent complete: 19.1%; Average loss: 0.0088\n",
      "Iteration: 766; Percent complete: 19.1%; Average loss: 0.0093\n",
      "Iteration: 767; Percent complete: 19.2%; Average loss: 0.0100\n",
      "Iteration: 768; Percent complete: 19.2%; Average loss: 0.0088\n",
      "Iteration: 769; Percent complete: 19.2%; Average loss: 0.0090\n",
      "Iteration: 770; Percent complete: 19.2%; Average loss: 0.0081\n",
      "Iteration: 771; Percent complete: 19.3%; Average loss: 0.0099\n",
      "Iteration: 772; Percent complete: 19.3%; Average loss: 0.0091\n",
      "Iteration: 773; Percent complete: 19.3%; Average loss: 0.0090\n",
      "Iteration: 774; Percent complete: 19.4%; Average loss: 0.0089\n",
      "Iteration: 775; Percent complete: 19.4%; Average loss: 0.0089\n",
      "Iteration: 776; Percent complete: 19.4%; Average loss: 0.0095\n",
      "Iteration: 777; Percent complete: 19.4%; Average loss: 0.0090\n",
      "Iteration: 778; Percent complete: 19.4%; Average loss: 0.0088\n",
      "Iteration: 779; Percent complete: 19.5%; Average loss: 0.0084\n",
      "Iteration: 780; Percent complete: 19.5%; Average loss: 0.0084\n",
      "Iteration: 781; Percent complete: 19.5%; Average loss: 0.0092\n",
      "Iteration: 782; Percent complete: 19.6%; Average loss: 0.0096\n",
      "Iteration: 783; Percent complete: 19.6%; Average loss: 0.0081\n",
      "Iteration: 784; Percent complete: 19.6%; Average loss: 0.0097\n",
      "Iteration: 785; Percent complete: 19.6%; Average loss: 0.0089\n",
      "Iteration: 786; Percent complete: 19.7%; Average loss: 0.0085\n",
      "Iteration: 787; Percent complete: 19.7%; Average loss: 0.0085\n",
      "Iteration: 788; Percent complete: 19.7%; Average loss: 0.0086\n",
      "Iteration: 789; Percent complete: 19.7%; Average loss: 0.0086\n",
      "Iteration: 790; Percent complete: 19.8%; Average loss: 0.0090\n",
      "Iteration: 791; Percent complete: 19.8%; Average loss: 0.0086\n",
      "Iteration: 792; Percent complete: 19.8%; Average loss: 0.0086\n",
      "Iteration: 793; Percent complete: 19.8%; Average loss: 0.0090\n",
      "Iteration: 794; Percent complete: 19.9%; Average loss: 0.0086\n",
      "Iteration: 795; Percent complete: 19.9%; Average loss: 0.0090\n",
      "Iteration: 796; Percent complete: 19.9%; Average loss: 0.0083\n",
      "Iteration: 797; Percent complete: 19.9%; Average loss: 0.0082\n",
      "Iteration: 798; Percent complete: 20.0%; Average loss: 0.0086\n",
      "Iteration: 799; Percent complete: 20.0%; Average loss: 0.0082\n",
      "Iteration: 800; Percent complete: 20.0%; Average loss: 0.0080\n",
      "Iteration: 801; Percent complete: 20.0%; Average loss: 0.0078\n",
      "Iteration: 802; Percent complete: 20.1%; Average loss: 0.0089\n",
      "Iteration: 803; Percent complete: 20.1%; Average loss: 0.0090\n",
      "Iteration: 804; Percent complete: 20.1%; Average loss: 0.0079\n",
      "Iteration: 805; Percent complete: 20.1%; Average loss: 0.0077\n",
      "Iteration: 806; Percent complete: 20.2%; Average loss: 0.0077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 807; Percent complete: 20.2%; Average loss: 0.0080\n",
      "Iteration: 808; Percent complete: 20.2%; Average loss: 0.0078\n",
      "Iteration: 809; Percent complete: 20.2%; Average loss: 0.0076\n",
      "Iteration: 810; Percent complete: 20.2%; Average loss: 0.0078\n",
      "Iteration: 811; Percent complete: 20.3%; Average loss: 0.0083\n",
      "Iteration: 812; Percent complete: 20.3%; Average loss: 0.0087\n",
      "Iteration: 813; Percent complete: 20.3%; Average loss: 0.0078\n",
      "Iteration: 814; Percent complete: 20.3%; Average loss: 0.0083\n",
      "Iteration: 815; Percent complete: 20.4%; Average loss: 0.0076\n",
      "Iteration: 816; Percent complete: 20.4%; Average loss: 0.0080\n",
      "Iteration: 817; Percent complete: 20.4%; Average loss: 0.0088\n",
      "Iteration: 818; Percent complete: 20.4%; Average loss: 0.0077\n",
      "Iteration: 819; Percent complete: 20.5%; Average loss: 0.0076\n",
      "Iteration: 820; Percent complete: 20.5%; Average loss: 0.0069\n",
      "Iteration: 821; Percent complete: 20.5%; Average loss: 0.0085\n",
      "Iteration: 822; Percent complete: 20.5%; Average loss: 0.0075\n",
      "Iteration: 823; Percent complete: 20.6%; Average loss: 0.0078\n",
      "Iteration: 824; Percent complete: 20.6%; Average loss: 0.0080\n",
      "Iteration: 825; Percent complete: 20.6%; Average loss: 0.0081\n",
      "Iteration: 826; Percent complete: 20.6%; Average loss: 0.0081\n",
      "Iteration: 827; Percent complete: 20.7%; Average loss: 0.0087\n",
      "Iteration: 828; Percent complete: 20.7%; Average loss: 0.0076\n",
      "Iteration: 829; Percent complete: 20.7%; Average loss: 0.0070\n",
      "Iteration: 830; Percent complete: 20.8%; Average loss: 0.0083\n",
      "Iteration: 831; Percent complete: 20.8%; Average loss: 0.0089\n",
      "Iteration: 832; Percent complete: 20.8%; Average loss: 0.0080\n",
      "Iteration: 833; Percent complete: 20.8%; Average loss: 0.0082\n",
      "Iteration: 834; Percent complete: 20.8%; Average loss: 0.0076\n",
      "Iteration: 835; Percent complete: 20.9%; Average loss: 0.0079\n",
      "Iteration: 836; Percent complete: 20.9%; Average loss: 0.0075\n",
      "Iteration: 837; Percent complete: 20.9%; Average loss: 0.0072\n",
      "Iteration: 838; Percent complete: 20.9%; Average loss: 0.0078\n",
      "Iteration: 839; Percent complete: 21.0%; Average loss: 0.0075\n",
      "Iteration: 840; Percent complete: 21.0%; Average loss: 0.0078\n",
      "Iteration: 841; Percent complete: 21.0%; Average loss: 0.0081\n",
      "Iteration: 842; Percent complete: 21.1%; Average loss: 0.0075\n",
      "Iteration: 843; Percent complete: 21.1%; Average loss: 0.0082\n",
      "Iteration: 844; Percent complete: 21.1%; Average loss: 0.0074\n",
      "Iteration: 845; Percent complete: 21.1%; Average loss: 0.0068\n",
      "Iteration: 846; Percent complete: 21.1%; Average loss: 0.0073\n",
      "Iteration: 847; Percent complete: 21.2%; Average loss: 0.0071\n",
      "Iteration: 848; Percent complete: 21.2%; Average loss: 0.0078\n",
      "Iteration: 849; Percent complete: 21.2%; Average loss: 0.0073\n",
      "Iteration: 850; Percent complete: 21.2%; Average loss: 0.0067\n",
      "Iteration: 851; Percent complete: 21.3%; Average loss: 0.0068\n",
      "Iteration: 852; Percent complete: 21.3%; Average loss: 0.0069\n",
      "Iteration: 853; Percent complete: 21.3%; Average loss: 0.0070\n",
      "Iteration: 854; Percent complete: 21.3%; Average loss: 0.0067\n",
      "Iteration: 855; Percent complete: 21.4%; Average loss: 0.0072\n",
      "Iteration: 856; Percent complete: 21.4%; Average loss: 0.0071\n",
      "Iteration: 857; Percent complete: 21.4%; Average loss: 0.0079\n",
      "Iteration: 858; Percent complete: 21.4%; Average loss: 0.0067\n",
      "Iteration: 859; Percent complete: 21.5%; Average loss: 0.0075\n",
      "Iteration: 860; Percent complete: 21.5%; Average loss: 0.0075\n",
      "Iteration: 861; Percent complete: 21.5%; Average loss: 0.0074\n",
      "Iteration: 862; Percent complete: 21.6%; Average loss: 0.0068\n",
      "Iteration: 863; Percent complete: 21.6%; Average loss: 0.0070\n",
      "Iteration: 864; Percent complete: 21.6%; Average loss: 0.0078\n",
      "Iteration: 865; Percent complete: 21.6%; Average loss: 0.0078\n",
      "Iteration: 866; Percent complete: 21.6%; Average loss: 0.0070\n",
      "Iteration: 867; Percent complete: 21.7%; Average loss: 0.0069\n",
      "Iteration: 868; Percent complete: 21.7%; Average loss: 0.0065\n",
      "Iteration: 869; Percent complete: 21.7%; Average loss: 0.0072\n",
      "Iteration: 870; Percent complete: 21.8%; Average loss: 0.0061\n",
      "Iteration: 871; Percent complete: 21.8%; Average loss: 0.0076\n",
      "Iteration: 872; Percent complete: 21.8%; Average loss: 0.0073\n",
      "Iteration: 873; Percent complete: 21.8%; Average loss: 0.0071\n",
      "Iteration: 874; Percent complete: 21.9%; Average loss: 0.0070\n",
      "Iteration: 875; Percent complete: 21.9%; Average loss: 0.0068\n",
      "Iteration: 876; Percent complete: 21.9%; Average loss: 0.0074\n",
      "Iteration: 877; Percent complete: 21.9%; Average loss: 0.0071\n",
      "Iteration: 878; Percent complete: 21.9%; Average loss: 0.0075\n",
      "Iteration: 879; Percent complete: 22.0%; Average loss: 0.0072\n",
      "Iteration: 880; Percent complete: 22.0%; Average loss: 0.0073\n",
      "Iteration: 881; Percent complete: 22.0%; Average loss: 0.0073\n",
      "Iteration: 882; Percent complete: 22.1%; Average loss: 0.0062\n",
      "Iteration: 883; Percent complete: 22.1%; Average loss: 0.0069\n",
      "Iteration: 884; Percent complete: 22.1%; Average loss: 0.0069\n",
      "Iteration: 885; Percent complete: 22.1%; Average loss: 0.0071\n",
      "Iteration: 886; Percent complete: 22.1%; Average loss: 0.0067\n",
      "Iteration: 887; Percent complete: 22.2%; Average loss: 0.0061\n",
      "Iteration: 888; Percent complete: 22.2%; Average loss: 0.0066\n",
      "Iteration: 889; Percent complete: 22.2%; Average loss: 0.0070\n",
      "Iteration: 890; Percent complete: 22.2%; Average loss: 0.0065\n",
      "Iteration: 891; Percent complete: 22.3%; Average loss: 0.0065\n",
      "Iteration: 892; Percent complete: 22.3%; Average loss: 0.0072\n",
      "Iteration: 893; Percent complete: 22.3%; Average loss: 0.0067\n",
      "Iteration: 894; Percent complete: 22.4%; Average loss: 0.0068\n",
      "Iteration: 895; Percent complete: 22.4%; Average loss: 0.0062\n",
      "Iteration: 896; Percent complete: 22.4%; Average loss: 0.0065\n",
      "Iteration: 897; Percent complete: 22.4%; Average loss: 0.0065\n",
      "Iteration: 898; Percent complete: 22.4%; Average loss: 0.0063\n",
      "Iteration: 899; Percent complete: 22.5%; Average loss: 0.0065\n",
      "Iteration: 900; Percent complete: 22.5%; Average loss: 0.0064\n",
      "Iteration: 901; Percent complete: 22.5%; Average loss: 0.0078\n",
      "Iteration: 902; Percent complete: 22.6%; Average loss: 0.0063\n",
      "Iteration: 903; Percent complete: 22.6%; Average loss: 0.0068\n",
      "Iteration: 904; Percent complete: 22.6%; Average loss: 0.0063\n",
      "Iteration: 905; Percent complete: 22.6%; Average loss: 0.0057\n",
      "Iteration: 906; Percent complete: 22.7%; Average loss: 0.0067\n",
      "Iteration: 907; Percent complete: 22.7%; Average loss: 0.0069\n",
      "Iteration: 908; Percent complete: 22.7%; Average loss: 0.0062\n",
      "Iteration: 909; Percent complete: 22.7%; Average loss: 0.0068\n",
      "Iteration: 910; Percent complete: 22.8%; Average loss: 0.0062\n",
      "Iteration: 911; Percent complete: 22.8%; Average loss: 0.0060\n",
      "Iteration: 912; Percent complete: 22.8%; Average loss: 0.0068\n",
      "Iteration: 913; Percent complete: 22.8%; Average loss: 0.0064\n",
      "Iteration: 914; Percent complete: 22.9%; Average loss: 0.0066\n",
      "Iteration: 915; Percent complete: 22.9%; Average loss: 0.0067\n",
      "Iteration: 916; Percent complete: 22.9%; Average loss: 0.0063\n",
      "Iteration: 917; Percent complete: 22.9%; Average loss: 0.0065\n",
      "Iteration: 918; Percent complete: 22.9%; Average loss: 0.0061\n",
      "Iteration: 919; Percent complete: 23.0%; Average loss: 0.0066\n",
      "Iteration: 920; Percent complete: 23.0%; Average loss: 0.0067\n",
      "Iteration: 921; Percent complete: 23.0%; Average loss: 0.0064\n",
      "Iteration: 922; Percent complete: 23.1%; Average loss: 0.0064\n",
      "Iteration: 923; Percent complete: 23.1%; Average loss: 0.0063\n",
      "Iteration: 924; Percent complete: 23.1%; Average loss: 0.0063\n",
      "Iteration: 925; Percent complete: 23.1%; Average loss: 0.0064\n",
      "Iteration: 926; Percent complete: 23.2%; Average loss: 0.0149\n",
      "Iteration: 927; Percent complete: 23.2%; Average loss: 0.0065\n",
      "Iteration: 928; Percent complete: 23.2%; Average loss: 0.0063\n",
      "Iteration: 929; Percent complete: 23.2%; Average loss: 0.0066\n",
      "Iteration: 930; Percent complete: 23.2%; Average loss: 0.0067\n",
      "Iteration: 931; Percent complete: 23.3%; Average loss: 0.0061\n",
      "Iteration: 932; Percent complete: 23.3%; Average loss: 0.0136\n",
      "Iteration: 933; Percent complete: 23.3%; Average loss: 0.0073\n",
      "Iteration: 934; Percent complete: 23.4%; Average loss: 0.0074\n",
      "Iteration: 935; Percent complete: 23.4%; Average loss: 0.0230\n",
      "Iteration: 936; Percent complete: 23.4%; Average loss: 0.0076\n",
      "Iteration: 937; Percent complete: 23.4%; Average loss: 0.0125\n",
      "Iteration: 938; Percent complete: 23.4%; Average loss: 0.0071\n",
      "Iteration: 939; Percent complete: 23.5%; Average loss: 0.0073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 940; Percent complete: 23.5%; Average loss: 0.0087\n",
      "Iteration: 941; Percent complete: 23.5%; Average loss: 0.0107\n",
      "Iteration: 942; Percent complete: 23.5%; Average loss: 0.0226\n",
      "Iteration: 943; Percent complete: 23.6%; Average loss: 0.0067\n",
      "Iteration: 944; Percent complete: 23.6%; Average loss: 0.0073\n",
      "Iteration: 945; Percent complete: 23.6%; Average loss: 0.0092\n",
      "Iteration: 946; Percent complete: 23.6%; Average loss: 0.0078\n",
      "Iteration: 947; Percent complete: 23.7%; Average loss: 0.0110\n",
      "Iteration: 948; Percent complete: 23.7%; Average loss: 0.0200\n",
      "Iteration: 949; Percent complete: 23.7%; Average loss: 0.0071\n",
      "Iteration: 950; Percent complete: 23.8%; Average loss: 0.0098\n",
      "Iteration: 951; Percent complete: 23.8%; Average loss: 0.0086\n",
      "Iteration: 952; Percent complete: 23.8%; Average loss: 0.0162\n",
      "Iteration: 953; Percent complete: 23.8%; Average loss: 0.0091\n",
      "Iteration: 954; Percent complete: 23.8%; Average loss: 0.0103\n",
      "Iteration: 955; Percent complete: 23.9%; Average loss: 0.0101\n",
      "Iteration: 956; Percent complete: 23.9%; Average loss: 0.0101\n",
      "Iteration: 957; Percent complete: 23.9%; Average loss: 0.0267\n",
      "Iteration: 958; Percent complete: 23.9%; Average loss: 0.0081\n",
      "Iteration: 959; Percent complete: 24.0%; Average loss: 0.0075\n",
      "Iteration: 960; Percent complete: 24.0%; Average loss: 0.0085\n",
      "Iteration: 961; Percent complete: 24.0%; Average loss: 0.0079\n",
      "Iteration: 962; Percent complete: 24.1%; Average loss: 0.0091\n",
      "Iteration: 963; Percent complete: 24.1%; Average loss: 0.0075\n",
      "Iteration: 964; Percent complete: 24.1%; Average loss: 0.0223\n",
      "Iteration: 965; Percent complete: 24.1%; Average loss: 0.0084\n",
      "Iteration: 966; Percent complete: 24.1%; Average loss: 0.0084\n",
      "Iteration: 967; Percent complete: 24.2%; Average loss: 0.0124\n",
      "Iteration: 968; Percent complete: 24.2%; Average loss: 0.0091\n",
      "Iteration: 969; Percent complete: 24.2%; Average loss: 0.0168\n",
      "Iteration: 970; Percent complete: 24.2%; Average loss: 0.0153\n",
      "Iteration: 971; Percent complete: 24.3%; Average loss: 0.0231\n",
      "Iteration: 972; Percent complete: 24.3%; Average loss: 0.0181\n",
      "Iteration: 973; Percent complete: 24.3%; Average loss: 0.0309\n",
      "Iteration: 974; Percent complete: 24.3%; Average loss: 0.0276\n",
      "Iteration: 975; Percent complete: 24.4%; Average loss: 0.0327\n",
      "Iteration: 976; Percent complete: 24.4%; Average loss: 0.0414\n",
      "Iteration: 977; Percent complete: 24.4%; Average loss: 0.0236\n",
      "Iteration: 978; Percent complete: 24.4%; Average loss: 0.0209\n",
      "Iteration: 979; Percent complete: 24.5%; Average loss: 0.0279\n",
      "Iteration: 980; Percent complete: 24.5%; Average loss: 0.0219\n",
      "Iteration: 981; Percent complete: 24.5%; Average loss: 0.0222\n",
      "Iteration: 982; Percent complete: 24.6%; Average loss: 0.0142\n",
      "Iteration: 983; Percent complete: 24.6%; Average loss: 0.0146\n",
      "Iteration: 984; Percent complete: 24.6%; Average loss: 0.0152\n",
      "Iteration: 985; Percent complete: 24.6%; Average loss: 0.0129\n",
      "Iteration: 986; Percent complete: 24.6%; Average loss: 0.0105\n",
      "Iteration: 987; Percent complete: 24.7%; Average loss: 0.0135\n",
      "Iteration: 988; Percent complete: 24.7%; Average loss: 0.0135\n",
      "Iteration: 989; Percent complete: 24.7%; Average loss: 0.0092\n",
      "Iteration: 990; Percent complete: 24.8%; Average loss: 0.0098\n",
      "Iteration: 991; Percent complete: 24.8%; Average loss: 0.0094\n",
      "Iteration: 992; Percent complete: 24.8%; Average loss: 0.0129\n",
      "Iteration: 993; Percent complete: 24.8%; Average loss: 0.0095\n",
      "Iteration: 994; Percent complete: 24.9%; Average loss: 0.0318\n",
      "Iteration: 995; Percent complete: 24.9%; Average loss: 0.0107\n",
      "Iteration: 996; Percent complete: 24.9%; Average loss: 0.0104\n",
      "Iteration: 997; Percent complete: 24.9%; Average loss: 0.0143\n",
      "Iteration: 998; Percent complete: 24.9%; Average loss: 0.0321\n",
      "Iteration: 999; Percent complete: 25.0%; Average loss: 0.0191\n",
      "Iteration: 1000; Percent complete: 25.0%; Average loss: 0.0238\n",
      "Iteration: 1001; Percent complete: 25.0%; Average loss: 0.0135\n",
      "Iteration: 1002; Percent complete: 25.1%; Average loss: 0.0091\n",
      "Iteration: 1003; Percent complete: 25.1%; Average loss: 0.0118\n",
      "Iteration: 1004; Percent complete: 25.1%; Average loss: 0.0115\n",
      "Iteration: 1005; Percent complete: 25.1%; Average loss: 0.0111\n",
      "Iteration: 1006; Percent complete: 25.1%; Average loss: 0.0086\n",
      "Iteration: 1007; Percent complete: 25.2%; Average loss: 0.0090\n",
      "Iteration: 1008; Percent complete: 25.2%; Average loss: 0.0111\n",
      "Iteration: 1009; Percent complete: 25.2%; Average loss: 0.0097\n",
      "Iteration: 1010; Percent complete: 25.2%; Average loss: 0.0143\n",
      "Iteration: 1011; Percent complete: 25.3%; Average loss: 0.0226\n",
      "Iteration: 1012; Percent complete: 25.3%; Average loss: 0.0092\n",
      "Iteration: 1013; Percent complete: 25.3%; Average loss: 0.0133\n",
      "Iteration: 1014; Percent complete: 25.4%; Average loss: 0.0103\n",
      "Iteration: 1015; Percent complete: 25.4%; Average loss: 0.0090\n",
      "Iteration: 1016; Percent complete: 25.4%; Average loss: 0.0107\n",
      "Iteration: 1017; Percent complete: 25.4%; Average loss: 0.0092\n",
      "Iteration: 1018; Percent complete: 25.4%; Average loss: 0.0080\n",
      "Iteration: 1019; Percent complete: 25.5%; Average loss: 0.0084\n",
      "Iteration: 1020; Percent complete: 25.5%; Average loss: 0.0081\n",
      "Iteration: 1021; Percent complete: 25.5%; Average loss: 0.0208\n",
      "Iteration: 1022; Percent complete: 25.6%; Average loss: 0.0108\n",
      "Iteration: 1023; Percent complete: 25.6%; Average loss: 0.0112\n",
      "Iteration: 1024; Percent complete: 25.6%; Average loss: 0.0225\n",
      "Iteration: 1025; Percent complete: 25.6%; Average loss: 0.0135\n",
      "Iteration: 1026; Percent complete: 25.7%; Average loss: 0.0087\n",
      "Iteration: 1027; Percent complete: 25.7%; Average loss: 0.0151\n",
      "Iteration: 1028; Percent complete: 25.7%; Average loss: 0.0084\n",
      "Iteration: 1029; Percent complete: 25.7%; Average loss: 0.0103\n",
      "Iteration: 1030; Percent complete: 25.8%; Average loss: 0.0122\n",
      "Iteration: 1031; Percent complete: 25.8%; Average loss: 0.0108\n",
      "Iteration: 1032; Percent complete: 25.8%; Average loss: 0.0141\n",
      "Iteration: 1033; Percent complete: 25.8%; Average loss: 0.0087\n",
      "Iteration: 1034; Percent complete: 25.9%; Average loss: 0.0106\n",
      "Iteration: 1035; Percent complete: 25.9%; Average loss: 0.0107\n",
      "Iteration: 1036; Percent complete: 25.9%; Average loss: 0.0129\n",
      "Iteration: 1037; Percent complete: 25.9%; Average loss: 0.0097\n",
      "Iteration: 1038; Percent complete: 25.9%; Average loss: 0.0118\n",
      "Iteration: 1039; Percent complete: 26.0%; Average loss: 0.0495\n",
      "Iteration: 1040; Percent complete: 26.0%; Average loss: 0.0082\n",
      "Iteration: 1041; Percent complete: 26.0%; Average loss: 0.0155\n",
      "Iteration: 1042; Percent complete: 26.1%; Average loss: 0.0294\n",
      "Iteration: 1043; Percent complete: 26.1%; Average loss: 0.0086\n",
      "Iteration: 1044; Percent complete: 26.1%; Average loss: 0.0287\n",
      "Iteration: 1045; Percent complete: 26.1%; Average loss: 0.0134\n",
      "Iteration: 1046; Percent complete: 26.2%; Average loss: 0.0111\n",
      "Iteration: 1047; Percent complete: 26.2%; Average loss: 0.0193\n",
      "Iteration: 1048; Percent complete: 26.2%; Average loss: 0.0253\n",
      "Iteration: 1049; Percent complete: 26.2%; Average loss: 0.0154\n",
      "Iteration: 1050; Percent complete: 26.2%; Average loss: 0.0137\n",
      "Iteration: 1051; Percent complete: 26.3%; Average loss: 0.0172\n",
      "Iteration: 1052; Percent complete: 26.3%; Average loss: 0.0245\n",
      "Iteration: 1053; Percent complete: 26.3%; Average loss: 0.0102\n",
      "Iteration: 1054; Percent complete: 26.4%; Average loss: 0.0170\n",
      "Iteration: 1055; Percent complete: 26.4%; Average loss: 0.0720\n",
      "Iteration: 1056; Percent complete: 26.4%; Average loss: 0.0485\n",
      "Iteration: 1057; Percent complete: 26.4%; Average loss: 0.0117\n",
      "Iteration: 1058; Percent complete: 26.5%; Average loss: 0.0392\n",
      "Iteration: 1059; Percent complete: 26.5%; Average loss: 0.0126\n",
      "Iteration: 1060; Percent complete: 26.5%; Average loss: 0.0164\n",
      "Iteration: 1061; Percent complete: 26.5%; Average loss: 0.0131\n",
      "Iteration: 1062; Percent complete: 26.6%; Average loss: 0.0312\n",
      "Iteration: 1063; Percent complete: 26.6%; Average loss: 0.0345\n",
      "Iteration: 1064; Percent complete: 26.6%; Average loss: 0.0112\n",
      "Iteration: 1065; Percent complete: 26.6%; Average loss: 0.0136\n",
      "Iteration: 1066; Percent complete: 26.7%; Average loss: 0.0099\n",
      "Iteration: 1067; Percent complete: 26.7%; Average loss: 0.0103\n",
      "Iteration: 1068; Percent complete: 26.7%; Average loss: 0.0131\n",
      "Iteration: 1069; Percent complete: 26.7%; Average loss: 0.0151\n",
      "Iteration: 1070; Percent complete: 26.8%; Average loss: 0.0114\n",
      "Iteration: 1071; Percent complete: 26.8%; Average loss: 0.0090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1072; Percent complete: 26.8%; Average loss: 0.0202\n",
      "Iteration: 1073; Percent complete: 26.8%; Average loss: 0.0101\n",
      "Iteration: 1074; Percent complete: 26.9%; Average loss: 0.0307\n",
      "Iteration: 1075; Percent complete: 26.9%; Average loss: 0.0103\n",
      "Iteration: 1076; Percent complete: 26.9%; Average loss: 0.0180\n",
      "Iteration: 1077; Percent complete: 26.9%; Average loss: 0.0079\n",
      "Iteration: 1078; Percent complete: 27.0%; Average loss: 0.0083\n",
      "Iteration: 1079; Percent complete: 27.0%; Average loss: 0.0143\n",
      "Iteration: 1080; Percent complete: 27.0%; Average loss: 0.0130\n",
      "Iteration: 1081; Percent complete: 27.0%; Average loss: 0.0079\n",
      "Iteration: 1082; Percent complete: 27.1%; Average loss: 0.0085\n",
      "Iteration: 1083; Percent complete: 27.1%; Average loss: 0.0082\n",
      "Iteration: 1084; Percent complete: 27.1%; Average loss: 0.0084\n",
      "Iteration: 1085; Percent complete: 27.1%; Average loss: 0.0093\n",
      "Iteration: 1086; Percent complete: 27.2%; Average loss: 0.0109\n",
      "Iteration: 1087; Percent complete: 27.2%; Average loss: 0.0082\n",
      "Iteration: 1088; Percent complete: 27.2%; Average loss: 0.0082\n",
      "Iteration: 1089; Percent complete: 27.2%; Average loss: 0.0078\n",
      "Iteration: 1090; Percent complete: 27.3%; Average loss: 0.0064\n",
      "Iteration: 1091; Percent complete: 27.3%; Average loss: 0.0084\n",
      "Iteration: 1092; Percent complete: 27.3%; Average loss: 0.0074\n",
      "Iteration: 1093; Percent complete: 27.3%; Average loss: 0.0088\n",
      "Iteration: 1094; Percent complete: 27.4%; Average loss: 0.0068\n",
      "Iteration: 1095; Percent complete: 27.4%; Average loss: 0.0068\n",
      "Iteration: 1096; Percent complete: 27.4%; Average loss: 0.0077\n",
      "Iteration: 1097; Percent complete: 27.4%; Average loss: 0.0079\n",
      "Iteration: 1098; Percent complete: 27.5%; Average loss: 0.0070\n",
      "Iteration: 1099; Percent complete: 27.5%; Average loss: 0.0073\n",
      "Iteration: 1100; Percent complete: 27.5%; Average loss: 0.0080\n",
      "Iteration: 1101; Percent complete: 27.5%; Average loss: 0.0071\n",
      "Iteration: 1102; Percent complete: 27.6%; Average loss: 0.0075\n",
      "Iteration: 1103; Percent complete: 27.6%; Average loss: 0.0079\n",
      "Iteration: 1104; Percent complete: 27.6%; Average loss: 0.0061\n",
      "Iteration: 1105; Percent complete: 27.6%; Average loss: 0.0063\n",
      "Iteration: 1106; Percent complete: 27.7%; Average loss: 0.0065\n",
      "Iteration: 1107; Percent complete: 27.7%; Average loss: 0.0064\n",
      "Iteration: 1108; Percent complete: 27.7%; Average loss: 0.0063\n",
      "Iteration: 1109; Percent complete: 27.7%; Average loss: 0.0072\n",
      "Iteration: 1110; Percent complete: 27.8%; Average loss: 0.0064\n",
      "Iteration: 1111; Percent complete: 27.8%; Average loss: 0.0070\n",
      "Iteration: 1112; Percent complete: 27.8%; Average loss: 0.0068\n",
      "Iteration: 1113; Percent complete: 27.8%; Average loss: 0.0067\n",
      "Iteration: 1114; Percent complete: 27.9%; Average loss: 0.0063\n",
      "Iteration: 1115; Percent complete: 27.9%; Average loss: 0.0062\n",
      "Iteration: 1116; Percent complete: 27.9%; Average loss: 0.0065\n",
      "Iteration: 1117; Percent complete: 27.9%; Average loss: 0.0066\n",
      "Iteration: 1118; Percent complete: 28.0%; Average loss: 0.0066\n",
      "Iteration: 1119; Percent complete: 28.0%; Average loss: 0.0071\n",
      "Iteration: 1120; Percent complete: 28.0%; Average loss: 0.0063\n",
      "Iteration: 1121; Percent complete: 28.0%; Average loss: 0.0067\n",
      "Iteration: 1122; Percent complete: 28.1%; Average loss: 0.0056\n",
      "Iteration: 1123; Percent complete: 28.1%; Average loss: 0.0068\n",
      "Iteration: 1124; Percent complete: 28.1%; Average loss: 0.0056\n",
      "Iteration: 1125; Percent complete: 28.1%; Average loss: 0.0059\n",
      "Iteration: 1126; Percent complete: 28.1%; Average loss: 0.0064\n",
      "Iteration: 1127; Percent complete: 28.2%; Average loss: 0.0057\n",
      "Iteration: 1128; Percent complete: 28.2%; Average loss: 0.0049\n",
      "Iteration: 1129; Percent complete: 28.2%; Average loss: 0.0058\n",
      "Iteration: 1130; Percent complete: 28.2%; Average loss: 0.0058\n",
      "Iteration: 1131; Percent complete: 28.3%; Average loss: 0.0059\n",
      "Iteration: 1132; Percent complete: 28.3%; Average loss: 0.0056\n",
      "Iteration: 1133; Percent complete: 28.3%; Average loss: 0.0065\n",
      "Iteration: 1134; Percent complete: 28.3%; Average loss: 0.0057\n",
      "Iteration: 1135; Percent complete: 28.4%; Average loss: 0.0056\n",
      "Iteration: 1136; Percent complete: 28.4%; Average loss: 0.0054\n",
      "Iteration: 1137; Percent complete: 28.4%; Average loss: 0.0057\n",
      "Iteration: 1138; Percent complete: 28.4%; Average loss: 0.0059\n",
      "Iteration: 1139; Percent complete: 28.5%; Average loss: 0.0061\n",
      "Iteration: 1140; Percent complete: 28.5%; Average loss: 0.0054\n",
      "Iteration: 1141; Percent complete: 28.5%; Average loss: 0.0057\n",
      "Iteration: 1142; Percent complete: 28.5%; Average loss: 0.0064\n",
      "Iteration: 1143; Percent complete: 28.6%; Average loss: 0.0060\n",
      "Iteration: 1144; Percent complete: 28.6%; Average loss: 0.0056\n",
      "Iteration: 1145; Percent complete: 28.6%; Average loss: 0.0051\n",
      "Iteration: 1146; Percent complete: 28.6%; Average loss: 0.0048\n",
      "Iteration: 1147; Percent complete: 28.7%; Average loss: 0.0055\n",
      "Iteration: 1148; Percent complete: 28.7%; Average loss: 0.0052\n",
      "Iteration: 1149; Percent complete: 28.7%; Average loss: 0.0052\n",
      "Iteration: 1150; Percent complete: 28.7%; Average loss: 0.0055\n",
      "Iteration: 1151; Percent complete: 28.8%; Average loss: 0.0051\n",
      "Iteration: 1152; Percent complete: 28.8%; Average loss: 0.0055\n",
      "Iteration: 1153; Percent complete: 28.8%; Average loss: 0.0055\n",
      "Iteration: 1154; Percent complete: 28.8%; Average loss: 0.0053\n",
      "Iteration: 1155; Percent complete: 28.9%; Average loss: 0.0055\n",
      "Iteration: 1156; Percent complete: 28.9%; Average loss: 0.0053\n",
      "Iteration: 1157; Percent complete: 28.9%; Average loss: 0.0054\n",
      "Iteration: 1158; Percent complete: 28.9%; Average loss: 0.0052\n",
      "Iteration: 1159; Percent complete: 29.0%; Average loss: 0.0050\n",
      "Iteration: 1160; Percent complete: 29.0%; Average loss: 0.0049\n",
      "Iteration: 1161; Percent complete: 29.0%; Average loss: 0.0057\n",
      "Iteration: 1162; Percent complete: 29.0%; Average loss: 0.0050\n",
      "Iteration: 1163; Percent complete: 29.1%; Average loss: 0.0047\n",
      "Iteration: 1164; Percent complete: 29.1%; Average loss: 0.0056\n",
      "Iteration: 1165; Percent complete: 29.1%; Average loss: 0.0057\n",
      "Iteration: 1166; Percent complete: 29.1%; Average loss: 0.0060\n",
      "Iteration: 1167; Percent complete: 29.2%; Average loss: 0.0049\n",
      "Iteration: 1168; Percent complete: 29.2%; Average loss: 0.0051\n",
      "Iteration: 1169; Percent complete: 29.2%; Average loss: 0.0055\n",
      "Iteration: 1170; Percent complete: 29.2%; Average loss: 0.0050\n",
      "Iteration: 1171; Percent complete: 29.3%; Average loss: 0.0053\n",
      "Iteration: 1172; Percent complete: 29.3%; Average loss: 0.0052\n",
      "Iteration: 1173; Percent complete: 29.3%; Average loss: 0.0052\n",
      "Iteration: 1174; Percent complete: 29.3%; Average loss: 0.0052\n",
      "Iteration: 1175; Percent complete: 29.4%; Average loss: 0.0052\n",
      "Iteration: 1176; Percent complete: 29.4%; Average loss: 0.0044\n",
      "Iteration: 1177; Percent complete: 29.4%; Average loss: 0.0047\n",
      "Iteration: 1178; Percent complete: 29.4%; Average loss: 0.0048\n",
      "Iteration: 1179; Percent complete: 29.5%; Average loss: 0.0053\n",
      "Iteration: 1180; Percent complete: 29.5%; Average loss: 0.0053\n",
      "Iteration: 1181; Percent complete: 29.5%; Average loss: 0.0045\n",
      "Iteration: 1182; Percent complete: 29.5%; Average loss: 0.0053\n",
      "Iteration: 1183; Percent complete: 29.6%; Average loss: 0.0046\n",
      "Iteration: 1184; Percent complete: 29.6%; Average loss: 0.0048\n",
      "Iteration: 1185; Percent complete: 29.6%; Average loss: 0.0044\n",
      "Iteration: 1186; Percent complete: 29.6%; Average loss: 0.0049\n",
      "Iteration: 1187; Percent complete: 29.7%; Average loss: 0.0049\n",
      "Iteration: 1188; Percent complete: 29.7%; Average loss: 0.0047\n",
      "Iteration: 1189; Percent complete: 29.7%; Average loss: 0.0047\n",
      "Iteration: 1190; Percent complete: 29.8%; Average loss: 0.0045\n",
      "Iteration: 1191; Percent complete: 29.8%; Average loss: 0.0052\n",
      "Iteration: 1192; Percent complete: 29.8%; Average loss: 0.0044\n",
      "Iteration: 1193; Percent complete: 29.8%; Average loss: 0.0050\n",
      "Iteration: 1194; Percent complete: 29.8%; Average loss: 0.0052\n",
      "Iteration: 1195; Percent complete: 29.9%; Average loss: 0.0041\n",
      "Iteration: 1196; Percent complete: 29.9%; Average loss: 0.0044\n",
      "Iteration: 1197; Percent complete: 29.9%; Average loss: 0.0048\n",
      "Iteration: 1198; Percent complete: 29.9%; Average loss: 0.0051\n",
      "Iteration: 1199; Percent complete: 30.0%; Average loss: 0.0050\n",
      "Iteration: 1200; Percent complete: 30.0%; Average loss: 0.0048\n",
      "Iteration: 1201; Percent complete: 30.0%; Average loss: 0.0044\n",
      "Iteration: 1202; Percent complete: 30.0%; Average loss: 0.0040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1203; Percent complete: 30.1%; Average loss: 0.0043\n",
      "Iteration: 1204; Percent complete: 30.1%; Average loss: 0.0041\n",
      "Iteration: 1205; Percent complete: 30.1%; Average loss: 0.0045\n",
      "Iteration: 1206; Percent complete: 30.1%; Average loss: 0.0043\n",
      "Iteration: 1207; Percent complete: 30.2%; Average loss: 0.0046\n",
      "Iteration: 1208; Percent complete: 30.2%; Average loss: 0.0046\n",
      "Iteration: 1209; Percent complete: 30.2%; Average loss: 0.0044\n",
      "Iteration: 1210; Percent complete: 30.2%; Average loss: 0.0050\n",
      "Iteration: 1211; Percent complete: 30.3%; Average loss: 0.0047\n",
      "Iteration: 1212; Percent complete: 30.3%; Average loss: 0.0044\n",
      "Iteration: 1213; Percent complete: 30.3%; Average loss: 0.0046\n",
      "Iteration: 1214; Percent complete: 30.3%; Average loss: 0.0044\n",
      "Iteration: 1215; Percent complete: 30.4%; Average loss: 0.0046\n",
      "Iteration: 1216; Percent complete: 30.4%; Average loss: 0.0043\n",
      "Iteration: 1217; Percent complete: 30.4%; Average loss: 0.0043\n",
      "Iteration: 1218; Percent complete: 30.4%; Average loss: 0.0041\n",
      "Iteration: 1219; Percent complete: 30.5%; Average loss: 0.0044\n",
      "Iteration: 1220; Percent complete: 30.5%; Average loss: 0.0049\n",
      "Iteration: 1221; Percent complete: 30.5%; Average loss: 0.0041\n",
      "Iteration: 1222; Percent complete: 30.6%; Average loss: 0.0045\n",
      "Iteration: 1223; Percent complete: 30.6%; Average loss: 0.0043\n",
      "Iteration: 1224; Percent complete: 30.6%; Average loss: 0.0045\n",
      "Iteration: 1225; Percent complete: 30.6%; Average loss: 0.0042\n",
      "Iteration: 1226; Percent complete: 30.6%; Average loss: 0.0044\n",
      "Iteration: 1227; Percent complete: 30.7%; Average loss: 0.0043\n",
      "Iteration: 1228; Percent complete: 30.7%; Average loss: 0.0044\n",
      "Iteration: 1229; Percent complete: 30.7%; Average loss: 0.0043\n",
      "Iteration: 1230; Percent complete: 30.8%; Average loss: 0.0040\n",
      "Iteration: 1231; Percent complete: 30.8%; Average loss: 0.0043\n",
      "Iteration: 1232; Percent complete: 30.8%; Average loss: 0.0039\n",
      "Iteration: 1233; Percent complete: 30.8%; Average loss: 0.0043\n",
      "Iteration: 1234; Percent complete: 30.9%; Average loss: 0.0039\n",
      "Iteration: 1235; Percent complete: 30.9%; Average loss: 0.0043\n",
      "Iteration: 1236; Percent complete: 30.9%; Average loss: 0.0041\n",
      "Iteration: 1237; Percent complete: 30.9%; Average loss: 0.0045\n",
      "Iteration: 1238; Percent complete: 30.9%; Average loss: 0.0039\n",
      "Iteration: 1239; Percent complete: 31.0%; Average loss: 0.0044\n",
      "Iteration: 1240; Percent complete: 31.0%; Average loss: 0.0040\n",
      "Iteration: 1241; Percent complete: 31.0%; Average loss: 0.0044\n",
      "Iteration: 1242; Percent complete: 31.1%; Average loss: 0.0038\n",
      "Iteration: 1243; Percent complete: 31.1%; Average loss: 0.0042\n",
      "Iteration: 1244; Percent complete: 31.1%; Average loss: 0.0044\n",
      "Iteration: 1245; Percent complete: 31.1%; Average loss: 0.0044\n",
      "Iteration: 1246; Percent complete: 31.1%; Average loss: 0.0036\n",
      "Iteration: 1247; Percent complete: 31.2%; Average loss: 0.0040\n",
      "Iteration: 1248; Percent complete: 31.2%; Average loss: 0.0046\n",
      "Iteration: 1249; Percent complete: 31.2%; Average loss: 0.0042\n",
      "Iteration: 1250; Percent complete: 31.2%; Average loss: 0.0044\n",
      "Iteration: 1251; Percent complete: 31.3%; Average loss: 0.0040\n",
      "Iteration: 1252; Percent complete: 31.3%; Average loss: 0.0041\n",
      "Iteration: 1253; Percent complete: 31.3%; Average loss: 0.0038\n",
      "Iteration: 1254; Percent complete: 31.4%; Average loss: 0.0039\n",
      "Iteration: 1255; Percent complete: 31.4%; Average loss: 0.0042\n",
      "Iteration: 1256; Percent complete: 31.4%; Average loss: 0.0040\n",
      "Iteration: 1257; Percent complete: 31.4%; Average loss: 0.0038\n",
      "Iteration: 1258; Percent complete: 31.4%; Average loss: 0.0043\n",
      "Iteration: 1259; Percent complete: 31.5%; Average loss: 0.0042\n",
      "Iteration: 1260; Percent complete: 31.5%; Average loss: 0.0037\n",
      "Iteration: 1261; Percent complete: 31.5%; Average loss: 0.0037\n",
      "Iteration: 1262; Percent complete: 31.6%; Average loss: 0.0041\n",
      "Iteration: 1263; Percent complete: 31.6%; Average loss: 0.0037\n",
      "Iteration: 1264; Percent complete: 31.6%; Average loss: 0.0035\n",
      "Iteration: 1265; Percent complete: 31.6%; Average loss: 0.0039\n",
      "Iteration: 1266; Percent complete: 31.6%; Average loss: 0.0040\n",
      "Iteration: 1267; Percent complete: 31.7%; Average loss: 0.0035\n",
      "Iteration: 1268; Percent complete: 31.7%; Average loss: 0.0037\n",
      "Iteration: 1269; Percent complete: 31.7%; Average loss: 0.0038\n",
      "Iteration: 1270; Percent complete: 31.8%; Average loss: 0.0037\n",
      "Iteration: 1271; Percent complete: 31.8%; Average loss: 0.0041\n",
      "Iteration: 1272; Percent complete: 31.8%; Average loss: 0.0043\n",
      "Iteration: 1273; Percent complete: 31.8%; Average loss: 0.0037\n",
      "Iteration: 1274; Percent complete: 31.9%; Average loss: 0.0038\n",
      "Iteration: 1275; Percent complete: 31.9%; Average loss: 0.0035\n",
      "Iteration: 1276; Percent complete: 31.9%; Average loss: 0.0038\n",
      "Iteration: 1277; Percent complete: 31.9%; Average loss: 0.0039\n",
      "Iteration: 1278; Percent complete: 31.9%; Average loss: 0.0038\n",
      "Iteration: 1279; Percent complete: 32.0%; Average loss: 0.0039\n",
      "Iteration: 1280; Percent complete: 32.0%; Average loss: 0.0038\n",
      "Iteration: 1281; Percent complete: 32.0%; Average loss: 0.0040\n",
      "Iteration: 1282; Percent complete: 32.0%; Average loss: 0.0041\n",
      "Iteration: 1283; Percent complete: 32.1%; Average loss: 0.0042\n",
      "Iteration: 1284; Percent complete: 32.1%; Average loss: 0.0037\n",
      "Iteration: 1285; Percent complete: 32.1%; Average loss: 0.0040\n",
      "Iteration: 1286; Percent complete: 32.1%; Average loss: 0.0034\n",
      "Iteration: 1287; Percent complete: 32.2%; Average loss: 0.0039\n",
      "Iteration: 1288; Percent complete: 32.2%; Average loss: 0.0036\n",
      "Iteration: 1289; Percent complete: 32.2%; Average loss: 0.0036\n",
      "Iteration: 1290; Percent complete: 32.2%; Average loss: 0.0039\n",
      "Iteration: 1291; Percent complete: 32.3%; Average loss: 0.0038\n",
      "Iteration: 1292; Percent complete: 32.3%; Average loss: 0.0041\n",
      "Iteration: 1293; Percent complete: 32.3%; Average loss: 0.0034\n",
      "Iteration: 1294; Percent complete: 32.4%; Average loss: 0.0033\n",
      "Iteration: 1295; Percent complete: 32.4%; Average loss: 0.0037\n",
      "Iteration: 1296; Percent complete: 32.4%; Average loss: 0.0037\n",
      "Iteration: 1297; Percent complete: 32.4%; Average loss: 0.0038\n",
      "Iteration: 1298; Percent complete: 32.5%; Average loss: 0.0039\n",
      "Iteration: 1299; Percent complete: 32.5%; Average loss: 0.0037\n",
      "Iteration: 1300; Percent complete: 32.5%; Average loss: 0.0038\n",
      "Iteration: 1301; Percent complete: 32.5%; Average loss: 0.0036\n",
      "Iteration: 1302; Percent complete: 32.6%; Average loss: 0.0036\n",
      "Iteration: 1303; Percent complete: 32.6%; Average loss: 0.0036\n",
      "Iteration: 1304; Percent complete: 32.6%; Average loss: 0.0035\n",
      "Iteration: 1305; Percent complete: 32.6%; Average loss: 0.0036\n",
      "Iteration: 1306; Percent complete: 32.6%; Average loss: 0.0037\n",
      "Iteration: 1307; Percent complete: 32.7%; Average loss: 0.0035\n",
      "Iteration: 1308; Percent complete: 32.7%; Average loss: 0.0035\n",
      "Iteration: 1309; Percent complete: 32.7%; Average loss: 0.0036\n",
      "Iteration: 1310; Percent complete: 32.8%; Average loss: 0.0039\n",
      "Iteration: 1311; Percent complete: 32.8%; Average loss: 0.0036\n",
      "Iteration: 1312; Percent complete: 32.8%; Average loss: 0.0035\n",
      "Iteration: 1313; Percent complete: 32.8%; Average loss: 0.0039\n",
      "Iteration: 1314; Percent complete: 32.9%; Average loss: 0.0037\n",
      "Iteration: 1315; Percent complete: 32.9%; Average loss: 0.0036\n",
      "Iteration: 1316; Percent complete: 32.9%; Average loss: 0.0033\n",
      "Iteration: 1317; Percent complete: 32.9%; Average loss: 0.0034\n",
      "Iteration: 1318; Percent complete: 33.0%; Average loss: 0.0033\n",
      "Iteration: 1319; Percent complete: 33.0%; Average loss: 0.0034\n",
      "Iteration: 1320; Percent complete: 33.0%; Average loss: 0.0037\n",
      "Iteration: 1321; Percent complete: 33.0%; Average loss: 0.0037\n",
      "Iteration: 1322; Percent complete: 33.1%; Average loss: 0.0035\n",
      "Iteration: 1323; Percent complete: 33.1%; Average loss: 0.0031\n",
      "Iteration: 1324; Percent complete: 33.1%; Average loss: 0.0037\n",
      "Iteration: 1325; Percent complete: 33.1%; Average loss: 0.0035\n",
      "Iteration: 1326; Percent complete: 33.1%; Average loss: 0.0033\n",
      "Iteration: 1327; Percent complete: 33.2%; Average loss: 0.0032\n",
      "Iteration: 1328; Percent complete: 33.2%; Average loss: 0.0037\n",
      "Iteration: 1329; Percent complete: 33.2%; Average loss: 0.0029\n",
      "Iteration: 1330; Percent complete: 33.2%; Average loss: 0.0033\n",
      "Iteration: 1331; Percent complete: 33.3%; Average loss: 0.0034\n",
      "Iteration: 1332; Percent complete: 33.3%; Average loss: 0.0032\n",
      "Iteration: 1333; Percent complete: 33.3%; Average loss: 0.0033\n",
      "Iteration: 1334; Percent complete: 33.4%; Average loss: 0.0034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1335; Percent complete: 33.4%; Average loss: 0.0030\n",
      "Iteration: 1336; Percent complete: 33.4%; Average loss: 0.0031\n",
      "Iteration: 1337; Percent complete: 33.4%; Average loss: 0.0032\n",
      "Iteration: 1338; Percent complete: 33.5%; Average loss: 0.0033\n",
      "Iteration: 1339; Percent complete: 33.5%; Average loss: 0.0032\n",
      "Iteration: 1340; Percent complete: 33.5%; Average loss: 0.0034\n",
      "Iteration: 1341; Percent complete: 33.5%; Average loss: 0.0033\n",
      "Iteration: 1342; Percent complete: 33.6%; Average loss: 0.0032\n",
      "Iteration: 1343; Percent complete: 33.6%; Average loss: 0.0032\n",
      "Iteration: 1344; Percent complete: 33.6%; Average loss: 0.0032\n",
      "Iteration: 1345; Percent complete: 33.6%; Average loss: 0.0030\n",
      "Iteration: 1346; Percent complete: 33.7%; Average loss: 0.0034\n",
      "Iteration: 1347; Percent complete: 33.7%; Average loss: 0.0032\n",
      "Iteration: 1348; Percent complete: 33.7%; Average loss: 0.0034\n",
      "Iteration: 1349; Percent complete: 33.7%; Average loss: 0.0036\n",
      "Iteration: 1350; Percent complete: 33.8%; Average loss: 0.0031\n",
      "Iteration: 1351; Percent complete: 33.8%; Average loss: 0.0033\n",
      "Iteration: 1352; Percent complete: 33.8%; Average loss: 0.0034\n",
      "Iteration: 1353; Percent complete: 33.8%; Average loss: 0.0032\n",
      "Iteration: 1354; Percent complete: 33.9%; Average loss: 0.0035\n",
      "Iteration: 1355; Percent complete: 33.9%; Average loss: 0.0035\n",
      "Iteration: 1356; Percent complete: 33.9%; Average loss: 0.0034\n",
      "Iteration: 1357; Percent complete: 33.9%; Average loss: 0.0032\n",
      "Iteration: 1358; Percent complete: 34.0%; Average loss: 0.0033\n",
      "Iteration: 1359; Percent complete: 34.0%; Average loss: 0.0033\n",
      "Iteration: 1360; Percent complete: 34.0%; Average loss: 0.0032\n",
      "Iteration: 1361; Percent complete: 34.0%; Average loss: 0.0031\n",
      "Iteration: 1362; Percent complete: 34.1%; Average loss: 0.0033\n",
      "Iteration: 1363; Percent complete: 34.1%; Average loss: 0.0032\n",
      "Iteration: 1364; Percent complete: 34.1%; Average loss: 0.0033\n",
      "Iteration: 1365; Percent complete: 34.1%; Average loss: 0.0033\n",
      "Iteration: 1366; Percent complete: 34.2%; Average loss: 0.0033\n",
      "Iteration: 1367; Percent complete: 34.2%; Average loss: 0.0028\n",
      "Iteration: 1368; Percent complete: 34.2%; Average loss: 0.0030\n",
      "Iteration: 1369; Percent complete: 34.2%; Average loss: 0.0031\n",
      "Iteration: 1370; Percent complete: 34.2%; Average loss: 0.0035\n",
      "Iteration: 1371; Percent complete: 34.3%; Average loss: 0.0032\n",
      "Iteration: 1372; Percent complete: 34.3%; Average loss: 0.0034\n",
      "Iteration: 1373; Percent complete: 34.3%; Average loss: 0.0032\n",
      "Iteration: 1374; Percent complete: 34.4%; Average loss: 0.0033\n",
      "Iteration: 1375; Percent complete: 34.4%; Average loss: 0.0031\n",
      "Iteration: 1376; Percent complete: 34.4%; Average loss: 0.0032\n",
      "Iteration: 1377; Percent complete: 34.4%; Average loss: 0.0033\n",
      "Iteration: 1378; Percent complete: 34.4%; Average loss: 0.0033\n",
      "Iteration: 1379; Percent complete: 34.5%; Average loss: 0.0029\n",
      "Iteration: 1380; Percent complete: 34.5%; Average loss: 0.0033\n",
      "Iteration: 1381; Percent complete: 34.5%; Average loss: 0.0033\n",
      "Iteration: 1382; Percent complete: 34.5%; Average loss: 0.0029\n",
      "Iteration: 1383; Percent complete: 34.6%; Average loss: 0.0029\n",
      "Iteration: 1384; Percent complete: 34.6%; Average loss: 0.0033\n",
      "Iteration: 1385; Percent complete: 34.6%; Average loss: 0.0030\n",
      "Iteration: 1386; Percent complete: 34.6%; Average loss: 0.0030\n",
      "Iteration: 1387; Percent complete: 34.7%; Average loss: 0.0026\n",
      "Iteration: 1388; Percent complete: 34.7%; Average loss: 0.0032\n",
      "Iteration: 1389; Percent complete: 34.7%; Average loss: 0.0028\n",
      "Iteration: 1390; Percent complete: 34.8%; Average loss: 0.0034\n",
      "Iteration: 1391; Percent complete: 34.8%; Average loss: 0.0034\n",
      "Iteration: 1392; Percent complete: 34.8%; Average loss: 0.0031\n",
      "Iteration: 1393; Percent complete: 34.8%; Average loss: 0.0029\n",
      "Iteration: 1394; Percent complete: 34.8%; Average loss: 0.0029\n",
      "Iteration: 1395; Percent complete: 34.9%; Average loss: 0.0031\n",
      "Iteration: 1396; Percent complete: 34.9%; Average loss: 0.0031\n",
      "Iteration: 1397; Percent complete: 34.9%; Average loss: 0.0032\n",
      "Iteration: 1398; Percent complete: 34.9%; Average loss: 0.0030\n",
      "Iteration: 1399; Percent complete: 35.0%; Average loss: 0.0032\n",
      "Iteration: 1400; Percent complete: 35.0%; Average loss: 0.0030\n",
      "Iteration: 1401; Percent complete: 35.0%; Average loss: 0.0028\n",
      "Iteration: 1402; Percent complete: 35.0%; Average loss: 0.0029\n",
      "Iteration: 1403; Percent complete: 35.1%; Average loss: 0.0030\n",
      "Iteration: 1404; Percent complete: 35.1%; Average loss: 0.0029\n",
      "Iteration: 1405; Percent complete: 35.1%; Average loss: 0.0029\n",
      "Iteration: 1406; Percent complete: 35.1%; Average loss: 0.0027\n",
      "Iteration: 1407; Percent complete: 35.2%; Average loss: 0.0028\n",
      "Iteration: 1408; Percent complete: 35.2%; Average loss: 0.0028\n",
      "Iteration: 1409; Percent complete: 35.2%; Average loss: 0.0029\n",
      "Iteration: 1410; Percent complete: 35.2%; Average loss: 0.0029\n",
      "Iteration: 1411; Percent complete: 35.3%; Average loss: 0.0029\n",
      "Iteration: 1412; Percent complete: 35.3%; Average loss: 0.0030\n",
      "Iteration: 1413; Percent complete: 35.3%; Average loss: 0.0032\n",
      "Iteration: 1414; Percent complete: 35.4%; Average loss: 0.0032\n",
      "Iteration: 1415; Percent complete: 35.4%; Average loss: 0.0029\n",
      "Iteration: 1416; Percent complete: 35.4%; Average loss: 0.0030\n",
      "Iteration: 1417; Percent complete: 35.4%; Average loss: 0.0027\n",
      "Iteration: 1418; Percent complete: 35.4%; Average loss: 0.0030\n",
      "Iteration: 1419; Percent complete: 35.5%; Average loss: 0.0029\n",
      "Iteration: 1420; Percent complete: 35.5%; Average loss: 0.0030\n",
      "Iteration: 1421; Percent complete: 35.5%; Average loss: 0.0027\n",
      "Iteration: 1422; Percent complete: 35.5%; Average loss: 0.0031\n",
      "Iteration: 1423; Percent complete: 35.6%; Average loss: 0.0028\n",
      "Iteration: 1424; Percent complete: 35.6%; Average loss: 0.0029\n",
      "Iteration: 1425; Percent complete: 35.6%; Average loss: 0.0028\n",
      "Iteration: 1426; Percent complete: 35.6%; Average loss: 0.0028\n",
      "Iteration: 1427; Percent complete: 35.7%; Average loss: 0.0027\n",
      "Iteration: 1428; Percent complete: 35.7%; Average loss: 0.0029\n",
      "Iteration: 1429; Percent complete: 35.7%; Average loss: 0.0030\n",
      "Iteration: 1430; Percent complete: 35.8%; Average loss: 0.0028\n",
      "Iteration: 1431; Percent complete: 35.8%; Average loss: 0.0028\n",
      "Iteration: 1432; Percent complete: 35.8%; Average loss: 0.0030\n",
      "Iteration: 1433; Percent complete: 35.8%; Average loss: 0.0029\n",
      "Iteration: 1434; Percent complete: 35.9%; Average loss: 0.0026\n",
      "Iteration: 1435; Percent complete: 35.9%; Average loss: 0.0031\n",
      "Iteration: 1436; Percent complete: 35.9%; Average loss: 0.0027\n",
      "Iteration: 1437; Percent complete: 35.9%; Average loss: 0.0027\n",
      "Iteration: 1438; Percent complete: 35.9%; Average loss: 0.0027\n",
      "Iteration: 1439; Percent complete: 36.0%; Average loss: 0.0030\n",
      "Iteration: 1440; Percent complete: 36.0%; Average loss: 0.0028\n",
      "Iteration: 1441; Percent complete: 36.0%; Average loss: 0.0028\n",
      "Iteration: 1442; Percent complete: 36.0%; Average loss: 0.0025\n",
      "Iteration: 1443; Percent complete: 36.1%; Average loss: 0.0027\n",
      "Iteration: 1444; Percent complete: 36.1%; Average loss: 0.0027\n",
      "Iteration: 1445; Percent complete: 36.1%; Average loss: 0.0028\n",
      "Iteration: 1446; Percent complete: 36.1%; Average loss: 0.0030\n",
      "Iteration: 1447; Percent complete: 36.2%; Average loss: 0.0029\n",
      "Iteration: 1448; Percent complete: 36.2%; Average loss: 0.0029\n",
      "Iteration: 1449; Percent complete: 36.2%; Average loss: 0.0027\n",
      "Iteration: 1450; Percent complete: 36.2%; Average loss: 0.0026\n",
      "Iteration: 1451; Percent complete: 36.3%; Average loss: 0.0028\n",
      "Iteration: 1452; Percent complete: 36.3%; Average loss: 0.0027\n",
      "Iteration: 1453; Percent complete: 36.3%; Average loss: 0.0029\n",
      "Iteration: 1454; Percent complete: 36.4%; Average loss: 0.0026\n",
      "Iteration: 1455; Percent complete: 36.4%; Average loss: 0.0029\n",
      "Iteration: 1456; Percent complete: 36.4%; Average loss: 0.0026\n",
      "Iteration: 1457; Percent complete: 36.4%; Average loss: 0.0029\n",
      "Iteration: 1458; Percent complete: 36.4%; Average loss: 0.0027\n",
      "Iteration: 1459; Percent complete: 36.5%; Average loss: 0.0029\n",
      "Iteration: 1460; Percent complete: 36.5%; Average loss: 0.0026\n",
      "Iteration: 1461; Percent complete: 36.5%; Average loss: 0.0027\n",
      "Iteration: 1462; Percent complete: 36.5%; Average loss: 0.0029\n",
      "Iteration: 1463; Percent complete: 36.6%; Average loss: 0.0027\n",
      "Iteration: 1464; Percent complete: 36.6%; Average loss: 0.0029\n",
      "Iteration: 1465; Percent complete: 36.6%; Average loss: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1466; Percent complete: 36.6%; Average loss: 0.0026\n",
      "Iteration: 1467; Percent complete: 36.7%; Average loss: 0.0026\n",
      "Iteration: 1468; Percent complete: 36.7%; Average loss: 0.0027\n",
      "Iteration: 1469; Percent complete: 36.7%; Average loss: 0.0025\n",
      "Iteration: 1470; Percent complete: 36.8%; Average loss: 0.0029\n",
      "Iteration: 1471; Percent complete: 36.8%; Average loss: 0.0028\n",
      "Iteration: 1472; Percent complete: 36.8%; Average loss: 0.0029\n",
      "Iteration: 1473; Percent complete: 36.8%; Average loss: 0.0024\n",
      "Iteration: 1474; Percent complete: 36.9%; Average loss: 0.0027\n",
      "Iteration: 1475; Percent complete: 36.9%; Average loss: 0.0028\n",
      "Iteration: 1476; Percent complete: 36.9%; Average loss: 0.0026\n",
      "Iteration: 1477; Percent complete: 36.9%; Average loss: 0.0032\n",
      "Iteration: 1478; Percent complete: 37.0%; Average loss: 0.0026\n",
      "Iteration: 1479; Percent complete: 37.0%; Average loss: 0.0024\n",
      "Iteration: 1480; Percent complete: 37.0%; Average loss: 0.0027\n",
      "Iteration: 1481; Percent complete: 37.0%; Average loss: 0.0030\n",
      "Iteration: 1482; Percent complete: 37.0%; Average loss: 0.0026\n",
      "Iteration: 1483; Percent complete: 37.1%; Average loss: 0.0024\n",
      "Iteration: 1484; Percent complete: 37.1%; Average loss: 0.0025\n",
      "Iteration: 1485; Percent complete: 37.1%; Average loss: 0.0024\n",
      "Iteration: 1486; Percent complete: 37.1%; Average loss: 0.0028\n",
      "Iteration: 1487; Percent complete: 37.2%; Average loss: 0.0025\n",
      "Iteration: 1488; Percent complete: 37.2%; Average loss: 0.0027\n",
      "Iteration: 1489; Percent complete: 37.2%; Average loss: 0.0027\n",
      "Iteration: 1490; Percent complete: 37.2%; Average loss: 0.0027\n",
      "Iteration: 1491; Percent complete: 37.3%; Average loss: 0.0028\n",
      "Iteration: 1492; Percent complete: 37.3%; Average loss: 0.0025\n",
      "Iteration: 1493; Percent complete: 37.3%; Average loss: 0.0025\n",
      "Iteration: 1494; Percent complete: 37.4%; Average loss: 0.0027\n",
      "Iteration: 1495; Percent complete: 37.4%; Average loss: 0.0026\n",
      "Iteration: 1496; Percent complete: 37.4%; Average loss: 0.0028\n",
      "Iteration: 1497; Percent complete: 37.4%; Average loss: 0.0025\n",
      "Iteration: 1498; Percent complete: 37.5%; Average loss: 0.0027\n",
      "Iteration: 1499; Percent complete: 37.5%; Average loss: 0.0026\n",
      "Iteration: 1500; Percent complete: 37.5%; Average loss: 0.0025\n",
      "Iteration: 1501; Percent complete: 37.5%; Average loss: 0.0025\n",
      "Iteration: 1502; Percent complete: 37.5%; Average loss: 0.0024\n",
      "Iteration: 1503; Percent complete: 37.6%; Average loss: 0.0025\n",
      "Iteration: 1504; Percent complete: 37.6%; Average loss: 0.0023\n",
      "Iteration: 1505; Percent complete: 37.6%; Average loss: 0.0025\n",
      "Iteration: 1506; Percent complete: 37.6%; Average loss: 0.0025\n",
      "Iteration: 1507; Percent complete: 37.7%; Average loss: 0.0025\n",
      "Iteration: 1508; Percent complete: 37.7%; Average loss: 0.0025\n",
      "Iteration: 1509; Percent complete: 37.7%; Average loss: 0.0025\n",
      "Iteration: 1510; Percent complete: 37.8%; Average loss: 0.0024\n",
      "Iteration: 1511; Percent complete: 37.8%; Average loss: 0.0025\n",
      "Iteration: 1512; Percent complete: 37.8%; Average loss: 0.0026\n",
      "Iteration: 1513; Percent complete: 37.8%; Average loss: 0.0027\n",
      "Iteration: 1514; Percent complete: 37.9%; Average loss: 0.0023\n",
      "Iteration: 1515; Percent complete: 37.9%; Average loss: 0.0025\n",
      "Iteration: 1516; Percent complete: 37.9%; Average loss: 0.0025\n",
      "Iteration: 1517; Percent complete: 37.9%; Average loss: 0.0025\n",
      "Iteration: 1518; Percent complete: 38.0%; Average loss: 0.0025\n",
      "Iteration: 1519; Percent complete: 38.0%; Average loss: 0.0025\n",
      "Iteration: 1520; Percent complete: 38.0%; Average loss: 0.0023\n",
      "Iteration: 1521; Percent complete: 38.0%; Average loss: 0.0024\n",
      "Iteration: 1522; Percent complete: 38.0%; Average loss: 0.0023\n",
      "Iteration: 1523; Percent complete: 38.1%; Average loss: 0.0026\n",
      "Iteration: 1524; Percent complete: 38.1%; Average loss: 0.0024\n",
      "Iteration: 1525; Percent complete: 38.1%; Average loss: 0.0026\n",
      "Iteration: 1526; Percent complete: 38.1%; Average loss: 0.0024\n",
      "Iteration: 1527; Percent complete: 38.2%; Average loss: 0.0025\n",
      "Iteration: 1528; Percent complete: 38.2%; Average loss: 0.0025\n",
      "Iteration: 1529; Percent complete: 38.2%; Average loss: 0.0023\n",
      "Iteration: 1530; Percent complete: 38.2%; Average loss: 0.0027\n",
      "Iteration: 1531; Percent complete: 38.3%; Average loss: 0.0025\n",
      "Iteration: 1532; Percent complete: 38.3%; Average loss: 0.0026\n",
      "Iteration: 1533; Percent complete: 38.3%; Average loss: 0.0024\n",
      "Iteration: 1534; Percent complete: 38.4%; Average loss: 0.0025\n",
      "Iteration: 1535; Percent complete: 38.4%; Average loss: 0.0025\n",
      "Iteration: 1536; Percent complete: 38.4%; Average loss: 0.0024\n",
      "Iteration: 1537; Percent complete: 38.4%; Average loss: 0.0027\n",
      "Iteration: 1538; Percent complete: 38.5%; Average loss: 0.0022\n",
      "Iteration: 1539; Percent complete: 38.5%; Average loss: 0.0022\n",
      "Iteration: 1540; Percent complete: 38.5%; Average loss: 0.0027\n",
      "Iteration: 1541; Percent complete: 38.5%; Average loss: 0.0024\n",
      "Iteration: 1542; Percent complete: 38.6%; Average loss: 0.0026\n",
      "Iteration: 1543; Percent complete: 38.6%; Average loss: 0.0025\n",
      "Iteration: 1544; Percent complete: 38.6%; Average loss: 0.0024\n",
      "Iteration: 1545; Percent complete: 38.6%; Average loss: 0.0024\n",
      "Iteration: 1546; Percent complete: 38.6%; Average loss: 0.0024\n",
      "Iteration: 1547; Percent complete: 38.7%; Average loss: 0.0026\n",
      "Iteration: 1548; Percent complete: 38.7%; Average loss: 0.0024\n",
      "Iteration: 1549; Percent complete: 38.7%; Average loss: 0.0025\n",
      "Iteration: 1550; Percent complete: 38.8%; Average loss: 0.0023\n",
      "Iteration: 1551; Percent complete: 38.8%; Average loss: 0.0024\n",
      "Iteration: 1552; Percent complete: 38.8%; Average loss: 0.0022\n",
      "Iteration: 1553; Percent complete: 38.8%; Average loss: 0.0024\n",
      "Iteration: 1554; Percent complete: 38.9%; Average loss: 0.0023\n",
      "Iteration: 1555; Percent complete: 38.9%; Average loss: 0.0022\n",
      "Iteration: 1556; Percent complete: 38.9%; Average loss: 0.0023\n",
      "Iteration: 1557; Percent complete: 38.9%; Average loss: 0.0023\n",
      "Iteration: 1558; Percent complete: 39.0%; Average loss: 0.0023\n",
      "Iteration: 1559; Percent complete: 39.0%; Average loss: 0.0023\n",
      "Iteration: 1560; Percent complete: 39.0%; Average loss: 0.0022\n",
      "Iteration: 1561; Percent complete: 39.0%; Average loss: 0.0024\n",
      "Iteration: 1562; Percent complete: 39.1%; Average loss: 0.0022\n",
      "Iteration: 1563; Percent complete: 39.1%; Average loss: 0.0022\n",
      "Iteration: 1564; Percent complete: 39.1%; Average loss: 0.0025\n",
      "Iteration: 1565; Percent complete: 39.1%; Average loss: 0.0020\n",
      "Iteration: 1566; Percent complete: 39.1%; Average loss: 0.0020\n",
      "Iteration: 1567; Percent complete: 39.2%; Average loss: 0.0020\n",
      "Iteration: 1568; Percent complete: 39.2%; Average loss: 0.0022\n",
      "Iteration: 1569; Percent complete: 39.2%; Average loss: 0.0022\n",
      "Iteration: 1570; Percent complete: 39.2%; Average loss: 0.0025\n",
      "Iteration: 1571; Percent complete: 39.3%; Average loss: 0.0024\n",
      "Iteration: 1572; Percent complete: 39.3%; Average loss: 0.0024\n",
      "Iteration: 1573; Percent complete: 39.3%; Average loss: 0.0022\n",
      "Iteration: 1574; Percent complete: 39.4%; Average loss: 0.0023\n",
      "Iteration: 1575; Percent complete: 39.4%; Average loss: 0.0023\n",
      "Iteration: 1576; Percent complete: 39.4%; Average loss: 0.0024\n",
      "Iteration: 1577; Percent complete: 39.4%; Average loss: 0.0023\n",
      "Iteration: 1578; Percent complete: 39.5%; Average loss: 0.0021\n",
      "Iteration: 1579; Percent complete: 39.5%; Average loss: 0.0023\n",
      "Iteration: 1580; Percent complete: 39.5%; Average loss: 0.0022\n",
      "Iteration: 1581; Percent complete: 39.5%; Average loss: 0.0022\n",
      "Iteration: 1582; Percent complete: 39.6%; Average loss: 0.0021\n",
      "Iteration: 1583; Percent complete: 39.6%; Average loss: 0.0021\n",
      "Iteration: 1584; Percent complete: 39.6%; Average loss: 0.0022\n",
      "Iteration: 1585; Percent complete: 39.6%; Average loss: 0.0022\n",
      "Iteration: 1586; Percent complete: 39.6%; Average loss: 0.0024\n",
      "Iteration: 1587; Percent complete: 39.7%; Average loss: 0.0025\n",
      "Iteration: 1588; Percent complete: 39.7%; Average loss: 0.0023\n",
      "Iteration: 1589; Percent complete: 39.7%; Average loss: 0.0023\n",
      "Iteration: 1590; Percent complete: 39.8%; Average loss: 0.0027\n",
      "Iteration: 1591; Percent complete: 39.8%; Average loss: 0.0023\n",
      "Iteration: 1592; Percent complete: 39.8%; Average loss: 0.0022\n",
      "Iteration: 1593; Percent complete: 39.8%; Average loss: 0.0021\n",
      "Iteration: 1594; Percent complete: 39.9%; Average loss: 0.0020\n",
      "Iteration: 1595; Percent complete: 39.9%; Average loss: 0.0024\n",
      "Iteration: 1596; Percent complete: 39.9%; Average loss: 0.0022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1597; Percent complete: 39.9%; Average loss: 0.0023\n",
      "Iteration: 1598; Percent complete: 40.0%; Average loss: 0.0023\n",
      "Iteration: 1599; Percent complete: 40.0%; Average loss: 0.0024\n",
      "Iteration: 1600; Percent complete: 40.0%; Average loss: 0.0023\n",
      "Iteration: 1601; Percent complete: 40.0%; Average loss: 0.0022\n",
      "Iteration: 1602; Percent complete: 40.1%; Average loss: 0.0023\n",
      "Iteration: 1603; Percent complete: 40.1%; Average loss: 0.0021\n",
      "Iteration: 1604; Percent complete: 40.1%; Average loss: 0.0026\n",
      "Iteration: 1605; Percent complete: 40.1%; Average loss: 0.0023\n",
      "Iteration: 1606; Percent complete: 40.2%; Average loss: 0.0024\n",
      "Iteration: 1607; Percent complete: 40.2%; Average loss: 0.0023\n",
      "Iteration: 1608; Percent complete: 40.2%; Average loss: 0.0021\n",
      "Iteration: 1609; Percent complete: 40.2%; Average loss: 0.0021\n",
      "Iteration: 1610; Percent complete: 40.2%; Average loss: 0.0027\n",
      "Iteration: 1611; Percent complete: 40.3%; Average loss: 0.0023\n",
      "Iteration: 1612; Percent complete: 40.3%; Average loss: 0.0022\n",
      "Iteration: 1613; Percent complete: 40.3%; Average loss: 0.0021\n",
      "Iteration: 1614; Percent complete: 40.4%; Average loss: 0.0021\n",
      "Iteration: 1615; Percent complete: 40.4%; Average loss: 0.0023\n",
      "Iteration: 1616; Percent complete: 40.4%; Average loss: 0.0021\n",
      "Iteration: 1617; Percent complete: 40.4%; Average loss: 0.0022\n",
      "Iteration: 1618; Percent complete: 40.5%; Average loss: 0.0022\n",
      "Iteration: 1619; Percent complete: 40.5%; Average loss: 0.0023\n",
      "Iteration: 1620; Percent complete: 40.5%; Average loss: 0.0022\n",
      "Iteration: 1621; Percent complete: 40.5%; Average loss: 0.0022\n",
      "Iteration: 1622; Percent complete: 40.6%; Average loss: 0.0022\n",
      "Iteration: 1623; Percent complete: 40.6%; Average loss: 0.0021\n",
      "Iteration: 1624; Percent complete: 40.6%; Average loss: 0.0021\n",
      "Iteration: 1625; Percent complete: 40.6%; Average loss: 0.0021\n",
      "Iteration: 1626; Percent complete: 40.6%; Average loss: 0.0021\n",
      "Iteration: 1627; Percent complete: 40.7%; Average loss: 0.0020\n",
      "Iteration: 1628; Percent complete: 40.7%; Average loss: 0.0020\n",
      "Iteration: 1629; Percent complete: 40.7%; Average loss: 0.0020\n",
      "Iteration: 1630; Percent complete: 40.8%; Average loss: 0.0022\n",
      "Iteration: 1631; Percent complete: 40.8%; Average loss: 0.0022\n",
      "Iteration: 1632; Percent complete: 40.8%; Average loss: 0.0023\n",
      "Iteration: 1633; Percent complete: 40.8%; Average loss: 0.0023\n",
      "Iteration: 1634; Percent complete: 40.8%; Average loss: 0.0021\n",
      "Iteration: 1635; Percent complete: 40.9%; Average loss: 0.0020\n",
      "Iteration: 1636; Percent complete: 40.9%; Average loss: 0.0020\n",
      "Iteration: 1637; Percent complete: 40.9%; Average loss: 0.0022\n",
      "Iteration: 1638; Percent complete: 40.9%; Average loss: 0.0020\n",
      "Iteration: 1639; Percent complete: 41.0%; Average loss: 0.0019\n",
      "Iteration: 1640; Percent complete: 41.0%; Average loss: 0.0020\n",
      "Iteration: 1641; Percent complete: 41.0%; Average loss: 0.0021\n",
      "Iteration: 1642; Percent complete: 41.0%; Average loss: 0.0020\n",
      "Iteration: 1643; Percent complete: 41.1%; Average loss: 0.0020\n",
      "Iteration: 1644; Percent complete: 41.1%; Average loss: 0.0023\n",
      "Iteration: 1645; Percent complete: 41.1%; Average loss: 0.0020\n",
      "Iteration: 1646; Percent complete: 41.1%; Average loss: 0.0020\n",
      "Iteration: 1647; Percent complete: 41.2%; Average loss: 0.0021\n",
      "Iteration: 1648; Percent complete: 41.2%; Average loss: 0.0020\n",
      "Iteration: 1649; Percent complete: 41.2%; Average loss: 0.0021\n",
      "Iteration: 1650; Percent complete: 41.2%; Average loss: 0.0022\n",
      "Iteration: 1651; Percent complete: 41.3%; Average loss: 0.0019\n",
      "Iteration: 1652; Percent complete: 41.3%; Average loss: 0.0020\n",
      "Iteration: 1653; Percent complete: 41.3%; Average loss: 0.0021\n",
      "Iteration: 1654; Percent complete: 41.3%; Average loss: 0.0021\n",
      "Iteration: 1655; Percent complete: 41.4%; Average loss: 0.0021\n",
      "Iteration: 1656; Percent complete: 41.4%; Average loss: 0.0022\n",
      "Iteration: 1657; Percent complete: 41.4%; Average loss: 0.0020\n",
      "Iteration: 1658; Percent complete: 41.4%; Average loss: 0.0021\n",
      "Iteration: 1659; Percent complete: 41.5%; Average loss: 0.0023\n",
      "Iteration: 1660; Percent complete: 41.5%; Average loss: 0.0022\n",
      "Iteration: 1661; Percent complete: 41.5%; Average loss: 0.0021\n",
      "Iteration: 1662; Percent complete: 41.5%; Average loss: 0.0020\n",
      "Iteration: 1663; Percent complete: 41.6%; Average loss: 0.0020\n",
      "Iteration: 1664; Percent complete: 41.6%; Average loss: 0.0020\n",
      "Iteration: 1665; Percent complete: 41.6%; Average loss: 0.0020\n",
      "Iteration: 1666; Percent complete: 41.6%; Average loss: 0.0022\n",
      "Iteration: 1667; Percent complete: 41.7%; Average loss: 0.0020\n",
      "Iteration: 1668; Percent complete: 41.7%; Average loss: 0.0020\n",
      "Iteration: 1669; Percent complete: 41.7%; Average loss: 0.0021\n",
      "Iteration: 1670; Percent complete: 41.8%; Average loss: 0.0020\n",
      "Iteration: 1671; Percent complete: 41.8%; Average loss: 0.0020\n",
      "Iteration: 1672; Percent complete: 41.8%; Average loss: 0.0020\n",
      "Iteration: 1673; Percent complete: 41.8%; Average loss: 0.0020\n",
      "Iteration: 1674; Percent complete: 41.9%; Average loss: 0.0019\n",
      "Iteration: 1675; Percent complete: 41.9%; Average loss: 0.0019\n",
      "Iteration: 1676; Percent complete: 41.9%; Average loss: 0.0021\n",
      "Iteration: 1677; Percent complete: 41.9%; Average loss: 0.0018\n",
      "Iteration: 1678; Percent complete: 41.9%; Average loss: 0.0019\n",
      "Iteration: 1679; Percent complete: 42.0%; Average loss: 0.0021\n",
      "Iteration: 1680; Percent complete: 42.0%; Average loss: 0.0019\n",
      "Iteration: 1681; Percent complete: 42.0%; Average loss: 0.0020\n",
      "Iteration: 1682; Percent complete: 42.0%; Average loss: 0.0019\n",
      "Iteration: 1683; Percent complete: 42.1%; Average loss: 0.0019\n",
      "Iteration: 1684; Percent complete: 42.1%; Average loss: 0.0021\n",
      "Iteration: 1685; Percent complete: 42.1%; Average loss: 0.0020\n",
      "Iteration: 1686; Percent complete: 42.1%; Average loss: 0.0018\n",
      "Iteration: 1687; Percent complete: 42.2%; Average loss: 0.0020\n",
      "Iteration: 1688; Percent complete: 42.2%; Average loss: 0.0018\n",
      "Iteration: 1689; Percent complete: 42.2%; Average loss: 0.0021\n",
      "Iteration: 1690; Percent complete: 42.2%; Average loss: 0.0019\n",
      "Iteration: 1691; Percent complete: 42.3%; Average loss: 0.0018\n",
      "Iteration: 1692; Percent complete: 42.3%; Average loss: 0.0022\n",
      "Iteration: 1693; Percent complete: 42.3%; Average loss: 0.0020\n",
      "Iteration: 1694; Percent complete: 42.4%; Average loss: 0.0020\n",
      "Iteration: 1695; Percent complete: 42.4%; Average loss: 0.0021\n",
      "Iteration: 1696; Percent complete: 42.4%; Average loss: 0.0019\n",
      "Iteration: 1697; Percent complete: 42.4%; Average loss: 0.0019\n",
      "Iteration: 1698; Percent complete: 42.4%; Average loss: 0.0019\n",
      "Iteration: 1699; Percent complete: 42.5%; Average loss: 0.0020\n",
      "Iteration: 1700; Percent complete: 42.5%; Average loss: 0.0022\n",
      "Iteration: 1701; Percent complete: 42.5%; Average loss: 0.0019\n",
      "Iteration: 1702; Percent complete: 42.5%; Average loss: 0.0019\n",
      "Iteration: 1703; Percent complete: 42.6%; Average loss: 0.0017\n",
      "Iteration: 1704; Percent complete: 42.6%; Average loss: 0.0021\n",
      "Iteration: 1705; Percent complete: 42.6%; Average loss: 0.0018\n",
      "Iteration: 1706; Percent complete: 42.6%; Average loss: 0.0018\n",
      "Iteration: 1707; Percent complete: 42.7%; Average loss: 0.0018\n",
      "Iteration: 1708; Percent complete: 42.7%; Average loss: 0.0020\n",
      "Iteration: 1709; Percent complete: 42.7%; Average loss: 0.0018\n",
      "Iteration: 1710; Percent complete: 42.8%; Average loss: 0.0020\n",
      "Iteration: 1711; Percent complete: 42.8%; Average loss: 0.0020\n",
      "Iteration: 1712; Percent complete: 42.8%; Average loss: 0.0020\n",
      "Iteration: 1713; Percent complete: 42.8%; Average loss: 0.0019\n",
      "Iteration: 1714; Percent complete: 42.9%; Average loss: 0.0019\n",
      "Iteration: 1715; Percent complete: 42.9%; Average loss: 0.0019\n",
      "Iteration: 1716; Percent complete: 42.9%; Average loss: 0.0020\n",
      "Iteration: 1717; Percent complete: 42.9%; Average loss: 0.0019\n",
      "Iteration: 1718; Percent complete: 43.0%; Average loss: 0.0020\n",
      "Iteration: 1719; Percent complete: 43.0%; Average loss: 0.0020\n",
      "Iteration: 1720; Percent complete: 43.0%; Average loss: 0.0018\n",
      "Iteration: 1721; Percent complete: 43.0%; Average loss: 0.0019\n",
      "Iteration: 1722; Percent complete: 43.0%; Average loss: 0.0019\n",
      "Iteration: 1723; Percent complete: 43.1%; Average loss: 0.0018\n",
      "Iteration: 1724; Percent complete: 43.1%; Average loss: 0.0018\n",
      "Iteration: 1725; Percent complete: 43.1%; Average loss: 0.0019\n",
      "Iteration: 1726; Percent complete: 43.1%; Average loss: 0.0019\n",
      "Iteration: 1727; Percent complete: 43.2%; Average loss: 0.0019\n",
      "Iteration: 1728; Percent complete: 43.2%; Average loss: 0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1729; Percent complete: 43.2%; Average loss: 0.0018\n",
      "Iteration: 1730; Percent complete: 43.2%; Average loss: 0.0018\n",
      "Iteration: 1731; Percent complete: 43.3%; Average loss: 0.0018\n",
      "Iteration: 1732; Percent complete: 43.3%; Average loss: 0.0018\n",
      "Iteration: 1733; Percent complete: 43.3%; Average loss: 0.0017\n",
      "Iteration: 1734; Percent complete: 43.4%; Average loss: 0.0018\n",
      "Iteration: 1735; Percent complete: 43.4%; Average loss: 0.0017\n",
      "Iteration: 1736; Percent complete: 43.4%; Average loss: 0.0020\n",
      "Iteration: 1737; Percent complete: 43.4%; Average loss: 0.0020\n",
      "Iteration: 1738; Percent complete: 43.5%; Average loss: 0.0019\n",
      "Iteration: 1739; Percent complete: 43.5%; Average loss: 0.0018\n",
      "Iteration: 1740; Percent complete: 43.5%; Average loss: 0.0019\n",
      "Iteration: 1741; Percent complete: 43.5%; Average loss: 0.0019\n",
      "Iteration: 1742; Percent complete: 43.5%; Average loss: 0.0018\n",
      "Iteration: 1743; Percent complete: 43.6%; Average loss: 0.0018\n",
      "Iteration: 1744; Percent complete: 43.6%; Average loss: 0.0019\n",
      "Iteration: 1745; Percent complete: 43.6%; Average loss: 0.0018\n",
      "Iteration: 1746; Percent complete: 43.6%; Average loss: 0.0020\n",
      "Iteration: 1747; Percent complete: 43.7%; Average loss: 0.0017\n",
      "Iteration: 1748; Percent complete: 43.7%; Average loss: 0.0017\n",
      "Iteration: 1749; Percent complete: 43.7%; Average loss: 0.0018\n",
      "Iteration: 1750; Percent complete: 43.8%; Average loss: 0.0019\n",
      "Iteration: 1751; Percent complete: 43.8%; Average loss: 0.0019\n",
      "Iteration: 1752; Percent complete: 43.8%; Average loss: 0.0019\n",
      "Iteration: 1753; Percent complete: 43.8%; Average loss: 0.0019\n",
      "Iteration: 1754; Percent complete: 43.9%; Average loss: 0.0018\n",
      "Iteration: 1755; Percent complete: 43.9%; Average loss: 0.0018\n",
      "Iteration: 1756; Percent complete: 43.9%; Average loss: 0.0019\n",
      "Iteration: 1757; Percent complete: 43.9%; Average loss: 0.0018\n",
      "Iteration: 1758; Percent complete: 44.0%; Average loss: 0.0018\n",
      "Iteration: 1759; Percent complete: 44.0%; Average loss: 0.0018\n",
      "Iteration: 1760; Percent complete: 44.0%; Average loss: 0.0017\n",
      "Iteration: 1761; Percent complete: 44.0%; Average loss: 0.0019\n",
      "Iteration: 1762; Percent complete: 44.0%; Average loss: 0.0017\n",
      "Iteration: 1763; Percent complete: 44.1%; Average loss: 0.0018\n",
      "Iteration: 1764; Percent complete: 44.1%; Average loss: 0.0019\n",
      "Iteration: 1765; Percent complete: 44.1%; Average loss: 0.0018\n",
      "Iteration: 1766; Percent complete: 44.1%; Average loss: 0.0019\n",
      "Iteration: 1767; Percent complete: 44.2%; Average loss: 0.0018\n",
      "Iteration: 1768; Percent complete: 44.2%; Average loss: 0.0017\n",
      "Iteration: 1769; Percent complete: 44.2%; Average loss: 0.0016\n",
      "Iteration: 1770; Percent complete: 44.2%; Average loss: 0.0018\n",
      "Iteration: 1771; Percent complete: 44.3%; Average loss: 0.0016\n",
      "Iteration: 1772; Percent complete: 44.3%; Average loss: 0.0014\n",
      "Iteration: 1773; Percent complete: 44.3%; Average loss: 0.0018\n",
      "Iteration: 1774; Percent complete: 44.4%; Average loss: 0.0018\n",
      "Iteration: 1775; Percent complete: 44.4%; Average loss: 0.0018\n",
      "Iteration: 1776; Percent complete: 44.4%; Average loss: 0.0017\n",
      "Iteration: 1777; Percent complete: 44.4%; Average loss: 0.0016\n",
      "Iteration: 1778; Percent complete: 44.5%; Average loss: 0.0017\n",
      "Iteration: 1779; Percent complete: 44.5%; Average loss: 0.0018\n",
      "Iteration: 1780; Percent complete: 44.5%; Average loss: 0.0018\n",
      "Iteration: 1781; Percent complete: 44.5%; Average loss: 0.0017\n",
      "Iteration: 1782; Percent complete: 44.5%; Average loss: 0.0016\n",
      "Iteration: 1783; Percent complete: 44.6%; Average loss: 0.0017\n",
      "Iteration: 1784; Percent complete: 44.6%; Average loss: 0.0016\n",
      "Iteration: 1785; Percent complete: 44.6%; Average loss: 0.0018\n",
      "Iteration: 1786; Percent complete: 44.6%; Average loss: 0.0018\n",
      "Iteration: 1787; Percent complete: 44.7%; Average loss: 0.0017\n",
      "Iteration: 1788; Percent complete: 44.7%; Average loss: 0.0016\n",
      "Iteration: 1789; Percent complete: 44.7%; Average loss: 0.0018\n",
      "Iteration: 1790; Percent complete: 44.8%; Average loss: 0.0017\n",
      "Iteration: 1791; Percent complete: 44.8%; Average loss: 0.0017\n",
      "Iteration: 1792; Percent complete: 44.8%; Average loss: 0.0034\n",
      "Iteration: 1793; Percent complete: 44.8%; Average loss: 0.0017\n",
      "Iteration: 1794; Percent complete: 44.9%; Average loss: 0.0017\n",
      "Iteration: 1795; Percent complete: 44.9%; Average loss: 0.0017\n",
      "Iteration: 1796; Percent complete: 44.9%; Average loss: 0.0019\n",
      "Iteration: 1797; Percent complete: 44.9%; Average loss: 0.0018\n",
      "Iteration: 1798; Percent complete: 45.0%; Average loss: 0.0018\n",
      "Iteration: 1799; Percent complete: 45.0%; Average loss: 0.0016\n",
      "Iteration: 1800; Percent complete: 45.0%; Average loss: 0.0018\n",
      "Iteration: 1801; Percent complete: 45.0%; Average loss: 0.0019\n",
      "Iteration: 1802; Percent complete: 45.1%; Average loss: 0.0019\n",
      "Iteration: 1803; Percent complete: 45.1%; Average loss: 0.0023\n",
      "Iteration: 1804; Percent complete: 45.1%; Average loss: 0.0036\n",
      "Iteration: 1805; Percent complete: 45.1%; Average loss: 0.0038\n",
      "Iteration: 1806; Percent complete: 45.1%; Average loss: 0.0026\n",
      "Iteration: 1807; Percent complete: 45.2%; Average loss: 0.0017\n",
      "Iteration: 1808; Percent complete: 45.2%; Average loss: 0.0025\n",
      "Iteration: 1809; Percent complete: 45.2%; Average loss: 0.0018\n",
      "Iteration: 1810; Percent complete: 45.2%; Average loss: 0.0019\n",
      "Iteration: 1811; Percent complete: 45.3%; Average loss: 0.0022\n",
      "Iteration: 1812; Percent complete: 45.3%; Average loss: 0.0020\n",
      "Iteration: 1813; Percent complete: 45.3%; Average loss: 0.0019\n",
      "Iteration: 1814; Percent complete: 45.4%; Average loss: 0.0018\n",
      "Iteration: 1815; Percent complete: 45.4%; Average loss: 0.0022\n",
      "Iteration: 1816; Percent complete: 45.4%; Average loss: 0.0019\n",
      "Iteration: 1817; Percent complete: 45.4%; Average loss: 0.0020\n",
      "Iteration: 1818; Percent complete: 45.5%; Average loss: 0.0017\n",
      "Iteration: 1819; Percent complete: 45.5%; Average loss: 0.0019\n",
      "Iteration: 1820; Percent complete: 45.5%; Average loss: 0.0018\n",
      "Iteration: 1821; Percent complete: 45.5%; Average loss: 0.0018\n",
      "Iteration: 1822; Percent complete: 45.6%; Average loss: 0.0020\n",
      "Iteration: 1823; Percent complete: 45.6%; Average loss: 0.0019\n",
      "Iteration: 1824; Percent complete: 45.6%; Average loss: 0.0018\n",
      "Iteration: 1825; Percent complete: 45.6%; Average loss: 0.0019\n",
      "Iteration: 1826; Percent complete: 45.6%; Average loss: 0.0018\n",
      "Iteration: 1827; Percent complete: 45.7%; Average loss: 0.0015\n",
      "Iteration: 1828; Percent complete: 45.7%; Average loss: 0.0019\n",
      "Iteration: 1829; Percent complete: 45.7%; Average loss: 0.0017\n",
      "Iteration: 1830; Percent complete: 45.8%; Average loss: 0.0019\n",
      "Iteration: 1831; Percent complete: 45.8%; Average loss: 0.0017\n",
      "Iteration: 1832; Percent complete: 45.8%; Average loss: 0.0019\n",
      "Iteration: 1833; Percent complete: 45.8%; Average loss: 0.0018\n",
      "Iteration: 1834; Percent complete: 45.9%; Average loss: 0.0018\n",
      "Iteration: 1835; Percent complete: 45.9%; Average loss: 0.0017\n",
      "Iteration: 1836; Percent complete: 45.9%; Average loss: 0.0017\n",
      "Iteration: 1837; Percent complete: 45.9%; Average loss: 0.0018\n",
      "Iteration: 1838; Percent complete: 46.0%; Average loss: 0.0016\n",
      "Iteration: 1839; Percent complete: 46.0%; Average loss: 0.0016\n",
      "Iteration: 1840; Percent complete: 46.0%; Average loss: 0.0017\n",
      "Iteration: 1841; Percent complete: 46.0%; Average loss: 0.0017\n",
      "Iteration: 1842; Percent complete: 46.1%; Average loss: 0.0017\n",
      "Iteration: 1843; Percent complete: 46.1%; Average loss: 0.0020\n",
      "Iteration: 1844; Percent complete: 46.1%; Average loss: 0.0017\n",
      "Iteration: 1845; Percent complete: 46.1%; Average loss: 0.0017\n",
      "Iteration: 1846; Percent complete: 46.2%; Average loss: 0.0017\n",
      "Iteration: 1847; Percent complete: 46.2%; Average loss: 0.0017\n",
      "Iteration: 1848; Percent complete: 46.2%; Average loss: 0.0018\n",
      "Iteration: 1849; Percent complete: 46.2%; Average loss: 0.0020\n",
      "Iteration: 1850; Percent complete: 46.2%; Average loss: 0.0016\n",
      "Iteration: 1851; Percent complete: 46.3%; Average loss: 0.0018\n",
      "Iteration: 1852; Percent complete: 46.3%; Average loss: 0.0016\n",
      "Iteration: 1853; Percent complete: 46.3%; Average loss: 0.0018\n",
      "Iteration: 1854; Percent complete: 46.4%; Average loss: 0.0017\n",
      "Iteration: 1855; Percent complete: 46.4%; Average loss: 0.0017\n",
      "Iteration: 1856; Percent complete: 46.4%; Average loss: 0.0016\n",
      "Iteration: 1857; Percent complete: 46.4%; Average loss: 0.0018\n",
      "Iteration: 1858; Percent complete: 46.5%; Average loss: 0.0017\n",
      "Iteration: 1859; Percent complete: 46.5%; Average loss: 0.0016\n",
      "Iteration: 1860; Percent complete: 46.5%; Average loss: 0.0017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1861; Percent complete: 46.5%; Average loss: 0.0019\n",
      "Iteration: 1862; Percent complete: 46.6%; Average loss: 0.0016\n",
      "Iteration: 1863; Percent complete: 46.6%; Average loss: 0.0017\n",
      "Iteration: 1864; Percent complete: 46.6%; Average loss: 0.0017\n",
      "Iteration: 1865; Percent complete: 46.6%; Average loss: 0.0017\n",
      "Iteration: 1866; Percent complete: 46.7%; Average loss: 0.0017\n",
      "Iteration: 1867; Percent complete: 46.7%; Average loss: 0.0016\n",
      "Iteration: 1868; Percent complete: 46.7%; Average loss: 0.0017\n",
      "Iteration: 1869; Percent complete: 46.7%; Average loss: 0.0016\n",
      "Iteration: 1870; Percent complete: 46.8%; Average loss: 0.0016\n",
      "Iteration: 1871; Percent complete: 46.8%; Average loss: 0.0016\n",
      "Iteration: 1872; Percent complete: 46.8%; Average loss: 0.0018\n",
      "Iteration: 1873; Percent complete: 46.8%; Average loss: 0.0016\n",
      "Iteration: 1874; Percent complete: 46.9%; Average loss: 0.0016\n",
      "Iteration: 1875; Percent complete: 46.9%; Average loss: 0.0017\n",
      "Iteration: 1876; Percent complete: 46.9%; Average loss: 0.0014\n",
      "Iteration: 1877; Percent complete: 46.9%; Average loss: 0.0017\n",
      "Iteration: 1878; Percent complete: 46.9%; Average loss: 0.0018\n",
      "Iteration: 1879; Percent complete: 47.0%; Average loss: 0.0014\n",
      "Iteration: 1880; Percent complete: 47.0%; Average loss: 0.0017\n",
      "Iteration: 1881; Percent complete: 47.0%; Average loss: 0.0016\n",
      "Iteration: 1882; Percent complete: 47.0%; Average loss: 0.0018\n",
      "Iteration: 1883; Percent complete: 47.1%; Average loss: 0.0014\n",
      "Iteration: 1884; Percent complete: 47.1%; Average loss: 0.0014\n",
      "Iteration: 1885; Percent complete: 47.1%; Average loss: 0.0015\n",
      "Iteration: 1886; Percent complete: 47.1%; Average loss: 0.0017\n",
      "Iteration: 1887; Percent complete: 47.2%; Average loss: 0.0017\n",
      "Iteration: 1888; Percent complete: 47.2%; Average loss: 0.0015\n",
      "Iteration: 1889; Percent complete: 47.2%; Average loss: 0.0016\n",
      "Iteration: 1890; Percent complete: 47.2%; Average loss: 0.0016\n",
      "Iteration: 1891; Percent complete: 47.3%; Average loss: 0.0016\n",
      "Iteration: 1892; Percent complete: 47.3%; Average loss: 0.0015\n",
      "Iteration: 1893; Percent complete: 47.3%; Average loss: 0.0015\n",
      "Iteration: 1894; Percent complete: 47.3%; Average loss: 0.0016\n",
      "Iteration: 1895; Percent complete: 47.4%; Average loss: 0.0016\n",
      "Iteration: 1896; Percent complete: 47.4%; Average loss: 0.0016\n",
      "Iteration: 1897; Percent complete: 47.4%; Average loss: 0.0018\n",
      "Iteration: 1898; Percent complete: 47.4%; Average loss: 0.0016\n",
      "Iteration: 1899; Percent complete: 47.5%; Average loss: 0.0016\n",
      "Iteration: 1900; Percent complete: 47.5%; Average loss: 0.0016\n",
      "Iteration: 1901; Percent complete: 47.5%; Average loss: 0.0015\n",
      "Iteration: 1902; Percent complete: 47.5%; Average loss: 0.0015\n",
      "Iteration: 1903; Percent complete: 47.6%; Average loss: 0.0016\n",
      "Iteration: 1904; Percent complete: 47.6%; Average loss: 0.0016\n",
      "Iteration: 1905; Percent complete: 47.6%; Average loss: 0.0016\n",
      "Iteration: 1906; Percent complete: 47.6%; Average loss: 0.0015\n",
      "Iteration: 1907; Percent complete: 47.7%; Average loss: 0.0016\n",
      "Iteration: 1908; Percent complete: 47.7%; Average loss: 0.0016\n",
      "Iteration: 1909; Percent complete: 47.7%; Average loss: 0.0015\n",
      "Iteration: 1910; Percent complete: 47.8%; Average loss: 0.0016\n",
      "Iteration: 1911; Percent complete: 47.8%; Average loss: 0.0016\n",
      "Iteration: 1912; Percent complete: 47.8%; Average loss: 0.0015\n",
      "Iteration: 1913; Percent complete: 47.8%; Average loss: 0.0016\n",
      "Iteration: 1914; Percent complete: 47.9%; Average loss: 0.0016\n",
      "Iteration: 1915; Percent complete: 47.9%; Average loss: 0.0014\n",
      "Iteration: 1916; Percent complete: 47.9%; Average loss: 0.0017\n",
      "Iteration: 1917; Percent complete: 47.9%; Average loss: 0.0015\n",
      "Iteration: 1918; Percent complete: 47.9%; Average loss: 0.0017\n",
      "Iteration: 1919; Percent complete: 48.0%; Average loss: 0.0014\n",
      "Iteration: 1920; Percent complete: 48.0%; Average loss: 0.0016\n",
      "Iteration: 1921; Percent complete: 48.0%; Average loss: 0.0015\n",
      "Iteration: 1922; Percent complete: 48.0%; Average loss: 0.0016\n",
      "Iteration: 1923; Percent complete: 48.1%; Average loss: 0.0016\n",
      "Iteration: 1924; Percent complete: 48.1%; Average loss: 0.0014\n",
      "Iteration: 1925; Percent complete: 48.1%; Average loss: 0.0015\n",
      "Iteration: 1926; Percent complete: 48.1%; Average loss: 0.0016\n",
      "Iteration: 1927; Percent complete: 48.2%; Average loss: 0.0016\n",
      "Iteration: 1928; Percent complete: 48.2%; Average loss: 0.0015\n",
      "Iteration: 1929; Percent complete: 48.2%; Average loss: 0.0014\n",
      "Iteration: 1930; Percent complete: 48.2%; Average loss: 0.0015\n",
      "Iteration: 1931; Percent complete: 48.3%; Average loss: 0.0015\n",
      "Iteration: 1932; Percent complete: 48.3%; Average loss: 0.0015\n",
      "Iteration: 1933; Percent complete: 48.3%; Average loss: 0.0015\n",
      "Iteration: 1934; Percent complete: 48.4%; Average loss: 0.0013\n",
      "Iteration: 1935; Percent complete: 48.4%; Average loss: 0.0017\n",
      "Iteration: 1936; Percent complete: 48.4%; Average loss: 0.0014\n",
      "Iteration: 1937; Percent complete: 48.4%; Average loss: 0.0015\n",
      "Iteration: 1938; Percent complete: 48.4%; Average loss: 0.0015\n",
      "Iteration: 1939; Percent complete: 48.5%; Average loss: 0.0014\n",
      "Iteration: 1940; Percent complete: 48.5%; Average loss: 0.0013\n",
      "Iteration: 1941; Percent complete: 48.5%; Average loss: 0.0015\n",
      "Iteration: 1942; Percent complete: 48.5%; Average loss: 0.0015\n",
      "Iteration: 1943; Percent complete: 48.6%; Average loss: 0.0014\n",
      "Iteration: 1944; Percent complete: 48.6%; Average loss: 0.0013\n",
      "Iteration: 1945; Percent complete: 48.6%; Average loss: 0.0014\n",
      "Iteration: 1946; Percent complete: 48.6%; Average loss: 0.0015\n",
      "Iteration: 1947; Percent complete: 48.7%; Average loss: 0.0015\n",
      "Iteration: 1948; Percent complete: 48.7%; Average loss: 0.0014\n",
      "Iteration: 1949; Percent complete: 48.7%; Average loss: 0.0014\n",
      "Iteration: 1950; Percent complete: 48.8%; Average loss: 0.0016\n",
      "Iteration: 1951; Percent complete: 48.8%; Average loss: 0.0016\n",
      "Iteration: 1952; Percent complete: 48.8%; Average loss: 0.0014\n",
      "Iteration: 1953; Percent complete: 48.8%; Average loss: 0.0015\n",
      "Iteration: 1954; Percent complete: 48.9%; Average loss: 0.0014\n",
      "Iteration: 1955; Percent complete: 48.9%; Average loss: 0.0014\n",
      "Iteration: 1956; Percent complete: 48.9%; Average loss: 0.0015\n",
      "Iteration: 1957; Percent complete: 48.9%; Average loss: 0.0014\n",
      "Iteration: 1958; Percent complete: 48.9%; Average loss: 0.0016\n",
      "Iteration: 1959; Percent complete: 49.0%; Average loss: 0.0015\n",
      "Iteration: 1960; Percent complete: 49.0%; Average loss: 0.0014\n",
      "Iteration: 1961; Percent complete: 49.0%; Average loss: 0.0014\n",
      "Iteration: 1962; Percent complete: 49.0%; Average loss: 0.0013\n",
      "Iteration: 1963; Percent complete: 49.1%; Average loss: 0.0015\n",
      "Iteration: 1964; Percent complete: 49.1%; Average loss: 0.0014\n",
      "Iteration: 1965; Percent complete: 49.1%; Average loss: 0.0016\n",
      "Iteration: 1966; Percent complete: 49.1%; Average loss: 0.0014\n",
      "Iteration: 1967; Percent complete: 49.2%; Average loss: 0.0014\n",
      "Iteration: 1968; Percent complete: 49.2%; Average loss: 0.0014\n",
      "Iteration: 1969; Percent complete: 49.2%; Average loss: 0.0013\n",
      "Iteration: 1970; Percent complete: 49.2%; Average loss: 0.0016\n",
      "Iteration: 1971; Percent complete: 49.3%; Average loss: 0.0014\n",
      "Iteration: 1972; Percent complete: 49.3%; Average loss: 0.0013\n",
      "Iteration: 1973; Percent complete: 49.3%; Average loss: 0.0015\n",
      "Iteration: 1974; Percent complete: 49.4%; Average loss: 0.0013\n",
      "Iteration: 1975; Percent complete: 49.4%; Average loss: 0.0014\n",
      "Iteration: 1976; Percent complete: 49.4%; Average loss: 0.0014\n",
      "Iteration: 1977; Percent complete: 49.4%; Average loss: 0.0014\n",
      "Iteration: 1978; Percent complete: 49.5%; Average loss: 0.0014\n",
      "Iteration: 1979; Percent complete: 49.5%; Average loss: 0.0014\n",
      "Iteration: 1980; Percent complete: 49.5%; Average loss: 0.0015\n",
      "Iteration: 1981; Percent complete: 49.5%; Average loss: 0.0015\n",
      "Iteration: 1982; Percent complete: 49.5%; Average loss: 0.0015\n",
      "Iteration: 1983; Percent complete: 49.6%; Average loss: 0.0013\n",
      "Iteration: 1984; Percent complete: 49.6%; Average loss: 0.0012\n",
      "Iteration: 1985; Percent complete: 49.6%; Average loss: 0.0015\n",
      "Iteration: 1986; Percent complete: 49.6%; Average loss: 0.0014\n",
      "Iteration: 1987; Percent complete: 49.7%; Average loss: 0.0015\n",
      "Iteration: 1988; Percent complete: 49.7%; Average loss: 0.0015\n",
      "Iteration: 1989; Percent complete: 49.7%; Average loss: 0.0014\n",
      "Iteration: 1990; Percent complete: 49.8%; Average loss: 0.0013\n",
      "Iteration: 1991; Percent complete: 49.8%; Average loss: 0.0013\n",
      "Iteration: 1992; Percent complete: 49.8%; Average loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1993; Percent complete: 49.8%; Average loss: 0.0013\n",
      "Iteration: 1994; Percent complete: 49.9%; Average loss: 0.0015\n",
      "Iteration: 1995; Percent complete: 49.9%; Average loss: 0.0014\n",
      "Iteration: 1996; Percent complete: 49.9%; Average loss: 0.0015\n",
      "Iteration: 1997; Percent complete: 49.9%; Average loss: 0.0014\n",
      "Iteration: 1998; Percent complete: 50.0%; Average loss: 0.0013\n",
      "Iteration: 1999; Percent complete: 50.0%; Average loss: 0.0014\n",
      "Iteration: 2000; Percent complete: 50.0%; Average loss: 0.0013\n",
      "Iteration: 2001; Percent complete: 50.0%; Average loss: 0.0014\n",
      "Iteration: 2002; Percent complete: 50.0%; Average loss: 0.0013\n",
      "Iteration: 2003; Percent complete: 50.1%; Average loss: 0.0014\n",
      "Iteration: 2004; Percent complete: 50.1%; Average loss: 0.0014\n",
      "Iteration: 2005; Percent complete: 50.1%; Average loss: 0.0013\n",
      "Iteration: 2006; Percent complete: 50.1%; Average loss: 0.0013\n",
      "Iteration: 2007; Percent complete: 50.2%; Average loss: 0.0012\n",
      "Iteration: 2008; Percent complete: 50.2%; Average loss: 0.0013\n",
      "Iteration: 2009; Percent complete: 50.2%; Average loss: 0.0013\n",
      "Iteration: 2010; Percent complete: 50.2%; Average loss: 0.0014\n",
      "Iteration: 2011; Percent complete: 50.3%; Average loss: 0.0013\n",
      "Iteration: 2012; Percent complete: 50.3%; Average loss: 0.0012\n",
      "Iteration: 2013; Percent complete: 50.3%; Average loss: 0.0013\n",
      "Iteration: 2014; Percent complete: 50.3%; Average loss: 0.0013\n",
      "Iteration: 2015; Percent complete: 50.4%; Average loss: 0.0014\n",
      "Iteration: 2016; Percent complete: 50.4%; Average loss: 0.0014\n",
      "Iteration: 2017; Percent complete: 50.4%; Average loss: 0.0013\n",
      "Iteration: 2018; Percent complete: 50.4%; Average loss: 0.0013\n",
      "Iteration: 2019; Percent complete: 50.5%; Average loss: 0.0013\n",
      "Iteration: 2020; Percent complete: 50.5%; Average loss: 0.0013\n",
      "Iteration: 2021; Percent complete: 50.5%; Average loss: 0.0014\n",
      "Iteration: 2022; Percent complete: 50.5%; Average loss: 0.0013\n",
      "Iteration: 2023; Percent complete: 50.6%; Average loss: 0.0012\n",
      "Iteration: 2024; Percent complete: 50.6%; Average loss: 0.0014\n",
      "Iteration: 2025; Percent complete: 50.6%; Average loss: 0.0012\n",
      "Iteration: 2026; Percent complete: 50.6%; Average loss: 0.0015\n",
      "Iteration: 2027; Percent complete: 50.7%; Average loss: 0.0014\n",
      "Iteration: 2028; Percent complete: 50.7%; Average loss: 0.0013\n",
      "Iteration: 2029; Percent complete: 50.7%; Average loss: 0.0014\n",
      "Iteration: 2030; Percent complete: 50.7%; Average loss: 0.0013\n",
      "Iteration: 2031; Percent complete: 50.8%; Average loss: 0.0013\n",
      "Iteration: 2032; Percent complete: 50.8%; Average loss: 0.0013\n",
      "Iteration: 2033; Percent complete: 50.8%; Average loss: 0.0012\n",
      "Iteration: 2034; Percent complete: 50.8%; Average loss: 0.0014\n",
      "Iteration: 2035; Percent complete: 50.9%; Average loss: 0.0014\n",
      "Iteration: 2036; Percent complete: 50.9%; Average loss: 0.0013\n",
      "Iteration: 2037; Percent complete: 50.9%; Average loss: 0.0012\n",
      "Iteration: 2038; Percent complete: 50.9%; Average loss: 0.0014\n",
      "Iteration: 2039; Percent complete: 51.0%; Average loss: 0.0013\n",
      "Iteration: 2040; Percent complete: 51.0%; Average loss: 0.0013\n",
      "Iteration: 2041; Percent complete: 51.0%; Average loss: 0.0011\n",
      "Iteration: 2042; Percent complete: 51.0%; Average loss: 0.0013\n",
      "Iteration: 2043; Percent complete: 51.1%; Average loss: 0.0014\n",
      "Iteration: 2044; Percent complete: 51.1%; Average loss: 0.0012\n",
      "Iteration: 2045; Percent complete: 51.1%; Average loss: 0.0014\n",
      "Iteration: 2046; Percent complete: 51.1%; Average loss: 0.0013\n",
      "Iteration: 2047; Percent complete: 51.2%; Average loss: 0.0013\n",
      "Iteration: 2048; Percent complete: 51.2%; Average loss: 0.0014\n",
      "Iteration: 2049; Percent complete: 51.2%; Average loss: 0.0013\n",
      "Iteration: 2050; Percent complete: 51.2%; Average loss: 0.0012\n",
      "Iteration: 2051; Percent complete: 51.3%; Average loss: 0.0013\n",
      "Iteration: 2052; Percent complete: 51.3%; Average loss: 0.0014\n",
      "Iteration: 2053; Percent complete: 51.3%; Average loss: 0.0013\n",
      "Iteration: 2054; Percent complete: 51.3%; Average loss: 0.0012\n",
      "Iteration: 2055; Percent complete: 51.4%; Average loss: 0.0013\n",
      "Iteration: 2056; Percent complete: 51.4%; Average loss: 0.0013\n",
      "Iteration: 2057; Percent complete: 51.4%; Average loss: 0.0012\n",
      "Iteration: 2058; Percent complete: 51.4%; Average loss: 0.0013\n",
      "Iteration: 2059; Percent complete: 51.5%; Average loss: 0.0012\n",
      "Iteration: 2060; Percent complete: 51.5%; Average loss: 0.0014\n",
      "Iteration: 2061; Percent complete: 51.5%; Average loss: 0.0013\n",
      "Iteration: 2062; Percent complete: 51.5%; Average loss: 0.0013\n",
      "Iteration: 2063; Percent complete: 51.6%; Average loss: 0.0013\n",
      "Iteration: 2064; Percent complete: 51.6%; Average loss: 0.0012\n",
      "Iteration: 2065; Percent complete: 51.6%; Average loss: 0.0013\n",
      "Iteration: 2066; Percent complete: 51.6%; Average loss: 0.0012\n",
      "Iteration: 2067; Percent complete: 51.7%; Average loss: 0.0013\n",
      "Iteration: 2068; Percent complete: 51.7%; Average loss: 0.0012\n",
      "Iteration: 2069; Percent complete: 51.7%; Average loss: 0.0013\n",
      "Iteration: 2070; Percent complete: 51.7%; Average loss: 0.0013\n",
      "Iteration: 2071; Percent complete: 51.8%; Average loss: 0.0012\n",
      "Iteration: 2072; Percent complete: 51.8%; Average loss: 0.0012\n",
      "Iteration: 2073; Percent complete: 51.8%; Average loss: 0.0013\n",
      "Iteration: 2074; Percent complete: 51.8%; Average loss: 0.0013\n",
      "Iteration: 2075; Percent complete: 51.9%; Average loss: 0.0013\n",
      "Iteration: 2076; Percent complete: 51.9%; Average loss: 0.0013\n",
      "Iteration: 2077; Percent complete: 51.9%; Average loss: 0.0012\n",
      "Iteration: 2078; Percent complete: 51.9%; Average loss: 0.0013\n",
      "Iteration: 2079; Percent complete: 52.0%; Average loss: 0.0012\n",
      "Iteration: 2080; Percent complete: 52.0%; Average loss: 0.0012\n",
      "Iteration: 2081; Percent complete: 52.0%; Average loss: 0.0012\n",
      "Iteration: 2082; Percent complete: 52.0%; Average loss: 0.0012\n",
      "Iteration: 2083; Percent complete: 52.1%; Average loss: 0.0013\n",
      "Iteration: 2084; Percent complete: 52.1%; Average loss: 0.0013\n",
      "Iteration: 2085; Percent complete: 52.1%; Average loss: 0.0011\n",
      "Iteration: 2086; Percent complete: 52.1%; Average loss: 0.0014\n",
      "Iteration: 2087; Percent complete: 52.2%; Average loss: 0.0012\n",
      "Iteration: 2088; Percent complete: 52.2%; Average loss: 0.0013\n",
      "Iteration: 2089; Percent complete: 52.2%; Average loss: 0.0013\n",
      "Iteration: 2090; Percent complete: 52.2%; Average loss: 0.0012\n",
      "Iteration: 2091; Percent complete: 52.3%; Average loss: 0.0012\n",
      "Iteration: 2092; Percent complete: 52.3%; Average loss: 0.0011\n",
      "Iteration: 2093; Percent complete: 52.3%; Average loss: 0.0013\n",
      "Iteration: 2094; Percent complete: 52.3%; Average loss: 0.0013\n",
      "Iteration: 2095; Percent complete: 52.4%; Average loss: 0.0012\n",
      "Iteration: 2096; Percent complete: 52.4%; Average loss: 0.0013\n",
      "Iteration: 2097; Percent complete: 52.4%; Average loss: 0.0013\n",
      "Iteration: 2098; Percent complete: 52.4%; Average loss: 0.0012\n",
      "Iteration: 2099; Percent complete: 52.5%; Average loss: 0.0014\n",
      "Iteration: 2100; Percent complete: 52.5%; Average loss: 0.0013\n",
      "Iteration: 2101; Percent complete: 52.5%; Average loss: 0.0012\n",
      "Iteration: 2102; Percent complete: 52.5%; Average loss: 0.0012\n",
      "Iteration: 2103; Percent complete: 52.6%; Average loss: 0.0013\n",
      "Iteration: 2104; Percent complete: 52.6%; Average loss: 0.0013\n",
      "Iteration: 2105; Percent complete: 52.6%; Average loss: 0.0012\n",
      "Iteration: 2106; Percent complete: 52.6%; Average loss: 0.0011\n",
      "Iteration: 2107; Percent complete: 52.7%; Average loss: 0.0013\n",
      "Iteration: 2108; Percent complete: 52.7%; Average loss: 0.0012\n",
      "Iteration: 2109; Percent complete: 52.7%; Average loss: 0.0011\n",
      "Iteration: 2110; Percent complete: 52.8%; Average loss: 0.0013\n",
      "Iteration: 2111; Percent complete: 52.8%; Average loss: 0.0012\n",
      "Iteration: 2112; Percent complete: 52.8%; Average loss: 0.0012\n",
      "Iteration: 2113; Percent complete: 52.8%; Average loss: 0.0013\n",
      "Iteration: 2114; Percent complete: 52.8%; Average loss: 0.0012\n",
      "Iteration: 2115; Percent complete: 52.9%; Average loss: 0.0012\n",
      "Iteration: 2116; Percent complete: 52.9%; Average loss: 0.0012\n",
      "Iteration: 2117; Percent complete: 52.9%; Average loss: 0.0012\n",
      "Iteration: 2118; Percent complete: 52.9%; Average loss: 0.0013\n",
      "Iteration: 2119; Percent complete: 53.0%; Average loss: 0.0011\n",
      "Iteration: 2120; Percent complete: 53.0%; Average loss: 0.0012\n",
      "Iteration: 2121; Percent complete: 53.0%; Average loss: 0.0013\n",
      "Iteration: 2122; Percent complete: 53.0%; Average loss: 0.0012\n",
      "Iteration: 2123; Percent complete: 53.1%; Average loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2124; Percent complete: 53.1%; Average loss: 0.0012\n",
      "Iteration: 2125; Percent complete: 53.1%; Average loss: 0.0012\n",
      "Iteration: 2126; Percent complete: 53.1%; Average loss: 0.0013\n",
      "Iteration: 2127; Percent complete: 53.2%; Average loss: 0.0012\n",
      "Iteration: 2128; Percent complete: 53.2%; Average loss: 0.0012\n",
      "Iteration: 2129; Percent complete: 53.2%; Average loss: 0.0013\n",
      "Iteration: 2130; Percent complete: 53.2%; Average loss: 0.0013\n",
      "Iteration: 2131; Percent complete: 53.3%; Average loss: 0.0012\n",
      "Iteration: 2132; Percent complete: 53.3%; Average loss: 0.0012\n",
      "Iteration: 2133; Percent complete: 53.3%; Average loss: 0.0012\n",
      "Iteration: 2134; Percent complete: 53.3%; Average loss: 0.0012\n",
      "Iteration: 2135; Percent complete: 53.4%; Average loss: 0.0012\n",
      "Iteration: 2136; Percent complete: 53.4%; Average loss: 0.0013\n",
      "Iteration: 2137; Percent complete: 53.4%; Average loss: 0.0012\n",
      "Iteration: 2138; Percent complete: 53.4%; Average loss: 0.0014\n",
      "Iteration: 2139; Percent complete: 53.5%; Average loss: 0.0012\n",
      "Iteration: 2140; Percent complete: 53.5%; Average loss: 0.0011\n",
      "Iteration: 2141; Percent complete: 53.5%; Average loss: 0.0012\n",
      "Iteration: 2142; Percent complete: 53.5%; Average loss: 0.0013\n",
      "Iteration: 2143; Percent complete: 53.6%; Average loss: 0.0012\n",
      "Iteration: 2144; Percent complete: 53.6%; Average loss: 0.0013\n",
      "Iteration: 2145; Percent complete: 53.6%; Average loss: 0.0012\n",
      "Iteration: 2146; Percent complete: 53.6%; Average loss: 0.0012\n",
      "Iteration: 2147; Percent complete: 53.7%; Average loss: 0.0012\n",
      "Iteration: 2148; Percent complete: 53.7%; Average loss: 0.0012\n",
      "Iteration: 2149; Percent complete: 53.7%; Average loss: 0.0013\n",
      "Iteration: 2150; Percent complete: 53.8%; Average loss: 0.0012\n",
      "Iteration: 2151; Percent complete: 53.8%; Average loss: 0.0012\n",
      "Iteration: 2152; Percent complete: 53.8%; Average loss: 0.0012\n",
      "Iteration: 2153; Percent complete: 53.8%; Average loss: 0.0011\n",
      "Iteration: 2154; Percent complete: 53.8%; Average loss: 0.0012\n",
      "Iteration: 2155; Percent complete: 53.9%; Average loss: 0.0011\n",
      "Iteration: 2156; Percent complete: 53.9%; Average loss: 0.0011\n",
      "Iteration: 2157; Percent complete: 53.9%; Average loss: 0.0011\n",
      "Iteration: 2158; Percent complete: 53.9%; Average loss: 0.0011\n",
      "Iteration: 2159; Percent complete: 54.0%; Average loss: 0.0012\n",
      "Iteration: 2160; Percent complete: 54.0%; Average loss: 0.0011\n",
      "Iteration: 2161; Percent complete: 54.0%; Average loss: 0.0011\n",
      "Iteration: 2162; Percent complete: 54.0%; Average loss: 0.0012\n",
      "Iteration: 2163; Percent complete: 54.1%; Average loss: 0.0012\n",
      "Iteration: 2164; Percent complete: 54.1%; Average loss: 0.0012\n",
      "Iteration: 2165; Percent complete: 54.1%; Average loss: 0.0011\n",
      "Iteration: 2166; Percent complete: 54.1%; Average loss: 0.0011\n",
      "Iteration: 2167; Percent complete: 54.2%; Average loss: 0.0011\n",
      "Iteration: 2168; Percent complete: 54.2%; Average loss: 0.0011\n",
      "Iteration: 2169; Percent complete: 54.2%; Average loss: 0.0012\n",
      "Iteration: 2170; Percent complete: 54.2%; Average loss: 0.0011\n",
      "Iteration: 2171; Percent complete: 54.3%; Average loss: 0.0011\n",
      "Iteration: 2172; Percent complete: 54.3%; Average loss: 0.0011\n",
      "Iteration: 2173; Percent complete: 54.3%; Average loss: 0.0011\n",
      "Iteration: 2174; Percent complete: 54.4%; Average loss: 0.0011\n",
      "Iteration: 2175; Percent complete: 54.4%; Average loss: 0.0012\n",
      "Iteration: 2176; Percent complete: 54.4%; Average loss: 0.0012\n",
      "Iteration: 2177; Percent complete: 54.4%; Average loss: 0.0011\n",
      "Iteration: 2178; Percent complete: 54.4%; Average loss: 0.0011\n",
      "Iteration: 2179; Percent complete: 54.5%; Average loss: 0.0011\n",
      "Iteration: 2180; Percent complete: 54.5%; Average loss: 0.0012\n",
      "Iteration: 2181; Percent complete: 54.5%; Average loss: 0.0010\n",
      "Iteration: 2182; Percent complete: 54.5%; Average loss: 0.0012\n",
      "Iteration: 2183; Percent complete: 54.6%; Average loss: 0.0011\n",
      "Iteration: 2184; Percent complete: 54.6%; Average loss: 0.0011\n",
      "Iteration: 2185; Percent complete: 54.6%; Average loss: 0.0010\n",
      "Iteration: 2186; Percent complete: 54.6%; Average loss: 0.0011\n",
      "Iteration: 2187; Percent complete: 54.7%; Average loss: 0.0011\n",
      "Iteration: 2188; Percent complete: 54.7%; Average loss: 0.0012\n",
      "Iteration: 2189; Percent complete: 54.7%; Average loss: 0.0012\n",
      "Iteration: 2190; Percent complete: 54.8%; Average loss: 0.0011\n",
      "Iteration: 2191; Percent complete: 54.8%; Average loss: 0.0010\n",
      "Iteration: 2192; Percent complete: 54.8%; Average loss: 0.0011\n",
      "Iteration: 2193; Percent complete: 54.8%; Average loss: 0.0012\n",
      "Iteration: 2194; Percent complete: 54.9%; Average loss: 0.0011\n",
      "Iteration: 2195; Percent complete: 54.9%; Average loss: 0.0011\n",
      "Iteration: 2196; Percent complete: 54.9%; Average loss: 0.0010\n",
      "Iteration: 2197; Percent complete: 54.9%; Average loss: 0.0012\n",
      "Iteration: 2198; Percent complete: 54.9%; Average loss: 0.0011\n",
      "Iteration: 2199; Percent complete: 55.0%; Average loss: 0.0011\n",
      "Iteration: 2200; Percent complete: 55.0%; Average loss: 0.0012\n",
      "Iteration: 2201; Percent complete: 55.0%; Average loss: 0.0010\n",
      "Iteration: 2202; Percent complete: 55.0%; Average loss: 0.0012\n",
      "Iteration: 2203; Percent complete: 55.1%; Average loss: 0.0010\n",
      "Iteration: 2204; Percent complete: 55.1%; Average loss: 0.0011\n",
      "Iteration: 2205; Percent complete: 55.1%; Average loss: 0.0011\n",
      "Iteration: 2206; Percent complete: 55.1%; Average loss: 0.0012\n",
      "Iteration: 2207; Percent complete: 55.2%; Average loss: 0.0010\n",
      "Iteration: 2208; Percent complete: 55.2%; Average loss: 0.0011\n",
      "Iteration: 2209; Percent complete: 55.2%; Average loss: 0.0010\n",
      "Iteration: 2210; Percent complete: 55.2%; Average loss: 0.0011\n",
      "Iteration: 2211; Percent complete: 55.3%; Average loss: 0.0011\n",
      "Iteration: 2212; Percent complete: 55.3%; Average loss: 0.0010\n",
      "Iteration: 2213; Percent complete: 55.3%; Average loss: 0.0012\n",
      "Iteration: 2214; Percent complete: 55.4%; Average loss: 0.0011\n",
      "Iteration: 2215; Percent complete: 55.4%; Average loss: 0.0011\n",
      "Iteration: 2216; Percent complete: 55.4%; Average loss: 0.0010\n",
      "Iteration: 2217; Percent complete: 55.4%; Average loss: 0.0012\n",
      "Iteration: 2218; Percent complete: 55.5%; Average loss: 0.0010\n",
      "Iteration: 2219; Percent complete: 55.5%; Average loss: 0.0012\n",
      "Iteration: 2220; Percent complete: 55.5%; Average loss: 0.0010\n",
      "Iteration: 2221; Percent complete: 55.5%; Average loss: 0.0010\n",
      "Iteration: 2222; Percent complete: 55.5%; Average loss: 0.0011\n",
      "Iteration: 2223; Percent complete: 55.6%; Average loss: 0.0011\n",
      "Iteration: 2224; Percent complete: 55.6%; Average loss: 0.0011\n",
      "Iteration: 2225; Percent complete: 55.6%; Average loss: 0.0011\n",
      "Iteration: 2226; Percent complete: 55.6%; Average loss: 0.0010\n",
      "Iteration: 2227; Percent complete: 55.7%; Average loss: 0.0010\n",
      "Iteration: 2228; Percent complete: 55.7%; Average loss: 0.0010\n",
      "Iteration: 2229; Percent complete: 55.7%; Average loss: 0.0012\n",
      "Iteration: 2230; Percent complete: 55.8%; Average loss: 0.0012\n",
      "Iteration: 2231; Percent complete: 55.8%; Average loss: 0.0011\n",
      "Iteration: 2232; Percent complete: 55.8%; Average loss: 0.0013\n",
      "Iteration: 2233; Percent complete: 55.8%; Average loss: 0.0012\n",
      "Iteration: 2234; Percent complete: 55.9%; Average loss: 0.0011\n",
      "Iteration: 2235; Percent complete: 55.9%; Average loss: 0.0010\n",
      "Iteration: 2236; Percent complete: 55.9%; Average loss: 0.0011\n",
      "Iteration: 2237; Percent complete: 55.9%; Average loss: 0.0012\n",
      "Iteration: 2238; Percent complete: 56.0%; Average loss: 0.0014\n",
      "Iteration: 2239; Percent complete: 56.0%; Average loss: 0.0010\n",
      "Iteration: 2240; Percent complete: 56.0%; Average loss: 0.0011\n",
      "Iteration: 2241; Percent complete: 56.0%; Average loss: 0.0011\n",
      "Iteration: 2242; Percent complete: 56.0%; Average loss: 0.0011\n",
      "Iteration: 2243; Percent complete: 56.1%; Average loss: 0.0011\n",
      "Iteration: 2244; Percent complete: 56.1%; Average loss: 0.0011\n",
      "Iteration: 2245; Percent complete: 56.1%; Average loss: 0.0011\n",
      "Iteration: 2246; Percent complete: 56.1%; Average loss: 0.0011\n",
      "Iteration: 2247; Percent complete: 56.2%; Average loss: 0.0013\n",
      "Iteration: 2248; Percent complete: 56.2%; Average loss: 0.0011\n",
      "Iteration: 2249; Percent complete: 56.2%; Average loss: 0.0010\n",
      "Iteration: 2250; Percent complete: 56.2%; Average loss: 0.0010\n",
      "Iteration: 2251; Percent complete: 56.3%; Average loss: 0.0011\n",
      "Iteration: 2252; Percent complete: 56.3%; Average loss: 0.0011\n",
      "Iteration: 2253; Percent complete: 56.3%; Average loss: 0.0010\n",
      "Iteration: 2254; Percent complete: 56.4%; Average loss: 0.0012\n",
      "Iteration: 2255; Percent complete: 56.4%; Average loss: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2256; Percent complete: 56.4%; Average loss: 0.0012\n",
      "Iteration: 2257; Percent complete: 56.4%; Average loss: 0.0011\n",
      "Iteration: 2258; Percent complete: 56.5%; Average loss: 0.0011\n",
      "Iteration: 2259; Percent complete: 56.5%; Average loss: 0.0010\n",
      "Iteration: 2260; Percent complete: 56.5%; Average loss: 0.0009\n",
      "Iteration: 2261; Percent complete: 56.5%; Average loss: 0.0010\n",
      "Iteration: 2262; Percent complete: 56.5%; Average loss: 0.0010\n",
      "Iteration: 2263; Percent complete: 56.6%; Average loss: 0.0011\n",
      "Iteration: 2264; Percent complete: 56.6%; Average loss: 0.0010\n",
      "Iteration: 2265; Percent complete: 56.6%; Average loss: 0.0011\n",
      "Iteration: 2266; Percent complete: 56.6%; Average loss: 0.0011\n",
      "Iteration: 2267; Percent complete: 56.7%; Average loss: 0.0012\n",
      "Iteration: 2268; Percent complete: 56.7%; Average loss: 0.0010\n",
      "Iteration: 2269; Percent complete: 56.7%; Average loss: 0.0011\n",
      "Iteration: 2270; Percent complete: 56.8%; Average loss: 0.0011\n",
      "Iteration: 2271; Percent complete: 56.8%; Average loss: 0.0010\n",
      "Iteration: 2272; Percent complete: 56.8%; Average loss: 0.0011\n",
      "Iteration: 2273; Percent complete: 56.8%; Average loss: 0.0011\n",
      "Iteration: 2274; Percent complete: 56.9%; Average loss: 0.0010\n",
      "Iteration: 2275; Percent complete: 56.9%; Average loss: 0.0012\n",
      "Iteration: 2276; Percent complete: 56.9%; Average loss: 0.0009\n",
      "Iteration: 2277; Percent complete: 56.9%; Average loss: 0.0010\n",
      "Iteration: 2278; Percent complete: 57.0%; Average loss: 0.0011\n",
      "Iteration: 2279; Percent complete: 57.0%; Average loss: 0.0010\n",
      "Iteration: 2280; Percent complete: 57.0%; Average loss: 0.0011\n",
      "Iteration: 2281; Percent complete: 57.0%; Average loss: 0.0010\n",
      "Iteration: 2282; Percent complete: 57.0%; Average loss: 0.0011\n",
      "Iteration: 2283; Percent complete: 57.1%; Average loss: 0.0010\n",
      "Iteration: 2284; Percent complete: 57.1%; Average loss: 0.0011\n",
      "Iteration: 2285; Percent complete: 57.1%; Average loss: 0.0010\n",
      "Iteration: 2286; Percent complete: 57.1%; Average loss: 0.0009\n",
      "Iteration: 2287; Percent complete: 57.2%; Average loss: 0.0011\n",
      "Iteration: 2288; Percent complete: 57.2%; Average loss: 0.0010\n",
      "Iteration: 2289; Percent complete: 57.2%; Average loss: 0.0010\n",
      "Iteration: 2290; Percent complete: 57.2%; Average loss: 0.0010\n",
      "Iteration: 2291; Percent complete: 57.3%; Average loss: 0.0011\n",
      "Iteration: 2292; Percent complete: 57.3%; Average loss: 0.0009\n",
      "Iteration: 2293; Percent complete: 57.3%; Average loss: 0.0010\n",
      "Iteration: 2294; Percent complete: 57.4%; Average loss: 0.0010\n",
      "Iteration: 2295; Percent complete: 57.4%; Average loss: 0.0010\n",
      "Iteration: 2296; Percent complete: 57.4%; Average loss: 0.0010\n",
      "Iteration: 2297; Percent complete: 57.4%; Average loss: 0.0010\n",
      "Iteration: 2298; Percent complete: 57.5%; Average loss: 0.0010\n",
      "Iteration: 2299; Percent complete: 57.5%; Average loss: 0.0010\n",
      "Iteration: 2300; Percent complete: 57.5%; Average loss: 0.0008\n",
      "Iteration: 2301; Percent complete: 57.5%; Average loss: 0.0010\n",
      "Iteration: 2302; Percent complete: 57.6%; Average loss: 0.0010\n",
      "Iteration: 2303; Percent complete: 57.6%; Average loss: 0.0010\n",
      "Iteration: 2304; Percent complete: 57.6%; Average loss: 0.0011\n",
      "Iteration: 2305; Percent complete: 57.6%; Average loss: 0.0010\n",
      "Iteration: 2306; Percent complete: 57.6%; Average loss: 0.0010\n",
      "Iteration: 2307; Percent complete: 57.7%; Average loss: 0.0009\n",
      "Iteration: 2308; Percent complete: 57.7%; Average loss: 0.0010\n",
      "Iteration: 2309; Percent complete: 57.7%; Average loss: 0.0010\n",
      "Iteration: 2310; Percent complete: 57.8%; Average loss: 0.0010\n",
      "Iteration: 2311; Percent complete: 57.8%; Average loss: 0.0009\n",
      "Iteration: 2312; Percent complete: 57.8%; Average loss: 0.0010\n",
      "Iteration: 2313; Percent complete: 57.8%; Average loss: 0.0010\n",
      "Iteration: 2314; Percent complete: 57.9%; Average loss: 0.0010\n",
      "Iteration: 2315; Percent complete: 57.9%; Average loss: 0.0010\n",
      "Iteration: 2316; Percent complete: 57.9%; Average loss: 0.0010\n",
      "Iteration: 2317; Percent complete: 57.9%; Average loss: 0.0010\n",
      "Iteration: 2318; Percent complete: 58.0%; Average loss: 0.0010\n",
      "Iteration: 2319; Percent complete: 58.0%; Average loss: 0.0010\n",
      "Iteration: 2320; Percent complete: 58.0%; Average loss: 0.0011\n",
      "Iteration: 2321; Percent complete: 58.0%; Average loss: 0.0010\n",
      "Iteration: 2322; Percent complete: 58.1%; Average loss: 0.0010\n",
      "Iteration: 2323; Percent complete: 58.1%; Average loss: 0.0010\n",
      "Iteration: 2324; Percent complete: 58.1%; Average loss: 0.0009\n",
      "Iteration: 2325; Percent complete: 58.1%; Average loss: 0.0009\n",
      "Iteration: 2326; Percent complete: 58.1%; Average loss: 0.0010\n",
      "Iteration: 2327; Percent complete: 58.2%; Average loss: 0.0011\n",
      "Iteration: 2328; Percent complete: 58.2%; Average loss: 0.0009\n",
      "Iteration: 2329; Percent complete: 58.2%; Average loss: 0.0010\n",
      "Iteration: 2330; Percent complete: 58.2%; Average loss: 0.0009\n",
      "Iteration: 2331; Percent complete: 58.3%; Average loss: 0.0010\n",
      "Iteration: 2332; Percent complete: 58.3%; Average loss: 0.0010\n",
      "Iteration: 2333; Percent complete: 58.3%; Average loss: 0.0010\n",
      "Iteration: 2334; Percent complete: 58.4%; Average loss: 0.0010\n",
      "Iteration: 2335; Percent complete: 58.4%; Average loss: 0.0009\n",
      "Iteration: 2336; Percent complete: 58.4%; Average loss: 0.0010\n",
      "Iteration: 2337; Percent complete: 58.4%; Average loss: 0.0009\n",
      "Iteration: 2338; Percent complete: 58.5%; Average loss: 0.0009\n",
      "Iteration: 2339; Percent complete: 58.5%; Average loss: 0.0010\n",
      "Iteration: 2340; Percent complete: 58.5%; Average loss: 0.0009\n",
      "Iteration: 2341; Percent complete: 58.5%; Average loss: 0.0009\n",
      "Iteration: 2342; Percent complete: 58.6%; Average loss: 0.0011\n",
      "Iteration: 2343; Percent complete: 58.6%; Average loss: 0.0009\n",
      "Iteration: 2344; Percent complete: 58.6%; Average loss: 0.0009\n",
      "Iteration: 2345; Percent complete: 58.6%; Average loss: 0.0009\n",
      "Iteration: 2346; Percent complete: 58.7%; Average loss: 0.0009\n",
      "Iteration: 2347; Percent complete: 58.7%; Average loss: 0.0010\n",
      "Iteration: 2348; Percent complete: 58.7%; Average loss: 0.0009\n",
      "Iteration: 2349; Percent complete: 58.7%; Average loss: 0.0009\n",
      "Iteration: 2350; Percent complete: 58.8%; Average loss: 0.0010\n",
      "Iteration: 2351; Percent complete: 58.8%; Average loss: 0.0010\n",
      "Iteration: 2352; Percent complete: 58.8%; Average loss: 0.0010\n",
      "Iteration: 2353; Percent complete: 58.8%; Average loss: 0.0010\n",
      "Iteration: 2354; Percent complete: 58.9%; Average loss: 0.0008\n",
      "Iteration: 2355; Percent complete: 58.9%; Average loss: 0.0009\n",
      "Iteration: 2356; Percent complete: 58.9%; Average loss: 0.0010\n",
      "Iteration: 2357; Percent complete: 58.9%; Average loss: 0.0010\n",
      "Iteration: 2358; Percent complete: 59.0%; Average loss: 0.0010\n",
      "Iteration: 2359; Percent complete: 59.0%; Average loss: 0.0009\n",
      "Iteration: 2360; Percent complete: 59.0%; Average loss: 0.0010\n",
      "Iteration: 2361; Percent complete: 59.0%; Average loss: 0.0009\n",
      "Iteration: 2362; Percent complete: 59.1%; Average loss: 0.0009\n",
      "Iteration: 2363; Percent complete: 59.1%; Average loss: 0.0009\n",
      "Iteration: 2364; Percent complete: 59.1%; Average loss: 0.0010\n",
      "Iteration: 2365; Percent complete: 59.1%; Average loss: 0.0010\n",
      "Iteration: 2366; Percent complete: 59.2%; Average loss: 0.0009\n",
      "Iteration: 2367; Percent complete: 59.2%; Average loss: 0.0010\n",
      "Iteration: 2368; Percent complete: 59.2%; Average loss: 0.0010\n",
      "Iteration: 2369; Percent complete: 59.2%; Average loss: 0.0010\n",
      "Iteration: 2370; Percent complete: 59.2%; Average loss: 0.0010\n",
      "Iteration: 2371; Percent complete: 59.3%; Average loss: 0.0009\n",
      "Iteration: 2372; Percent complete: 59.3%; Average loss: 0.0009\n",
      "Iteration: 2373; Percent complete: 59.3%; Average loss: 0.0010\n",
      "Iteration: 2374; Percent complete: 59.4%; Average loss: 0.0010\n",
      "Iteration: 2375; Percent complete: 59.4%; Average loss: 0.0009\n",
      "Iteration: 2376; Percent complete: 59.4%; Average loss: 0.0010\n",
      "Iteration: 2377; Percent complete: 59.4%; Average loss: 0.0010\n",
      "Iteration: 2378; Percent complete: 59.5%; Average loss: 0.0010\n",
      "Iteration: 2379; Percent complete: 59.5%; Average loss: 0.0010\n",
      "Iteration: 2380; Percent complete: 59.5%; Average loss: 0.0008\n",
      "Iteration: 2381; Percent complete: 59.5%; Average loss: 0.0010\n",
      "Iteration: 2382; Percent complete: 59.6%; Average loss: 0.0010\n",
      "Iteration: 2383; Percent complete: 59.6%; Average loss: 0.0009\n",
      "Iteration: 2384; Percent complete: 59.6%; Average loss: 0.0009\n",
      "Iteration: 2385; Percent complete: 59.6%; Average loss: 0.0009\n",
      "Iteration: 2386; Percent complete: 59.7%; Average loss: 0.0010\n",
      "Iteration: 2387; Percent complete: 59.7%; Average loss: 0.0009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2388; Percent complete: 59.7%; Average loss: 0.0008\n",
      "Iteration: 2389; Percent complete: 59.7%; Average loss: 0.0009\n",
      "Iteration: 2390; Percent complete: 59.8%; Average loss: 0.0010\n",
      "Iteration: 2391; Percent complete: 59.8%; Average loss: 0.0009\n",
      "Iteration: 2392; Percent complete: 59.8%; Average loss: 0.0011\n",
      "Iteration: 2393; Percent complete: 59.8%; Average loss: 0.0010\n",
      "Iteration: 2394; Percent complete: 59.9%; Average loss: 0.0009\n",
      "Iteration: 2395; Percent complete: 59.9%; Average loss: 0.0009\n",
      "Iteration: 2396; Percent complete: 59.9%; Average loss: 0.0010\n",
      "Iteration: 2397; Percent complete: 59.9%; Average loss: 0.0010\n",
      "Iteration: 2398; Percent complete: 60.0%; Average loss: 0.0009\n",
      "Iteration: 2399; Percent complete: 60.0%; Average loss: 0.0009\n",
      "Iteration: 2400; Percent complete: 60.0%; Average loss: 0.0009\n",
      "Iteration: 2401; Percent complete: 60.0%; Average loss: 0.0009\n",
      "Iteration: 2402; Percent complete: 60.1%; Average loss: 0.0009\n",
      "Iteration: 2403; Percent complete: 60.1%; Average loss: 0.0009\n",
      "Iteration: 2404; Percent complete: 60.1%; Average loss: 0.0009\n",
      "Iteration: 2405; Percent complete: 60.1%; Average loss: 0.0009\n",
      "Iteration: 2406; Percent complete: 60.2%; Average loss: 0.0010\n",
      "Iteration: 2407; Percent complete: 60.2%; Average loss: 0.0009\n",
      "Iteration: 2408; Percent complete: 60.2%; Average loss: 0.0009\n",
      "Iteration: 2409; Percent complete: 60.2%; Average loss: 0.0009\n",
      "Iteration: 2410; Percent complete: 60.2%; Average loss: 0.0009\n",
      "Iteration: 2411; Percent complete: 60.3%; Average loss: 0.0009\n",
      "Iteration: 2412; Percent complete: 60.3%; Average loss: 0.0009\n",
      "Iteration: 2413; Percent complete: 60.3%; Average loss: 0.0009\n",
      "Iteration: 2414; Percent complete: 60.4%; Average loss: 0.0008\n",
      "Iteration: 2415; Percent complete: 60.4%; Average loss: 0.0009\n",
      "Iteration: 2416; Percent complete: 60.4%; Average loss: 0.0008\n",
      "Iteration: 2417; Percent complete: 60.4%; Average loss: 0.0009\n",
      "Iteration: 2418; Percent complete: 60.5%; Average loss: 0.0010\n",
      "Iteration: 2419; Percent complete: 60.5%; Average loss: 0.0008\n",
      "Iteration: 2420; Percent complete: 60.5%; Average loss: 0.0009\n",
      "Iteration: 2421; Percent complete: 60.5%; Average loss: 0.0009\n",
      "Iteration: 2422; Percent complete: 60.6%; Average loss: 0.0009\n",
      "Iteration: 2423; Percent complete: 60.6%; Average loss: 0.0009\n",
      "Iteration: 2424; Percent complete: 60.6%; Average loss: 0.0008\n",
      "Iteration: 2425; Percent complete: 60.6%; Average loss: 0.0009\n",
      "Iteration: 2426; Percent complete: 60.7%; Average loss: 0.0009\n",
      "Iteration: 2427; Percent complete: 60.7%; Average loss: 0.0009\n",
      "Iteration: 2428; Percent complete: 60.7%; Average loss: 0.0009\n",
      "Iteration: 2429; Percent complete: 60.7%; Average loss: 0.0010\n",
      "Iteration: 2430; Percent complete: 60.8%; Average loss: 0.0009\n",
      "Iteration: 2431; Percent complete: 60.8%; Average loss: 0.0009\n",
      "Iteration: 2432; Percent complete: 60.8%; Average loss: 0.0009\n",
      "Iteration: 2433; Percent complete: 60.8%; Average loss: 0.0010\n",
      "Iteration: 2434; Percent complete: 60.9%; Average loss: 0.0008\n",
      "Iteration: 2435; Percent complete: 60.9%; Average loss: 0.0009\n",
      "Iteration: 2436; Percent complete: 60.9%; Average loss: 0.0008\n",
      "Iteration: 2437; Percent complete: 60.9%; Average loss: 0.0008\n",
      "Iteration: 2438; Percent complete: 61.0%; Average loss: 0.0009\n",
      "Iteration: 2439; Percent complete: 61.0%; Average loss: 0.0009\n",
      "Iteration: 2440; Percent complete: 61.0%; Average loss: 0.0010\n",
      "Iteration: 2441; Percent complete: 61.0%; Average loss: 0.0009\n",
      "Iteration: 2442; Percent complete: 61.1%; Average loss: 0.0009\n",
      "Iteration: 2443; Percent complete: 61.1%; Average loss: 0.0009\n",
      "Iteration: 2444; Percent complete: 61.1%; Average loss: 0.0010\n",
      "Iteration: 2445; Percent complete: 61.1%; Average loss: 0.0009\n",
      "Iteration: 2446; Percent complete: 61.2%; Average loss: 0.0008\n",
      "Iteration: 2447; Percent complete: 61.2%; Average loss: 0.0009\n",
      "Iteration: 2448; Percent complete: 61.2%; Average loss: 0.0009\n",
      "Iteration: 2449; Percent complete: 61.2%; Average loss: 0.0009\n",
      "Iteration: 2450; Percent complete: 61.3%; Average loss: 0.0008\n",
      "Iteration: 2451; Percent complete: 61.3%; Average loss: 0.0009\n",
      "Iteration: 2452; Percent complete: 61.3%; Average loss: 0.0009\n",
      "Iteration: 2453; Percent complete: 61.3%; Average loss: 0.0009\n",
      "Iteration: 2454; Percent complete: 61.4%; Average loss: 0.0009\n",
      "Iteration: 2455; Percent complete: 61.4%; Average loss: 0.0008\n",
      "Iteration: 2456; Percent complete: 61.4%; Average loss: 0.0009\n",
      "Iteration: 2457; Percent complete: 61.4%; Average loss: 0.0008\n",
      "Iteration: 2458; Percent complete: 61.5%; Average loss: 0.0009\n",
      "Iteration: 2459; Percent complete: 61.5%; Average loss: 0.0007\n",
      "Iteration: 2460; Percent complete: 61.5%; Average loss: 0.0008\n",
      "Iteration: 2461; Percent complete: 61.5%; Average loss: 0.0008\n",
      "Iteration: 2462; Percent complete: 61.6%; Average loss: 0.0009\n",
      "Iteration: 2463; Percent complete: 61.6%; Average loss: 0.0009\n",
      "Iteration: 2464; Percent complete: 61.6%; Average loss: 0.0009\n",
      "Iteration: 2465; Percent complete: 61.6%; Average loss: 0.0008\n",
      "Iteration: 2466; Percent complete: 61.7%; Average loss: 0.0008\n",
      "Iteration: 2467; Percent complete: 61.7%; Average loss: 0.0009\n",
      "Iteration: 2468; Percent complete: 61.7%; Average loss: 0.0009\n",
      "Iteration: 2469; Percent complete: 61.7%; Average loss: 0.0009\n",
      "Iteration: 2470; Percent complete: 61.8%; Average loss: 0.0009\n",
      "Iteration: 2471; Percent complete: 61.8%; Average loss: 0.0009\n",
      "Iteration: 2472; Percent complete: 61.8%; Average loss: 0.0008\n",
      "Iteration: 2473; Percent complete: 61.8%; Average loss: 0.0008\n",
      "Iteration: 2474; Percent complete: 61.9%; Average loss: 0.0009\n",
      "Iteration: 2475; Percent complete: 61.9%; Average loss: 0.0009\n",
      "Iteration: 2476; Percent complete: 61.9%; Average loss: 0.0009\n",
      "Iteration: 2477; Percent complete: 61.9%; Average loss: 0.0008\n",
      "Iteration: 2478; Percent complete: 62.0%; Average loss: 0.0008\n",
      "Iteration: 2479; Percent complete: 62.0%; Average loss: 0.0009\n",
      "Iteration: 2480; Percent complete: 62.0%; Average loss: 0.0008\n",
      "Iteration: 2481; Percent complete: 62.0%; Average loss: 0.0008\n",
      "Iteration: 2482; Percent complete: 62.1%; Average loss: 0.0009\n",
      "Iteration: 2483; Percent complete: 62.1%; Average loss: 0.0008\n",
      "Iteration: 2484; Percent complete: 62.1%; Average loss: 0.0008\n",
      "Iteration: 2485; Percent complete: 62.1%; Average loss: 0.0008\n",
      "Iteration: 2486; Percent complete: 62.2%; Average loss: 0.0009\n",
      "Iteration: 2487; Percent complete: 62.2%; Average loss: 0.0009\n",
      "Iteration: 2488; Percent complete: 62.2%; Average loss: 0.0009\n",
      "Iteration: 2489; Percent complete: 62.2%; Average loss: 0.0009\n",
      "Iteration: 2490; Percent complete: 62.3%; Average loss: 0.0009\n",
      "Iteration: 2491; Percent complete: 62.3%; Average loss: 0.0009\n",
      "Iteration: 2492; Percent complete: 62.3%; Average loss: 0.0008\n",
      "Iteration: 2493; Percent complete: 62.3%; Average loss: 0.0008\n",
      "Iteration: 2494; Percent complete: 62.4%; Average loss: 0.0009\n",
      "Iteration: 2495; Percent complete: 62.4%; Average loss: 0.0007\n",
      "Iteration: 2496; Percent complete: 62.4%; Average loss: 0.0009\n",
      "Iteration: 2497; Percent complete: 62.4%; Average loss: 0.0007\n",
      "Iteration: 2498; Percent complete: 62.5%; Average loss: 0.0009\n",
      "Iteration: 2499; Percent complete: 62.5%; Average loss: 0.0008\n",
      "Iteration: 2500; Percent complete: 62.5%; Average loss: 0.0009\n",
      "Iteration: 2501; Percent complete: 62.5%; Average loss: 0.0008\n",
      "Iteration: 2502; Percent complete: 62.5%; Average loss: 0.0008\n",
      "Iteration: 2503; Percent complete: 62.6%; Average loss: 0.0008\n",
      "Iteration: 2504; Percent complete: 62.6%; Average loss: 0.0008\n",
      "Iteration: 2505; Percent complete: 62.6%; Average loss: 0.0008\n",
      "Iteration: 2506; Percent complete: 62.6%; Average loss: 0.0009\n",
      "Iteration: 2507; Percent complete: 62.7%; Average loss: 0.0008\n",
      "Iteration: 2508; Percent complete: 62.7%; Average loss: 0.0009\n",
      "Iteration: 2509; Percent complete: 62.7%; Average loss: 0.0008\n",
      "Iteration: 2510; Percent complete: 62.7%; Average loss: 0.0008\n",
      "Iteration: 2511; Percent complete: 62.8%; Average loss: 0.0008\n",
      "Iteration: 2512; Percent complete: 62.8%; Average loss: 0.0008\n",
      "Iteration: 2513; Percent complete: 62.8%; Average loss: 0.0008\n",
      "Iteration: 2514; Percent complete: 62.8%; Average loss: 0.0008\n",
      "Iteration: 2515; Percent complete: 62.9%; Average loss: 0.0008\n",
      "Iteration: 2516; Percent complete: 62.9%; Average loss: 0.0008\n",
      "Iteration: 2517; Percent complete: 62.9%; Average loss: 0.0007\n",
      "Iteration: 2518; Percent complete: 62.9%; Average loss: 0.0008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2519; Percent complete: 63.0%; Average loss: 0.0008\n",
      "Iteration: 2520; Percent complete: 63.0%; Average loss: 0.0009\n",
      "Iteration: 2521; Percent complete: 63.0%; Average loss: 0.0008\n",
      "Iteration: 2522; Percent complete: 63.0%; Average loss: 0.0008\n",
      "Iteration: 2523; Percent complete: 63.1%; Average loss: 0.0008\n",
      "Iteration: 2524; Percent complete: 63.1%; Average loss: 0.0008\n",
      "Iteration: 2525; Percent complete: 63.1%; Average loss: 0.0009\n",
      "Iteration: 2526; Percent complete: 63.1%; Average loss: 0.0009\n",
      "Iteration: 2527; Percent complete: 63.2%; Average loss: 0.0008\n",
      "Iteration: 2528; Percent complete: 63.2%; Average loss: 0.0008\n",
      "Iteration: 2529; Percent complete: 63.2%; Average loss: 0.0009\n",
      "Iteration: 2530; Percent complete: 63.2%; Average loss: 0.0008\n",
      "Iteration: 2531; Percent complete: 63.3%; Average loss: 0.0008\n",
      "Iteration: 2532; Percent complete: 63.3%; Average loss: 0.0009\n",
      "Iteration: 2533; Percent complete: 63.3%; Average loss: 0.0008\n",
      "Iteration: 2534; Percent complete: 63.3%; Average loss: 0.0008\n",
      "Iteration: 2535; Percent complete: 63.4%; Average loss: 0.0008\n",
      "Iteration: 2536; Percent complete: 63.4%; Average loss: 0.0009\n",
      "Iteration: 2537; Percent complete: 63.4%; Average loss: 0.0008\n",
      "Iteration: 2538; Percent complete: 63.4%; Average loss: 0.0008\n",
      "Iteration: 2539; Percent complete: 63.5%; Average loss: 0.0009\n",
      "Iteration: 2540; Percent complete: 63.5%; Average loss: 0.0009\n",
      "Iteration: 2541; Percent complete: 63.5%; Average loss: 0.0009\n",
      "Iteration: 2542; Percent complete: 63.5%; Average loss: 0.0008\n",
      "Iteration: 2543; Percent complete: 63.6%; Average loss: 0.0009\n",
      "Iteration: 2544; Percent complete: 63.6%; Average loss: 0.0009\n",
      "Iteration: 2545; Percent complete: 63.6%; Average loss: 0.0008\n",
      "Iteration: 2546; Percent complete: 63.6%; Average loss: 0.0008\n",
      "Iteration: 2547; Percent complete: 63.7%; Average loss: 0.0008\n",
      "Iteration: 2548; Percent complete: 63.7%; Average loss: 0.0008\n",
      "Iteration: 2549; Percent complete: 63.7%; Average loss: 0.0008\n",
      "Iteration: 2550; Percent complete: 63.7%; Average loss: 0.0008\n",
      "Iteration: 2551; Percent complete: 63.8%; Average loss: 0.0008\n",
      "Iteration: 2552; Percent complete: 63.8%; Average loss: 0.0008\n",
      "Iteration: 2553; Percent complete: 63.8%; Average loss: 0.0008\n",
      "Iteration: 2554; Percent complete: 63.8%; Average loss: 0.0008\n",
      "Iteration: 2555; Percent complete: 63.9%; Average loss: 0.0008\n",
      "Iteration: 2556; Percent complete: 63.9%; Average loss: 0.0008\n",
      "Iteration: 2557; Percent complete: 63.9%; Average loss: 0.0008\n",
      "Iteration: 2558; Percent complete: 63.9%; Average loss: 0.0008\n",
      "Iteration: 2559; Percent complete: 64.0%; Average loss: 0.0008\n",
      "Iteration: 2560; Percent complete: 64.0%; Average loss: 0.0008\n",
      "Iteration: 2561; Percent complete: 64.0%; Average loss: 0.0008\n",
      "Iteration: 2562; Percent complete: 64.0%; Average loss: 0.0009\n",
      "Iteration: 2563; Percent complete: 64.1%; Average loss: 0.0008\n",
      "Iteration: 2564; Percent complete: 64.1%; Average loss: 0.0009\n",
      "Iteration: 2565; Percent complete: 64.1%; Average loss: 0.0007\n",
      "Iteration: 2566; Percent complete: 64.1%; Average loss: 0.0008\n",
      "Iteration: 2567; Percent complete: 64.2%; Average loss: 0.0009\n",
      "Iteration: 2568; Percent complete: 64.2%; Average loss: 0.0008\n",
      "Iteration: 2569; Percent complete: 64.2%; Average loss: 0.0007\n",
      "Iteration: 2570; Percent complete: 64.2%; Average loss: 0.0008\n",
      "Iteration: 2571; Percent complete: 64.3%; Average loss: 0.0008\n",
      "Iteration: 2572; Percent complete: 64.3%; Average loss: 0.0008\n",
      "Iteration: 2573; Percent complete: 64.3%; Average loss: 0.0008\n",
      "Iteration: 2574; Percent complete: 64.3%; Average loss: 0.0008\n",
      "Iteration: 2575; Percent complete: 64.4%; Average loss: 0.0008\n",
      "Iteration: 2576; Percent complete: 64.4%; Average loss: 0.0008\n",
      "Iteration: 2577; Percent complete: 64.4%; Average loss: 0.0008\n",
      "Iteration: 2578; Percent complete: 64.5%; Average loss: 0.0008\n",
      "Iteration: 2579; Percent complete: 64.5%; Average loss: 0.0008\n",
      "Iteration: 2580; Percent complete: 64.5%; Average loss: 0.0008\n",
      "Iteration: 2581; Percent complete: 64.5%; Average loss: 0.0008\n",
      "Iteration: 2582; Percent complete: 64.5%; Average loss: 0.0007\n",
      "Iteration: 2583; Percent complete: 64.6%; Average loss: 0.0007\n",
      "Iteration: 2584; Percent complete: 64.6%; Average loss: 0.0008\n",
      "Iteration: 2585; Percent complete: 64.6%; Average loss: 0.0008\n",
      "Iteration: 2586; Percent complete: 64.6%; Average loss: 0.0008\n",
      "Iteration: 2587; Percent complete: 64.7%; Average loss: 0.0008\n",
      "Iteration: 2588; Percent complete: 64.7%; Average loss: 0.0008\n",
      "Iteration: 2589; Percent complete: 64.7%; Average loss: 0.0008\n",
      "Iteration: 2590; Percent complete: 64.8%; Average loss: 0.0008\n",
      "Iteration: 2591; Percent complete: 64.8%; Average loss: 0.0008\n",
      "Iteration: 2592; Percent complete: 64.8%; Average loss: 0.0008\n",
      "Iteration: 2593; Percent complete: 64.8%; Average loss: 0.0007\n",
      "Iteration: 2594; Percent complete: 64.8%; Average loss: 0.0008\n",
      "Iteration: 2595; Percent complete: 64.9%; Average loss: 0.0007\n",
      "Iteration: 2596; Percent complete: 64.9%; Average loss: 0.0007\n",
      "Iteration: 2597; Percent complete: 64.9%; Average loss: 0.0008\n",
      "Iteration: 2598; Percent complete: 65.0%; Average loss: 0.0007\n",
      "Iteration: 2599; Percent complete: 65.0%; Average loss: 0.0007\n",
      "Iteration: 2600; Percent complete: 65.0%; Average loss: 0.0008\n",
      "Iteration: 2601; Percent complete: 65.0%; Average loss: 0.0008\n",
      "Iteration: 2602; Percent complete: 65.0%; Average loss: 0.0008\n",
      "Iteration: 2603; Percent complete: 65.1%; Average loss: 0.0007\n",
      "Iteration: 2604; Percent complete: 65.1%; Average loss: 0.0008\n",
      "Iteration: 2605; Percent complete: 65.1%; Average loss: 0.0007\n",
      "Iteration: 2606; Percent complete: 65.1%; Average loss: 0.0008\n",
      "Iteration: 2607; Percent complete: 65.2%; Average loss: 0.0007\n",
      "Iteration: 2608; Percent complete: 65.2%; Average loss: 0.0008\n",
      "Iteration: 2609; Percent complete: 65.2%; Average loss: 0.0007\n",
      "Iteration: 2610; Percent complete: 65.2%; Average loss: 0.0008\n",
      "Iteration: 2611; Percent complete: 65.3%; Average loss: 0.0007\n",
      "Iteration: 2612; Percent complete: 65.3%; Average loss: 0.0008\n",
      "Iteration: 2613; Percent complete: 65.3%; Average loss: 0.0007\n",
      "Iteration: 2614; Percent complete: 65.3%; Average loss: 0.0007\n",
      "Iteration: 2615; Percent complete: 65.4%; Average loss: 0.0007\n",
      "Iteration: 2616; Percent complete: 65.4%; Average loss: 0.0007\n",
      "Iteration: 2617; Percent complete: 65.4%; Average loss: 0.0007\n",
      "Iteration: 2618; Percent complete: 65.5%; Average loss: 0.0007\n",
      "Iteration: 2619; Percent complete: 65.5%; Average loss: 0.0007\n",
      "Iteration: 2620; Percent complete: 65.5%; Average loss: 0.0007\n",
      "Iteration: 2621; Percent complete: 65.5%; Average loss: 0.0007\n",
      "Iteration: 2622; Percent complete: 65.5%; Average loss: 0.0008\n",
      "Iteration: 2623; Percent complete: 65.6%; Average loss: 0.0007\n",
      "Iteration: 2624; Percent complete: 65.6%; Average loss: 0.0008\n",
      "Iteration: 2625; Percent complete: 65.6%; Average loss: 0.0007\n",
      "Iteration: 2626; Percent complete: 65.6%; Average loss: 0.0008\n",
      "Iteration: 2627; Percent complete: 65.7%; Average loss: 0.0008\n",
      "Iteration: 2628; Percent complete: 65.7%; Average loss: 0.0008\n",
      "Iteration: 2629; Percent complete: 65.7%; Average loss: 0.0008\n",
      "Iteration: 2630; Percent complete: 65.8%; Average loss: 0.0008\n",
      "Iteration: 2631; Percent complete: 65.8%; Average loss: 0.0007\n",
      "Iteration: 2632; Percent complete: 65.8%; Average loss: 0.0008\n",
      "Iteration: 2633; Percent complete: 65.8%; Average loss: 0.0007\n",
      "Iteration: 2634; Percent complete: 65.8%; Average loss: 0.0008\n",
      "Iteration: 2635; Percent complete: 65.9%; Average loss: 0.0008\n",
      "Iteration: 2636; Percent complete: 65.9%; Average loss: 0.0007\n",
      "Iteration: 2637; Percent complete: 65.9%; Average loss: 0.0007\n",
      "Iteration: 2638; Percent complete: 66.0%; Average loss: 0.0007\n",
      "Iteration: 2639; Percent complete: 66.0%; Average loss: 0.0007\n",
      "Iteration: 2640; Percent complete: 66.0%; Average loss: 0.0007\n",
      "Iteration: 2641; Percent complete: 66.0%; Average loss: 0.0007\n",
      "Iteration: 2642; Percent complete: 66.0%; Average loss: 0.0008\n",
      "Iteration: 2643; Percent complete: 66.1%; Average loss: 0.0008\n",
      "Iteration: 2644; Percent complete: 66.1%; Average loss: 0.0008\n",
      "Iteration: 2645; Percent complete: 66.1%; Average loss: 0.0007\n",
      "Iteration: 2646; Percent complete: 66.1%; Average loss: 0.0007\n",
      "Iteration: 2647; Percent complete: 66.2%; Average loss: 0.0007\n",
      "Iteration: 2648; Percent complete: 66.2%; Average loss: 0.0008\n",
      "Iteration: 2649; Percent complete: 66.2%; Average loss: 0.0007\n",
      "Iteration: 2650; Percent complete: 66.2%; Average loss: 0.0007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2651; Percent complete: 66.3%; Average loss: 0.0007\n",
      "Iteration: 2652; Percent complete: 66.3%; Average loss: 0.0007\n",
      "Iteration: 2653; Percent complete: 66.3%; Average loss: 0.0008\n",
      "Iteration: 2654; Percent complete: 66.3%; Average loss: 0.0007\n",
      "Iteration: 2655; Percent complete: 66.4%; Average loss: 0.0007\n",
      "Iteration: 2656; Percent complete: 66.4%; Average loss: 0.0008\n",
      "Iteration: 2657; Percent complete: 66.4%; Average loss: 0.0007\n",
      "Iteration: 2658; Percent complete: 66.5%; Average loss: 0.0007\n",
      "Iteration: 2659; Percent complete: 66.5%; Average loss: 0.0007\n",
      "Iteration: 2660; Percent complete: 66.5%; Average loss: 0.0008\n",
      "Iteration: 2661; Percent complete: 66.5%; Average loss: 0.0007\n",
      "Iteration: 2662; Percent complete: 66.5%; Average loss: 0.0007\n",
      "Iteration: 2663; Percent complete: 66.6%; Average loss: 0.0007\n",
      "Iteration: 2664; Percent complete: 66.6%; Average loss: 0.0007\n",
      "Iteration: 2665; Percent complete: 66.6%; Average loss: 0.0007\n",
      "Iteration: 2666; Percent complete: 66.6%; Average loss: 0.0008\n",
      "Iteration: 2667; Percent complete: 66.7%; Average loss: 0.0007\n",
      "Iteration: 2668; Percent complete: 66.7%; Average loss: 0.0007\n",
      "Iteration: 2669; Percent complete: 66.7%; Average loss: 0.0007\n",
      "Iteration: 2670; Percent complete: 66.8%; Average loss: 0.0007\n",
      "Iteration: 2671; Percent complete: 66.8%; Average loss: 0.0008\n",
      "Iteration: 2672; Percent complete: 66.8%; Average loss: 0.0008\n",
      "Iteration: 2673; Percent complete: 66.8%; Average loss: 0.0007\n",
      "Iteration: 2674; Percent complete: 66.8%; Average loss: 0.0008\n",
      "Iteration: 2675; Percent complete: 66.9%; Average loss: 0.0007\n",
      "Iteration: 2676; Percent complete: 66.9%; Average loss: 0.0007\n",
      "Iteration: 2677; Percent complete: 66.9%; Average loss: 0.0007\n",
      "Iteration: 2678; Percent complete: 67.0%; Average loss: 0.0007\n",
      "Iteration: 2679; Percent complete: 67.0%; Average loss: 0.0007\n",
      "Iteration: 2680; Percent complete: 67.0%; Average loss: 0.0007\n",
      "Iteration: 2681; Percent complete: 67.0%; Average loss: 0.0007\n",
      "Iteration: 2682; Percent complete: 67.0%; Average loss: 0.0007\n",
      "Iteration: 2683; Percent complete: 67.1%; Average loss: 0.0007\n",
      "Iteration: 2684; Percent complete: 67.1%; Average loss: 0.0007\n",
      "Iteration: 2685; Percent complete: 67.1%; Average loss: 0.0007\n",
      "Iteration: 2686; Percent complete: 67.2%; Average loss: 0.0007\n",
      "Iteration: 2687; Percent complete: 67.2%; Average loss: 0.0008\n",
      "Iteration: 2688; Percent complete: 67.2%; Average loss: 0.0007\n",
      "Iteration: 2689; Percent complete: 67.2%; Average loss: 0.0007\n",
      "Iteration: 2690; Percent complete: 67.2%; Average loss: 0.0007\n",
      "Iteration: 2691; Percent complete: 67.3%; Average loss: 0.0007\n",
      "Iteration: 2692; Percent complete: 67.3%; Average loss: 0.0008\n",
      "Iteration: 2693; Percent complete: 67.3%; Average loss: 0.0007\n",
      "Iteration: 2694; Percent complete: 67.3%; Average loss: 0.0006\n",
      "Iteration: 2695; Percent complete: 67.4%; Average loss: 0.0008\n",
      "Iteration: 2696; Percent complete: 67.4%; Average loss: 0.0007\n",
      "Iteration: 2697; Percent complete: 67.4%; Average loss: 0.0007\n",
      "Iteration: 2698; Percent complete: 67.5%; Average loss: 0.0007\n",
      "Iteration: 2699; Percent complete: 67.5%; Average loss: 0.0007\n",
      "Iteration: 2700; Percent complete: 67.5%; Average loss: 0.0007\n",
      "Iteration: 2701; Percent complete: 67.5%; Average loss: 0.0007\n",
      "Iteration: 2702; Percent complete: 67.5%; Average loss: 0.0007\n",
      "Iteration: 2703; Percent complete: 67.6%; Average loss: 0.0007\n",
      "Iteration: 2704; Percent complete: 67.6%; Average loss: 0.0007\n",
      "Iteration: 2705; Percent complete: 67.6%; Average loss: 0.0008\n",
      "Iteration: 2706; Percent complete: 67.7%; Average loss: 0.0007\n",
      "Iteration: 2707; Percent complete: 67.7%; Average loss: 0.0007\n",
      "Iteration: 2708; Percent complete: 67.7%; Average loss: 0.0008\n",
      "Iteration: 2709; Percent complete: 67.7%; Average loss: 0.0007\n",
      "Iteration: 2710; Percent complete: 67.8%; Average loss: 0.0007\n",
      "Iteration: 2711; Percent complete: 67.8%; Average loss: 0.0007\n",
      "Iteration: 2712; Percent complete: 67.8%; Average loss: 0.0006\n",
      "Iteration: 2713; Percent complete: 67.8%; Average loss: 0.0007\n",
      "Iteration: 2714; Percent complete: 67.8%; Average loss: 0.0007\n",
      "Iteration: 2715; Percent complete: 67.9%; Average loss: 0.0007\n",
      "Iteration: 2716; Percent complete: 67.9%; Average loss: 0.0007\n",
      "Iteration: 2717; Percent complete: 67.9%; Average loss: 0.0007\n",
      "Iteration: 2718; Percent complete: 68.0%; Average loss: 0.0007\n",
      "Iteration: 2719; Percent complete: 68.0%; Average loss: 0.0006\n",
      "Iteration: 2720; Percent complete: 68.0%; Average loss: 0.0007\n",
      "Iteration: 2721; Percent complete: 68.0%; Average loss: 0.0007\n",
      "Iteration: 2722; Percent complete: 68.0%; Average loss: 0.0008\n",
      "Iteration: 2723; Percent complete: 68.1%; Average loss: 0.0007\n",
      "Iteration: 2724; Percent complete: 68.1%; Average loss: 0.0007\n",
      "Iteration: 2725; Percent complete: 68.1%; Average loss: 0.0007\n",
      "Iteration: 2726; Percent complete: 68.2%; Average loss: 0.0006\n",
      "Iteration: 2727; Percent complete: 68.2%; Average loss: 0.0006\n",
      "Iteration: 2728; Percent complete: 68.2%; Average loss: 0.0008\n",
      "Iteration: 2729; Percent complete: 68.2%; Average loss: 0.0006\n",
      "Iteration: 2730; Percent complete: 68.2%; Average loss: 0.0006\n",
      "Iteration: 2731; Percent complete: 68.3%; Average loss: 0.0007\n",
      "Iteration: 2732; Percent complete: 68.3%; Average loss: 0.0006\n",
      "Iteration: 2733; Percent complete: 68.3%; Average loss: 0.0006\n",
      "Iteration: 2734; Percent complete: 68.3%; Average loss: 0.0007\n",
      "Iteration: 2735; Percent complete: 68.4%; Average loss: 0.0006\n",
      "Iteration: 2736; Percent complete: 68.4%; Average loss: 0.0006\n",
      "Iteration: 2737; Percent complete: 68.4%; Average loss: 0.0007\n",
      "Iteration: 2738; Percent complete: 68.5%; Average loss: 0.0007\n",
      "Iteration: 2739; Percent complete: 68.5%; Average loss: 0.0006\n",
      "Iteration: 2740; Percent complete: 68.5%; Average loss: 0.0007\n",
      "Iteration: 2741; Percent complete: 68.5%; Average loss: 0.0007\n",
      "Iteration: 2742; Percent complete: 68.5%; Average loss: 0.0008\n",
      "Iteration: 2743; Percent complete: 68.6%; Average loss: 0.0007\n",
      "Iteration: 2744; Percent complete: 68.6%; Average loss: 0.0007\n",
      "Iteration: 2745; Percent complete: 68.6%; Average loss: 0.0007\n",
      "Iteration: 2746; Percent complete: 68.7%; Average loss: 0.0006\n",
      "Iteration: 2747; Percent complete: 68.7%; Average loss: 0.0007\n",
      "Iteration: 2748; Percent complete: 68.7%; Average loss: 0.0007\n",
      "Iteration: 2749; Percent complete: 68.7%; Average loss: 0.0006\n",
      "Iteration: 2750; Percent complete: 68.8%; Average loss: 0.0007\n",
      "Iteration: 2751; Percent complete: 68.8%; Average loss: 0.0007\n",
      "Iteration: 2752; Percent complete: 68.8%; Average loss: 0.0006\n",
      "Iteration: 2753; Percent complete: 68.8%; Average loss: 0.0007\n",
      "Iteration: 2754; Percent complete: 68.8%; Average loss: 0.0006\n",
      "Iteration: 2755; Percent complete: 68.9%; Average loss: 0.0007\n",
      "Iteration: 2756; Percent complete: 68.9%; Average loss: 0.0007\n",
      "Iteration: 2757; Percent complete: 68.9%; Average loss: 0.0007\n",
      "Iteration: 2758; Percent complete: 69.0%; Average loss: 0.0007\n",
      "Iteration: 2759; Percent complete: 69.0%; Average loss: 0.0007\n",
      "Iteration: 2760; Percent complete: 69.0%; Average loss: 0.0007\n",
      "Iteration: 2761; Percent complete: 69.0%; Average loss: 0.0007\n",
      "Iteration: 2762; Percent complete: 69.0%; Average loss: 0.0006\n",
      "Iteration: 2763; Percent complete: 69.1%; Average loss: 0.0007\n",
      "Iteration: 2764; Percent complete: 69.1%; Average loss: 0.0007\n",
      "Iteration: 2765; Percent complete: 69.1%; Average loss: 0.0006\n",
      "Iteration: 2766; Percent complete: 69.2%; Average loss: 0.0007\n",
      "Iteration: 2767; Percent complete: 69.2%; Average loss: 0.0007\n",
      "Iteration: 2768; Percent complete: 69.2%; Average loss: 0.0006\n",
      "Iteration: 2769; Percent complete: 69.2%; Average loss: 0.0007\n",
      "Iteration: 2770; Percent complete: 69.2%; Average loss: 0.0007\n",
      "Iteration: 2771; Percent complete: 69.3%; Average loss: 0.0007\n",
      "Iteration: 2772; Percent complete: 69.3%; Average loss: 0.0006\n",
      "Iteration: 2773; Percent complete: 69.3%; Average loss: 0.0007\n",
      "Iteration: 2774; Percent complete: 69.3%; Average loss: 0.0007\n",
      "Iteration: 2775; Percent complete: 69.4%; Average loss: 0.0006\n",
      "Iteration: 2776; Percent complete: 69.4%; Average loss: 0.0007\n",
      "Iteration: 2777; Percent complete: 69.4%; Average loss: 0.0008\n",
      "Iteration: 2778; Percent complete: 69.5%; Average loss: 0.0006\n",
      "Iteration: 2779; Percent complete: 69.5%; Average loss: 0.0006\n",
      "Iteration: 2780; Percent complete: 69.5%; Average loss: 0.0006\n",
      "Iteration: 2781; Percent complete: 69.5%; Average loss: 0.0007\n",
      "Iteration: 2782; Percent complete: 69.5%; Average loss: 0.0006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2783; Percent complete: 69.6%; Average loss: 0.0007\n",
      "Iteration: 2784; Percent complete: 69.6%; Average loss: 0.0006\n",
      "Iteration: 2785; Percent complete: 69.6%; Average loss: 0.0007\n",
      "Iteration: 2786; Percent complete: 69.7%; Average loss: 0.0006\n",
      "Iteration: 2787; Percent complete: 69.7%; Average loss: 0.0007\n",
      "Iteration: 2788; Percent complete: 69.7%; Average loss: 0.0006\n",
      "Iteration: 2789; Percent complete: 69.7%; Average loss: 0.0006\n",
      "Iteration: 2790; Percent complete: 69.8%; Average loss: 0.0006\n",
      "Iteration: 2791; Percent complete: 69.8%; Average loss: 0.0006\n",
      "Iteration: 2792; Percent complete: 69.8%; Average loss: 0.0007\n",
      "Iteration: 2793; Percent complete: 69.8%; Average loss: 0.0006\n",
      "Iteration: 2794; Percent complete: 69.8%; Average loss: 0.0006\n",
      "Iteration: 2795; Percent complete: 69.9%; Average loss: 0.0006\n",
      "Iteration: 2796; Percent complete: 69.9%; Average loss: 0.0007\n",
      "Iteration: 2797; Percent complete: 69.9%; Average loss: 0.0007\n",
      "Iteration: 2798; Percent complete: 70.0%; Average loss: 0.0007\n",
      "Iteration: 2799; Percent complete: 70.0%; Average loss: 0.0007\n",
      "Iteration: 2800; Percent complete: 70.0%; Average loss: 0.0007\n",
      "Iteration: 2801; Percent complete: 70.0%; Average loss: 0.0007\n",
      "Iteration: 2802; Percent complete: 70.0%; Average loss: 0.0007\n",
      "Iteration: 2803; Percent complete: 70.1%; Average loss: 0.0007\n",
      "Iteration: 2804; Percent complete: 70.1%; Average loss: 0.0006\n",
      "Iteration: 2805; Percent complete: 70.1%; Average loss: 0.0007\n",
      "Iteration: 2806; Percent complete: 70.2%; Average loss: 0.0007\n",
      "Iteration: 2807; Percent complete: 70.2%; Average loss: 0.0006\n",
      "Iteration: 2808; Percent complete: 70.2%; Average loss: 0.0007\n",
      "Iteration: 2809; Percent complete: 70.2%; Average loss: 0.0006\n",
      "Iteration: 2810; Percent complete: 70.2%; Average loss: 0.0006\n",
      "Iteration: 2811; Percent complete: 70.3%; Average loss: 0.0007\n",
      "Iteration: 2812; Percent complete: 70.3%; Average loss: 0.0006\n",
      "Iteration: 2813; Percent complete: 70.3%; Average loss: 0.0006\n",
      "Iteration: 2814; Percent complete: 70.3%; Average loss: 0.0007\n",
      "Iteration: 2815; Percent complete: 70.4%; Average loss: 0.0006\n",
      "Iteration: 2816; Percent complete: 70.4%; Average loss: 0.0006\n",
      "Iteration: 2817; Percent complete: 70.4%; Average loss: 0.0007\n",
      "Iteration: 2818; Percent complete: 70.5%; Average loss: 0.0007\n",
      "Iteration: 2819; Percent complete: 70.5%; Average loss: 0.0006\n",
      "Iteration: 2820; Percent complete: 70.5%; Average loss: 0.0007\n",
      "Iteration: 2821; Percent complete: 70.5%; Average loss: 0.0006\n",
      "Iteration: 2822; Percent complete: 70.5%; Average loss: 0.0006\n",
      "Iteration: 2823; Percent complete: 70.6%; Average loss: 0.0006\n",
      "Iteration: 2824; Percent complete: 70.6%; Average loss: 0.0006\n",
      "Iteration: 2825; Percent complete: 70.6%; Average loss: 0.0007\n",
      "Iteration: 2826; Percent complete: 70.7%; Average loss: 0.0006\n",
      "Iteration: 2827; Percent complete: 70.7%; Average loss: 0.0006\n",
      "Iteration: 2828; Percent complete: 70.7%; Average loss: 0.0007\n",
      "Iteration: 2829; Percent complete: 70.7%; Average loss: 0.0007\n",
      "Iteration: 2830; Percent complete: 70.8%; Average loss: 0.0006\n",
      "Iteration: 2831; Percent complete: 70.8%; Average loss: 0.0007\n",
      "Iteration: 2832; Percent complete: 70.8%; Average loss: 0.0007\n",
      "Iteration: 2833; Percent complete: 70.8%; Average loss: 0.0007\n",
      "Iteration: 2834; Percent complete: 70.9%; Average loss: 0.0007\n",
      "Iteration: 2835; Percent complete: 70.9%; Average loss: 0.0007\n",
      "Iteration: 2836; Percent complete: 70.9%; Average loss: 0.0006\n",
      "Iteration: 2837; Percent complete: 70.9%; Average loss: 0.0006\n",
      "Iteration: 2838; Percent complete: 71.0%; Average loss: 0.0007\n",
      "Iteration: 2839; Percent complete: 71.0%; Average loss: 0.0007\n",
      "Iteration: 2840; Percent complete: 71.0%; Average loss: 0.0006\n",
      "Iteration: 2841; Percent complete: 71.0%; Average loss: 0.0006\n",
      "Iteration: 2842; Percent complete: 71.0%; Average loss: 0.0006\n",
      "Iteration: 2843; Percent complete: 71.1%; Average loss: 0.0006\n",
      "Iteration: 2844; Percent complete: 71.1%; Average loss: 0.0006\n",
      "Iteration: 2845; Percent complete: 71.1%; Average loss: 0.0006\n",
      "Iteration: 2846; Percent complete: 71.2%; Average loss: 0.0006\n",
      "Iteration: 2847; Percent complete: 71.2%; Average loss: 0.0006\n",
      "Iteration: 2848; Percent complete: 71.2%; Average loss: 0.0007\n",
      "Iteration: 2849; Percent complete: 71.2%; Average loss: 0.0006\n",
      "Iteration: 2850; Percent complete: 71.2%; Average loss: 0.0006\n",
      "Iteration: 2851; Percent complete: 71.3%; Average loss: 0.0006\n",
      "Iteration: 2852; Percent complete: 71.3%; Average loss: 0.0006\n",
      "Iteration: 2853; Percent complete: 71.3%; Average loss: 0.0007\n",
      "Iteration: 2854; Percent complete: 71.4%; Average loss: 0.0005\n",
      "Iteration: 2855; Percent complete: 71.4%; Average loss: 0.0006\n",
      "Iteration: 2856; Percent complete: 71.4%; Average loss: 0.0007\n",
      "Iteration: 2857; Percent complete: 71.4%; Average loss: 0.0006\n",
      "Iteration: 2858; Percent complete: 71.5%; Average loss: 0.0006\n",
      "Iteration: 2859; Percent complete: 71.5%; Average loss: 0.0006\n",
      "Iteration: 2860; Percent complete: 71.5%; Average loss: 0.0006\n",
      "Iteration: 2861; Percent complete: 71.5%; Average loss: 0.0006\n",
      "Iteration: 2862; Percent complete: 71.5%; Average loss: 0.0006\n",
      "Iteration: 2863; Percent complete: 71.6%; Average loss: 0.0007\n",
      "Iteration: 2864; Percent complete: 71.6%; Average loss: 0.0006\n",
      "Iteration: 2865; Percent complete: 71.6%; Average loss: 0.0006\n",
      "Iteration: 2866; Percent complete: 71.7%; Average loss: 0.0006\n",
      "Iteration: 2867; Percent complete: 71.7%; Average loss: 0.0006\n",
      "Iteration: 2868; Percent complete: 71.7%; Average loss: 0.0006\n",
      "Iteration: 2869; Percent complete: 71.7%; Average loss: 0.0006\n",
      "Iteration: 2870; Percent complete: 71.8%; Average loss: 0.0006\n",
      "Iteration: 2871; Percent complete: 71.8%; Average loss: 0.0006\n",
      "Iteration: 2872; Percent complete: 71.8%; Average loss: 0.0006\n",
      "Iteration: 2873; Percent complete: 71.8%; Average loss: 0.0006\n",
      "Iteration: 2874; Percent complete: 71.9%; Average loss: 0.0006\n",
      "Iteration: 2875; Percent complete: 71.9%; Average loss: 0.0006\n",
      "Iteration: 2876; Percent complete: 71.9%; Average loss: 0.0006\n",
      "Iteration: 2877; Percent complete: 71.9%; Average loss: 0.0007\n",
      "Iteration: 2878; Percent complete: 72.0%; Average loss: 0.0006\n",
      "Iteration: 2879; Percent complete: 72.0%; Average loss: 0.0006\n",
      "Iteration: 2880; Percent complete: 72.0%; Average loss: 0.0006\n",
      "Iteration: 2881; Percent complete: 72.0%; Average loss: 0.0007\n",
      "Iteration: 2882; Percent complete: 72.0%; Average loss: 0.0006\n",
      "Iteration: 2883; Percent complete: 72.1%; Average loss: 0.0006\n",
      "Iteration: 2884; Percent complete: 72.1%; Average loss: 0.0006\n",
      "Iteration: 2885; Percent complete: 72.1%; Average loss: 0.0006\n",
      "Iteration: 2886; Percent complete: 72.2%; Average loss: 0.0006\n",
      "Iteration: 2887; Percent complete: 72.2%; Average loss: 0.0007\n",
      "Iteration: 2888; Percent complete: 72.2%; Average loss: 0.0006\n",
      "Iteration: 2889; Percent complete: 72.2%; Average loss: 0.0005\n",
      "Iteration: 2890; Percent complete: 72.2%; Average loss: 0.0006\n",
      "Iteration: 2891; Percent complete: 72.3%; Average loss: 0.0006\n",
      "Iteration: 2892; Percent complete: 72.3%; Average loss: 0.0006\n",
      "Iteration: 2893; Percent complete: 72.3%; Average loss: 0.0006\n",
      "Iteration: 2894; Percent complete: 72.4%; Average loss: 0.0006\n",
      "Iteration: 2895; Percent complete: 72.4%; Average loss: 0.0007\n",
      "Iteration: 2896; Percent complete: 72.4%; Average loss: 0.0006\n",
      "Iteration: 2897; Percent complete: 72.4%; Average loss: 0.0006\n",
      "Iteration: 2898; Percent complete: 72.5%; Average loss: 0.0006\n",
      "Iteration: 2899; Percent complete: 72.5%; Average loss: 0.0006\n",
      "Iteration: 2900; Percent complete: 72.5%; Average loss: 0.0006\n",
      "Iteration: 2901; Percent complete: 72.5%; Average loss: 0.0006\n",
      "Iteration: 2902; Percent complete: 72.5%; Average loss: 0.0006\n",
      "Iteration: 2903; Percent complete: 72.6%; Average loss: 0.0006\n",
      "Iteration: 2904; Percent complete: 72.6%; Average loss: 0.0006\n",
      "Iteration: 2905; Percent complete: 72.6%; Average loss: 0.0006\n",
      "Iteration: 2906; Percent complete: 72.7%; Average loss: 0.0006\n",
      "Iteration: 2907; Percent complete: 72.7%; Average loss: 0.0006\n",
      "Iteration: 2908; Percent complete: 72.7%; Average loss: 0.0006\n",
      "Iteration: 2909; Percent complete: 72.7%; Average loss: 0.0006\n",
      "Iteration: 2910; Percent complete: 72.8%; Average loss: 0.0006\n",
      "Iteration: 2911; Percent complete: 72.8%; Average loss: 0.0006\n",
      "Iteration: 2912; Percent complete: 72.8%; Average loss: 0.0006\n",
      "Iteration: 2913; Percent complete: 72.8%; Average loss: 0.0007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2914; Percent complete: 72.9%; Average loss: 0.0006\n",
      "Iteration: 2915; Percent complete: 72.9%; Average loss: 0.0006\n",
      "Iteration: 2916; Percent complete: 72.9%; Average loss: 0.0006\n",
      "Iteration: 2917; Percent complete: 72.9%; Average loss: 0.0006\n",
      "Iteration: 2918; Percent complete: 73.0%; Average loss: 0.0006\n",
      "Iteration: 2919; Percent complete: 73.0%; Average loss: 0.0006\n",
      "Iteration: 2920; Percent complete: 73.0%; Average loss: 0.0006\n",
      "Iteration: 2921; Percent complete: 73.0%; Average loss: 0.0006\n",
      "Iteration: 2922; Percent complete: 73.0%; Average loss: 0.0006\n",
      "Iteration: 2923; Percent complete: 73.1%; Average loss: 0.0006\n",
      "Iteration: 2924; Percent complete: 73.1%; Average loss: 0.0006\n",
      "Iteration: 2925; Percent complete: 73.1%; Average loss: 0.0006\n",
      "Iteration: 2926; Percent complete: 73.2%; Average loss: 0.0005\n",
      "Iteration: 2927; Percent complete: 73.2%; Average loss: 0.0006\n",
      "Iteration: 2928; Percent complete: 73.2%; Average loss: 0.0006\n",
      "Iteration: 2929; Percent complete: 73.2%; Average loss: 0.0006\n",
      "Iteration: 2930; Percent complete: 73.2%; Average loss: 0.0006\n",
      "Iteration: 2931; Percent complete: 73.3%; Average loss: 0.0006\n",
      "Iteration: 2932; Percent complete: 73.3%; Average loss: 0.0006\n",
      "Iteration: 2933; Percent complete: 73.3%; Average loss: 0.0006\n",
      "Iteration: 2934; Percent complete: 73.4%; Average loss: 0.0006\n",
      "Iteration: 2935; Percent complete: 73.4%; Average loss: 0.0006\n",
      "Iteration: 2936; Percent complete: 73.4%; Average loss: 0.0006\n",
      "Iteration: 2937; Percent complete: 73.4%; Average loss: 0.0005\n",
      "Iteration: 2938; Percent complete: 73.5%; Average loss: 0.0006\n",
      "Iteration: 2939; Percent complete: 73.5%; Average loss: 0.0006\n",
      "Iteration: 2940; Percent complete: 73.5%; Average loss: 0.0006\n",
      "Iteration: 2941; Percent complete: 73.5%; Average loss: 0.0006\n",
      "Iteration: 2942; Percent complete: 73.6%; Average loss: 0.0006\n",
      "Iteration: 2943; Percent complete: 73.6%; Average loss: 0.0006\n",
      "Iteration: 2944; Percent complete: 73.6%; Average loss: 0.0006\n",
      "Iteration: 2945; Percent complete: 73.6%; Average loss: 0.0006\n",
      "Iteration: 2946; Percent complete: 73.7%; Average loss: 0.0006\n",
      "Iteration: 2947; Percent complete: 73.7%; Average loss: 0.0006\n",
      "Iteration: 2948; Percent complete: 73.7%; Average loss: 0.0006\n",
      "Iteration: 2949; Percent complete: 73.7%; Average loss: 0.0006\n",
      "Iteration: 2950; Percent complete: 73.8%; Average loss: 0.0006\n",
      "Iteration: 2951; Percent complete: 73.8%; Average loss: 0.0006\n",
      "Iteration: 2952; Percent complete: 73.8%; Average loss: 0.0005\n",
      "Iteration: 2953; Percent complete: 73.8%; Average loss: 0.0005\n",
      "Iteration: 2954; Percent complete: 73.9%; Average loss: 0.0006\n",
      "Iteration: 2955; Percent complete: 73.9%; Average loss: 0.0006\n",
      "Iteration: 2956; Percent complete: 73.9%; Average loss: 0.0006\n",
      "Iteration: 2957; Percent complete: 73.9%; Average loss: 0.0006\n",
      "Iteration: 2958; Percent complete: 74.0%; Average loss: 0.0005\n",
      "Iteration: 2959; Percent complete: 74.0%; Average loss: 0.0006\n",
      "Iteration: 2960; Percent complete: 74.0%; Average loss: 0.0005\n",
      "Iteration: 2961; Percent complete: 74.0%; Average loss: 0.0006\n",
      "Iteration: 2962; Percent complete: 74.1%; Average loss: 0.0006\n",
      "Iteration: 2963; Percent complete: 74.1%; Average loss: 0.0006\n",
      "Iteration: 2964; Percent complete: 74.1%; Average loss: 0.0006\n",
      "Iteration: 2965; Percent complete: 74.1%; Average loss: 0.0006\n",
      "Iteration: 2966; Percent complete: 74.2%; Average loss: 0.0006\n",
      "Iteration: 2967; Percent complete: 74.2%; Average loss: 0.0006\n",
      "Iteration: 2968; Percent complete: 74.2%; Average loss: 0.0006\n",
      "Iteration: 2969; Percent complete: 74.2%; Average loss: 0.0006\n",
      "Iteration: 2970; Percent complete: 74.2%; Average loss: 0.0006\n",
      "Iteration: 2971; Percent complete: 74.3%; Average loss: 0.0006\n",
      "Iteration: 2972; Percent complete: 74.3%; Average loss: 0.0006\n",
      "Iteration: 2973; Percent complete: 74.3%; Average loss: 0.0005\n",
      "Iteration: 2974; Percent complete: 74.4%; Average loss: 0.0006\n",
      "Iteration: 2975; Percent complete: 74.4%; Average loss: 0.0005\n",
      "Iteration: 2976; Percent complete: 74.4%; Average loss: 0.0006\n",
      "Iteration: 2977; Percent complete: 74.4%; Average loss: 0.0005\n",
      "Iteration: 2978; Percent complete: 74.5%; Average loss: 0.0005\n",
      "Iteration: 2979; Percent complete: 74.5%; Average loss: 0.0005\n",
      "Iteration: 2980; Percent complete: 74.5%; Average loss: 0.0005\n",
      "Iteration: 2981; Percent complete: 74.5%; Average loss: 0.0005\n",
      "Iteration: 2982; Percent complete: 74.6%; Average loss: 0.0006\n",
      "Iteration: 2983; Percent complete: 74.6%; Average loss: 0.0006\n",
      "Iteration: 2984; Percent complete: 74.6%; Average loss: 0.0006\n",
      "Iteration: 2985; Percent complete: 74.6%; Average loss: 0.0006\n",
      "Iteration: 2986; Percent complete: 74.7%; Average loss: 0.0006\n",
      "Iteration: 2987; Percent complete: 74.7%; Average loss: 0.0006\n",
      "Iteration: 2988; Percent complete: 74.7%; Average loss: 0.0006\n",
      "Iteration: 2989; Percent complete: 74.7%; Average loss: 0.0005\n",
      "Iteration: 2990; Percent complete: 74.8%; Average loss: 0.0005\n",
      "Iteration: 2991; Percent complete: 74.8%; Average loss: 0.0006\n",
      "Iteration: 2992; Percent complete: 74.8%; Average loss: 0.0006\n",
      "Iteration: 2993; Percent complete: 74.8%; Average loss: 0.0005\n",
      "Iteration: 2994; Percent complete: 74.9%; Average loss: 0.0006\n",
      "Iteration: 2995; Percent complete: 74.9%; Average loss: 0.0006\n",
      "Iteration: 2996; Percent complete: 74.9%; Average loss: 0.0005\n",
      "Iteration: 2997; Percent complete: 74.9%; Average loss: 0.0005\n",
      "Iteration: 2998; Percent complete: 75.0%; Average loss: 0.0006\n",
      "Iteration: 2999; Percent complete: 75.0%; Average loss: 0.0005\n",
      "Iteration: 3000; Percent complete: 75.0%; Average loss: 0.0006\n",
      "Iteration: 3001; Percent complete: 75.0%; Average loss: 0.0005\n",
      "Iteration: 3002; Percent complete: 75.0%; Average loss: 0.0006\n",
      "Iteration: 3003; Percent complete: 75.1%; Average loss: 0.0005\n",
      "Iteration: 3004; Percent complete: 75.1%; Average loss: 0.0005\n",
      "Iteration: 3005; Percent complete: 75.1%; Average loss: 0.0006\n",
      "Iteration: 3006; Percent complete: 75.1%; Average loss: 0.0005\n",
      "Iteration: 3007; Percent complete: 75.2%; Average loss: 0.0006\n",
      "Iteration: 3008; Percent complete: 75.2%; Average loss: 0.0006\n",
      "Iteration: 3009; Percent complete: 75.2%; Average loss: 0.0006\n",
      "Iteration: 3010; Percent complete: 75.2%; Average loss: 0.0006\n",
      "Iteration: 3011; Percent complete: 75.3%; Average loss: 0.0005\n",
      "Iteration: 3012; Percent complete: 75.3%; Average loss: 0.0006\n",
      "Iteration: 3013; Percent complete: 75.3%; Average loss: 0.0006\n",
      "Iteration: 3014; Percent complete: 75.3%; Average loss: 0.0005\n",
      "Iteration: 3015; Percent complete: 75.4%; Average loss: 0.0005\n",
      "Iteration: 3016; Percent complete: 75.4%; Average loss: 0.0006\n",
      "Iteration: 3017; Percent complete: 75.4%; Average loss: 0.0005\n",
      "Iteration: 3018; Percent complete: 75.4%; Average loss: 0.0006\n",
      "Iteration: 3019; Percent complete: 75.5%; Average loss: 0.0006\n",
      "Iteration: 3020; Percent complete: 75.5%; Average loss: 0.0006\n",
      "Iteration: 3021; Percent complete: 75.5%; Average loss: 0.0006\n",
      "Iteration: 3022; Percent complete: 75.5%; Average loss: 0.0006\n",
      "Iteration: 3023; Percent complete: 75.6%; Average loss: 0.0005\n",
      "Iteration: 3024; Percent complete: 75.6%; Average loss: 0.0005\n",
      "Iteration: 3025; Percent complete: 75.6%; Average loss: 0.0006\n",
      "Iteration: 3026; Percent complete: 75.6%; Average loss: 0.0005\n",
      "Iteration: 3027; Percent complete: 75.7%; Average loss: 0.0006\n",
      "Iteration: 3028; Percent complete: 75.7%; Average loss: 0.0006\n",
      "Iteration: 3029; Percent complete: 75.7%; Average loss: 0.0006\n",
      "Iteration: 3030; Percent complete: 75.8%; Average loss: 0.0006\n",
      "Iteration: 3031; Percent complete: 75.8%; Average loss: 0.0006\n",
      "Iteration: 3032; Percent complete: 75.8%; Average loss: 0.0005\n",
      "Iteration: 3033; Percent complete: 75.8%; Average loss: 0.0006\n",
      "Iteration: 3034; Percent complete: 75.8%; Average loss: 0.0005\n",
      "Iteration: 3035; Percent complete: 75.9%; Average loss: 0.0006\n",
      "Iteration: 3036; Percent complete: 75.9%; Average loss: 0.0005\n",
      "Iteration: 3037; Percent complete: 75.9%; Average loss: 0.0006\n",
      "Iteration: 3038; Percent complete: 75.9%; Average loss: 0.0005\n",
      "Iteration: 3039; Percent complete: 76.0%; Average loss: 0.0005\n",
      "Iteration: 3040; Percent complete: 76.0%; Average loss: 0.0005\n",
      "Iteration: 3041; Percent complete: 76.0%; Average loss: 0.0006\n",
      "Iteration: 3042; Percent complete: 76.0%; Average loss: 0.0005\n",
      "Iteration: 3043; Percent complete: 76.1%; Average loss: 0.0005\n",
      "Iteration: 3044; Percent complete: 76.1%; Average loss: 0.0005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3045; Percent complete: 76.1%; Average loss: 0.0005\n",
      "Iteration: 3046; Percent complete: 76.1%; Average loss: 0.0005\n",
      "Iteration: 3047; Percent complete: 76.2%; Average loss: 0.0005\n",
      "Iteration: 3048; Percent complete: 76.2%; Average loss: 0.0005\n",
      "Iteration: 3049; Percent complete: 76.2%; Average loss: 0.0005\n",
      "Iteration: 3050; Percent complete: 76.2%; Average loss: 0.0006\n",
      "Iteration: 3051; Percent complete: 76.3%; Average loss: 0.0005\n",
      "Iteration: 3052; Percent complete: 76.3%; Average loss: 0.0005\n",
      "Iteration: 3053; Percent complete: 76.3%; Average loss: 0.0005\n",
      "Iteration: 3054; Percent complete: 76.3%; Average loss: 0.0005\n",
      "Iteration: 3055; Percent complete: 76.4%; Average loss: 0.0005\n",
      "Iteration: 3056; Percent complete: 76.4%; Average loss: 0.0005\n",
      "Iteration: 3057; Percent complete: 76.4%; Average loss: 0.0006\n",
      "Iteration: 3058; Percent complete: 76.4%; Average loss: 0.0006\n",
      "Iteration: 3059; Percent complete: 76.5%; Average loss: 0.0005\n",
      "Iteration: 3060; Percent complete: 76.5%; Average loss: 0.0006\n",
      "Iteration: 3061; Percent complete: 76.5%; Average loss: 0.0005\n",
      "Iteration: 3062; Percent complete: 76.5%; Average loss: 0.0006\n",
      "Iteration: 3063; Percent complete: 76.6%; Average loss: 0.0005\n",
      "Iteration: 3064; Percent complete: 76.6%; Average loss: 0.0005\n",
      "Iteration: 3065; Percent complete: 76.6%; Average loss: 0.0005\n",
      "Iteration: 3066; Percent complete: 76.6%; Average loss: 0.0006\n",
      "Iteration: 3067; Percent complete: 76.7%; Average loss: 0.0005\n",
      "Iteration: 3068; Percent complete: 76.7%; Average loss: 0.0005\n",
      "Iteration: 3069; Percent complete: 76.7%; Average loss: 0.0005\n",
      "Iteration: 3070; Percent complete: 76.8%; Average loss: 0.0005\n",
      "Iteration: 3071; Percent complete: 76.8%; Average loss: 0.0005\n",
      "Iteration: 3072; Percent complete: 76.8%; Average loss: 0.0005\n",
      "Iteration: 3073; Percent complete: 76.8%; Average loss: 0.0006\n",
      "Iteration: 3074; Percent complete: 76.8%; Average loss: 0.0005\n",
      "Iteration: 3075; Percent complete: 76.9%; Average loss: 0.0005\n",
      "Iteration: 3076; Percent complete: 76.9%; Average loss: 0.0005\n",
      "Iteration: 3077; Percent complete: 76.9%; Average loss: 0.0006\n",
      "Iteration: 3078; Percent complete: 77.0%; Average loss: 0.0005\n",
      "Iteration: 3079; Percent complete: 77.0%; Average loss: 0.0005\n",
      "Iteration: 3080; Percent complete: 77.0%; Average loss: 0.0005\n",
      "Iteration: 3081; Percent complete: 77.0%; Average loss: 0.0005\n",
      "Iteration: 3082; Percent complete: 77.0%; Average loss: 0.0005\n",
      "Iteration: 3083; Percent complete: 77.1%; Average loss: 0.0005\n",
      "Iteration: 3084; Percent complete: 77.1%; Average loss: 0.0005\n",
      "Iteration: 3085; Percent complete: 77.1%; Average loss: 0.0005\n",
      "Iteration: 3086; Percent complete: 77.1%; Average loss: 0.0005\n",
      "Iteration: 3087; Percent complete: 77.2%; Average loss: 0.0005\n",
      "Iteration: 3088; Percent complete: 77.2%; Average loss: 0.0005\n",
      "Iteration: 3089; Percent complete: 77.2%; Average loss: 0.0005\n",
      "Iteration: 3090; Percent complete: 77.2%; Average loss: 0.0005\n",
      "Iteration: 3091; Percent complete: 77.3%; Average loss: 0.0005\n",
      "Iteration: 3092; Percent complete: 77.3%; Average loss: 0.0005\n",
      "Iteration: 3093; Percent complete: 77.3%; Average loss: 0.0005\n",
      "Iteration: 3094; Percent complete: 77.3%; Average loss: 0.0006\n",
      "Iteration: 3095; Percent complete: 77.4%; Average loss: 0.0006\n",
      "Iteration: 3096; Percent complete: 77.4%; Average loss: 0.0006\n",
      "Iteration: 3097; Percent complete: 77.4%; Average loss: 0.0005\n",
      "Iteration: 3098; Percent complete: 77.5%; Average loss: 0.0005\n",
      "Iteration: 3099; Percent complete: 77.5%; Average loss: 0.0005\n",
      "Iteration: 3100; Percent complete: 77.5%; Average loss: 0.0005\n",
      "Iteration: 3101; Percent complete: 77.5%; Average loss: 0.0005\n",
      "Iteration: 3102; Percent complete: 77.5%; Average loss: 0.0005\n",
      "Iteration: 3103; Percent complete: 77.6%; Average loss: 0.0005\n",
      "Iteration: 3104; Percent complete: 77.6%; Average loss: 0.0005\n",
      "Iteration: 3105; Percent complete: 77.6%; Average loss: 0.0006\n",
      "Iteration: 3106; Percent complete: 77.6%; Average loss: 0.0005\n",
      "Iteration: 3107; Percent complete: 77.7%; Average loss: 0.0005\n",
      "Iteration: 3108; Percent complete: 77.7%; Average loss: 0.0005\n",
      "Iteration: 3109; Percent complete: 77.7%; Average loss: 0.0005\n",
      "Iteration: 3110; Percent complete: 77.8%; Average loss: 0.0005\n",
      "Iteration: 3111; Percent complete: 77.8%; Average loss: 0.0006\n",
      "Iteration: 3112; Percent complete: 77.8%; Average loss: 0.0005\n",
      "Iteration: 3113; Percent complete: 77.8%; Average loss: 0.0005\n",
      "Iteration: 3114; Percent complete: 77.8%; Average loss: 0.0005\n",
      "Iteration: 3115; Percent complete: 77.9%; Average loss: 0.0005\n",
      "Iteration: 3116; Percent complete: 77.9%; Average loss: 0.0006\n",
      "Iteration: 3117; Percent complete: 77.9%; Average loss: 0.0005\n",
      "Iteration: 3118; Percent complete: 78.0%; Average loss: 0.0005\n",
      "Iteration: 3119; Percent complete: 78.0%; Average loss: 0.0005\n",
      "Iteration: 3120; Percent complete: 78.0%; Average loss: 0.0006\n",
      "Iteration: 3121; Percent complete: 78.0%; Average loss: 0.0006\n",
      "Iteration: 3122; Percent complete: 78.0%; Average loss: 0.0005\n",
      "Iteration: 3123; Percent complete: 78.1%; Average loss: 0.0005\n",
      "Iteration: 3124; Percent complete: 78.1%; Average loss: 0.0005\n",
      "Iteration: 3125; Percent complete: 78.1%; Average loss: 0.0005\n",
      "Iteration: 3126; Percent complete: 78.1%; Average loss: 0.0005\n",
      "Iteration: 3127; Percent complete: 78.2%; Average loss: 0.0005\n",
      "Iteration: 3128; Percent complete: 78.2%; Average loss: 0.0005\n",
      "Iteration: 3129; Percent complete: 78.2%; Average loss: 0.0005\n",
      "Iteration: 3130; Percent complete: 78.2%; Average loss: 0.0005\n",
      "Iteration: 3131; Percent complete: 78.3%; Average loss: 0.0005\n",
      "Iteration: 3132; Percent complete: 78.3%; Average loss: 0.0005\n",
      "Iteration: 3133; Percent complete: 78.3%; Average loss: 0.0005\n",
      "Iteration: 3134; Percent complete: 78.3%; Average loss: 0.0005\n",
      "Iteration: 3135; Percent complete: 78.4%; Average loss: 0.0005\n",
      "Iteration: 3136; Percent complete: 78.4%; Average loss: 0.0005\n",
      "Iteration: 3137; Percent complete: 78.4%; Average loss: 0.0005\n",
      "Iteration: 3138; Percent complete: 78.5%; Average loss: 0.0005\n",
      "Iteration: 3139; Percent complete: 78.5%; Average loss: 0.0005\n",
      "Iteration: 3140; Percent complete: 78.5%; Average loss: 0.0005\n",
      "Iteration: 3141; Percent complete: 78.5%; Average loss: 0.0005\n",
      "Iteration: 3142; Percent complete: 78.5%; Average loss: 0.0005\n",
      "Iteration: 3143; Percent complete: 78.6%; Average loss: 0.0005\n",
      "Iteration: 3144; Percent complete: 78.6%; Average loss: 0.0005\n",
      "Iteration: 3145; Percent complete: 78.6%; Average loss: 0.0005\n",
      "Iteration: 3146; Percent complete: 78.6%; Average loss: 0.0005\n",
      "Iteration: 3147; Percent complete: 78.7%; Average loss: 0.0005\n",
      "Iteration: 3148; Percent complete: 78.7%; Average loss: 0.0005\n",
      "Iteration: 3149; Percent complete: 78.7%; Average loss: 0.0005\n",
      "Iteration: 3150; Percent complete: 78.8%; Average loss: 0.0005\n",
      "Iteration: 3151; Percent complete: 78.8%; Average loss: 0.0005\n",
      "Iteration: 3152; Percent complete: 78.8%; Average loss: 0.0005\n",
      "Iteration: 3153; Percent complete: 78.8%; Average loss: 0.0005\n",
      "Iteration: 3154; Percent complete: 78.8%; Average loss: 0.0005\n",
      "Iteration: 3155; Percent complete: 78.9%; Average loss: 0.0005\n",
      "Iteration: 3156; Percent complete: 78.9%; Average loss: 0.0005\n",
      "Iteration: 3157; Percent complete: 78.9%; Average loss: 0.0005\n",
      "Iteration: 3158; Percent complete: 79.0%; Average loss: 0.0005\n",
      "Iteration: 3159; Percent complete: 79.0%; Average loss: 0.0005\n",
      "Iteration: 3160; Percent complete: 79.0%; Average loss: 0.0005\n",
      "Iteration: 3161; Percent complete: 79.0%; Average loss: 0.0005\n",
      "Iteration: 3162; Percent complete: 79.0%; Average loss: 0.0005\n",
      "Iteration: 3163; Percent complete: 79.1%; Average loss: 0.0005\n",
      "Iteration: 3164; Percent complete: 79.1%; Average loss: 0.0006\n",
      "Iteration: 3165; Percent complete: 79.1%; Average loss: 0.0005\n",
      "Iteration: 3166; Percent complete: 79.1%; Average loss: 0.0005\n",
      "Iteration: 3167; Percent complete: 79.2%; Average loss: 0.0005\n",
      "Iteration: 3168; Percent complete: 79.2%; Average loss: 0.0005\n",
      "Iteration: 3169; Percent complete: 79.2%; Average loss: 0.0005\n",
      "Iteration: 3170; Percent complete: 79.2%; Average loss: 0.0005\n",
      "Iteration: 3171; Percent complete: 79.3%; Average loss: 0.0005\n",
      "Iteration: 3172; Percent complete: 79.3%; Average loss: 0.0005\n",
      "Iteration: 3173; Percent complete: 79.3%; Average loss: 0.0005\n",
      "Iteration: 3174; Percent complete: 79.3%; Average loss: 0.0005\n",
      "Iteration: 3175; Percent complete: 79.4%; Average loss: 0.0005\n",
      "Iteration: 3176; Percent complete: 79.4%; Average loss: 0.0005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3177; Percent complete: 79.4%; Average loss: 0.0005\n",
      "Iteration: 3178; Percent complete: 79.5%; Average loss: 0.0005\n",
      "Iteration: 3179; Percent complete: 79.5%; Average loss: 0.0005\n",
      "Iteration: 3180; Percent complete: 79.5%; Average loss: 0.0005\n",
      "Iteration: 3181; Percent complete: 79.5%; Average loss: 0.0005\n",
      "Iteration: 3182; Percent complete: 79.5%; Average loss: 0.0005\n",
      "Iteration: 3183; Percent complete: 79.6%; Average loss: 0.0005\n",
      "Iteration: 3184; Percent complete: 79.6%; Average loss: 0.0005\n",
      "Iteration: 3185; Percent complete: 79.6%; Average loss: 0.0005\n",
      "Iteration: 3186; Percent complete: 79.7%; Average loss: 0.0004\n",
      "Iteration: 3187; Percent complete: 79.7%; Average loss: 0.0005\n",
      "Iteration: 3188; Percent complete: 79.7%; Average loss: 0.0005\n",
      "Iteration: 3189; Percent complete: 79.7%; Average loss: 0.0005\n",
      "Iteration: 3190; Percent complete: 79.8%; Average loss: 0.0005\n",
      "Iteration: 3191; Percent complete: 79.8%; Average loss: 0.0004\n",
      "Iteration: 3192; Percent complete: 79.8%; Average loss: 0.0005\n",
      "Iteration: 3193; Percent complete: 79.8%; Average loss: 0.0005\n",
      "Iteration: 3194; Percent complete: 79.8%; Average loss: 0.0004\n",
      "Iteration: 3195; Percent complete: 79.9%; Average loss: 0.0005\n",
      "Iteration: 3196; Percent complete: 79.9%; Average loss: 0.0005\n",
      "Iteration: 3197; Percent complete: 79.9%; Average loss: 0.0005\n",
      "Iteration: 3198; Percent complete: 80.0%; Average loss: 0.0005\n",
      "Iteration: 3199; Percent complete: 80.0%; Average loss: 0.0005\n",
      "Iteration: 3200; Percent complete: 80.0%; Average loss: 0.0005\n",
      "Iteration: 3201; Percent complete: 80.0%; Average loss: 0.0005\n",
      "Iteration: 3202; Percent complete: 80.0%; Average loss: 0.0005\n",
      "Iteration: 3203; Percent complete: 80.1%; Average loss: 0.0005\n",
      "Iteration: 3204; Percent complete: 80.1%; Average loss: 0.0005\n",
      "Iteration: 3205; Percent complete: 80.1%; Average loss: 0.0005\n",
      "Iteration: 3206; Percent complete: 80.2%; Average loss: 0.0005\n",
      "Iteration: 3207; Percent complete: 80.2%; Average loss: 0.0005\n",
      "Iteration: 3208; Percent complete: 80.2%; Average loss: 0.0005\n",
      "Iteration: 3209; Percent complete: 80.2%; Average loss: 0.0005\n",
      "Iteration: 3210; Percent complete: 80.2%; Average loss: 0.0005\n",
      "Iteration: 3211; Percent complete: 80.3%; Average loss: 0.0005\n",
      "Iteration: 3212; Percent complete: 80.3%; Average loss: 0.0005\n",
      "Iteration: 3213; Percent complete: 80.3%; Average loss: 0.0005\n",
      "Iteration: 3214; Percent complete: 80.3%; Average loss: 0.0005\n",
      "Iteration: 3215; Percent complete: 80.4%; Average loss: 0.0004\n",
      "Iteration: 3216; Percent complete: 80.4%; Average loss: 0.0005\n",
      "Iteration: 3217; Percent complete: 80.4%; Average loss: 0.0005\n",
      "Iteration: 3218; Percent complete: 80.5%; Average loss: 0.0004\n",
      "Iteration: 3219; Percent complete: 80.5%; Average loss: 0.0005\n",
      "Iteration: 3220; Percent complete: 80.5%; Average loss: 0.0005\n",
      "Iteration: 3221; Percent complete: 80.5%; Average loss: 0.0005\n",
      "Iteration: 3222; Percent complete: 80.5%; Average loss: 0.0005\n",
      "Iteration: 3223; Percent complete: 80.6%; Average loss: 0.0004\n",
      "Iteration: 3224; Percent complete: 80.6%; Average loss: 0.0005\n",
      "Iteration: 3225; Percent complete: 80.6%; Average loss: 0.0005\n",
      "Iteration: 3226; Percent complete: 80.7%; Average loss: 0.0005\n",
      "Iteration: 3227; Percent complete: 80.7%; Average loss: 0.0005\n",
      "Iteration: 3228; Percent complete: 80.7%; Average loss: 0.0005\n",
      "Iteration: 3229; Percent complete: 80.7%; Average loss: 0.0005\n",
      "Iteration: 3230; Percent complete: 80.8%; Average loss: 0.0004\n",
      "Iteration: 3231; Percent complete: 80.8%; Average loss: 0.0005\n",
      "Iteration: 3232; Percent complete: 80.8%; Average loss: 0.0005\n",
      "Iteration: 3233; Percent complete: 80.8%; Average loss: 0.0005\n",
      "Iteration: 3234; Percent complete: 80.8%; Average loss: 0.0005\n",
      "Iteration: 3235; Percent complete: 80.9%; Average loss: 0.0004\n",
      "Iteration: 3236; Percent complete: 80.9%; Average loss: 0.0004\n",
      "Iteration: 3237; Percent complete: 80.9%; Average loss: 0.0005\n",
      "Iteration: 3238; Percent complete: 81.0%; Average loss: 0.0005\n",
      "Iteration: 3239; Percent complete: 81.0%; Average loss: 0.0005\n",
      "Iteration: 3240; Percent complete: 81.0%; Average loss: 0.0005\n",
      "Iteration: 3241; Percent complete: 81.0%; Average loss: 0.0005\n",
      "Iteration: 3242; Percent complete: 81.0%; Average loss: 0.0005\n",
      "Iteration: 3243; Percent complete: 81.1%; Average loss: 0.0005\n",
      "Iteration: 3244; Percent complete: 81.1%; Average loss: 0.0005\n",
      "Iteration: 3245; Percent complete: 81.1%; Average loss: 0.0005\n",
      "Iteration: 3246; Percent complete: 81.2%; Average loss: 0.0004\n",
      "Iteration: 3247; Percent complete: 81.2%; Average loss: 0.0004\n",
      "Iteration: 3248; Percent complete: 81.2%; Average loss: 0.0005\n",
      "Iteration: 3249; Percent complete: 81.2%; Average loss: 0.0004\n",
      "Iteration: 3250; Percent complete: 81.2%; Average loss: 0.0005\n",
      "Iteration: 3251; Percent complete: 81.3%; Average loss: 0.0005\n",
      "Iteration: 3252; Percent complete: 81.3%; Average loss: 0.0005\n",
      "Iteration: 3253; Percent complete: 81.3%; Average loss: 0.0004\n",
      "Iteration: 3254; Percent complete: 81.3%; Average loss: 0.0004\n",
      "Iteration: 3255; Percent complete: 81.4%; Average loss: 0.0005\n",
      "Iteration: 3256; Percent complete: 81.4%; Average loss: 0.0005\n",
      "Iteration: 3257; Percent complete: 81.4%; Average loss: 0.0005\n",
      "Iteration: 3258; Percent complete: 81.5%; Average loss: 0.0004\n",
      "Iteration: 3259; Percent complete: 81.5%; Average loss: 0.0005\n",
      "Iteration: 3260; Percent complete: 81.5%; Average loss: 0.0005\n",
      "Iteration: 3261; Percent complete: 81.5%; Average loss: 0.0004\n",
      "Iteration: 3262; Percent complete: 81.5%; Average loss: 0.0005\n",
      "Iteration: 3263; Percent complete: 81.6%; Average loss: 0.0004\n",
      "Iteration: 3264; Percent complete: 81.6%; Average loss: 0.0005\n",
      "Iteration: 3265; Percent complete: 81.6%; Average loss: 0.0004\n",
      "Iteration: 3266; Percent complete: 81.7%; Average loss: 0.0005\n",
      "Iteration: 3267; Percent complete: 81.7%; Average loss: 0.0004\n",
      "Iteration: 3268; Percent complete: 81.7%; Average loss: 0.0005\n",
      "Iteration: 3269; Percent complete: 81.7%; Average loss: 0.0004\n",
      "Iteration: 3270; Percent complete: 81.8%; Average loss: 0.0004\n",
      "Iteration: 3271; Percent complete: 81.8%; Average loss: 0.0005\n",
      "Iteration: 3272; Percent complete: 81.8%; Average loss: 0.0004\n",
      "Iteration: 3273; Percent complete: 81.8%; Average loss: 0.0004\n",
      "Iteration: 3274; Percent complete: 81.8%; Average loss: 0.0005\n",
      "Iteration: 3275; Percent complete: 81.9%; Average loss: 0.0005\n",
      "Iteration: 3276; Percent complete: 81.9%; Average loss: 0.0004\n",
      "Iteration: 3277; Percent complete: 81.9%; Average loss: 0.0004\n",
      "Iteration: 3278; Percent complete: 82.0%; Average loss: 0.0005\n",
      "Iteration: 3279; Percent complete: 82.0%; Average loss: 0.0005\n",
      "Iteration: 3280; Percent complete: 82.0%; Average loss: 0.0004\n",
      "Iteration: 3281; Percent complete: 82.0%; Average loss: 0.0005\n",
      "Iteration: 3282; Percent complete: 82.0%; Average loss: 0.0005\n",
      "Iteration: 3283; Percent complete: 82.1%; Average loss: 0.0005\n",
      "Iteration: 3284; Percent complete: 82.1%; Average loss: 0.0004\n",
      "Iteration: 3285; Percent complete: 82.1%; Average loss: 0.0005\n",
      "Iteration: 3286; Percent complete: 82.2%; Average loss: 0.0004\n",
      "Iteration: 3287; Percent complete: 82.2%; Average loss: 0.0004\n",
      "Iteration: 3288; Percent complete: 82.2%; Average loss: 0.0005\n",
      "Iteration: 3289; Percent complete: 82.2%; Average loss: 0.0004\n",
      "Iteration: 3290; Percent complete: 82.2%; Average loss: 0.0005\n",
      "Iteration: 3291; Percent complete: 82.3%; Average loss: 0.0005\n",
      "Iteration: 3292; Percent complete: 82.3%; Average loss: 0.0005\n",
      "Iteration: 3293; Percent complete: 82.3%; Average loss: 0.0005\n",
      "Iteration: 3294; Percent complete: 82.3%; Average loss: 0.0004\n",
      "Iteration: 3295; Percent complete: 82.4%; Average loss: 0.0004\n",
      "Iteration: 3296; Percent complete: 82.4%; Average loss: 0.0005\n",
      "Iteration: 3297; Percent complete: 82.4%; Average loss: 0.0004\n",
      "Iteration: 3298; Percent complete: 82.5%; Average loss: 0.0004\n",
      "Iteration: 3299; Percent complete: 82.5%; Average loss: 0.0005\n",
      "Iteration: 3300; Percent complete: 82.5%; Average loss: 0.0004\n",
      "Iteration: 3301; Percent complete: 82.5%; Average loss: 0.0005\n",
      "Iteration: 3302; Percent complete: 82.5%; Average loss: 0.0005\n",
      "Iteration: 3303; Percent complete: 82.6%; Average loss: 0.0005\n",
      "Iteration: 3304; Percent complete: 82.6%; Average loss: 0.0004\n",
      "Iteration: 3305; Percent complete: 82.6%; Average loss: 0.0005\n",
      "Iteration: 3306; Percent complete: 82.7%; Average loss: 0.0004\n",
      "Iteration: 3307; Percent complete: 82.7%; Average loss: 0.0005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3308; Percent complete: 82.7%; Average loss: 0.0004\n",
      "Iteration: 3309; Percent complete: 82.7%; Average loss: 0.0004\n",
      "Iteration: 3310; Percent complete: 82.8%; Average loss: 0.0004\n",
      "Iteration: 3311; Percent complete: 82.8%; Average loss: 0.0004\n",
      "Iteration: 3312; Percent complete: 82.8%; Average loss: 0.0004\n",
      "Iteration: 3313; Percent complete: 82.8%; Average loss: 0.0004\n",
      "Iteration: 3314; Percent complete: 82.8%; Average loss: 0.0005\n",
      "Iteration: 3315; Percent complete: 82.9%; Average loss: 0.0004\n",
      "Iteration: 3316; Percent complete: 82.9%; Average loss: 0.0004\n",
      "Iteration: 3317; Percent complete: 82.9%; Average loss: 0.0004\n",
      "Iteration: 3318; Percent complete: 83.0%; Average loss: 0.0004\n",
      "Iteration: 3319; Percent complete: 83.0%; Average loss: 0.0004\n",
      "Iteration: 3320; Percent complete: 83.0%; Average loss: 0.0004\n",
      "Iteration: 3321; Percent complete: 83.0%; Average loss: 0.0004\n",
      "Iteration: 3322; Percent complete: 83.0%; Average loss: 0.0004\n",
      "Iteration: 3323; Percent complete: 83.1%; Average loss: 0.0005\n",
      "Iteration: 3324; Percent complete: 83.1%; Average loss: 0.0004\n",
      "Iteration: 3325; Percent complete: 83.1%; Average loss: 0.0004\n",
      "Iteration: 3326; Percent complete: 83.2%; Average loss: 0.0004\n",
      "Iteration: 3327; Percent complete: 83.2%; Average loss: 0.0004\n",
      "Iteration: 3328; Percent complete: 83.2%; Average loss: 0.0005\n",
      "Iteration: 3329; Percent complete: 83.2%; Average loss: 0.0004\n",
      "Iteration: 3330; Percent complete: 83.2%; Average loss: 0.0004\n",
      "Iteration: 3331; Percent complete: 83.3%; Average loss: 0.0004\n",
      "Iteration: 3332; Percent complete: 83.3%; Average loss: 0.0005\n",
      "Iteration: 3333; Percent complete: 83.3%; Average loss: 0.0004\n",
      "Iteration: 3334; Percent complete: 83.4%; Average loss: 0.0005\n",
      "Iteration: 3335; Percent complete: 83.4%; Average loss: 0.0004\n",
      "Iteration: 3336; Percent complete: 83.4%; Average loss: 0.0004\n",
      "Iteration: 3337; Percent complete: 83.4%; Average loss: 0.0004\n",
      "Iteration: 3338; Percent complete: 83.5%; Average loss: 0.0005\n",
      "Iteration: 3339; Percent complete: 83.5%; Average loss: 0.0005\n",
      "Iteration: 3340; Percent complete: 83.5%; Average loss: 0.0004\n",
      "Iteration: 3341; Percent complete: 83.5%; Average loss: 0.0004\n",
      "Iteration: 3342; Percent complete: 83.5%; Average loss: 0.0004\n",
      "Iteration: 3343; Percent complete: 83.6%; Average loss: 0.0004\n",
      "Iteration: 3344; Percent complete: 83.6%; Average loss: 0.0005\n",
      "Iteration: 3345; Percent complete: 83.6%; Average loss: 0.0004\n",
      "Iteration: 3346; Percent complete: 83.7%; Average loss: 0.0005\n",
      "Iteration: 3347; Percent complete: 83.7%; Average loss: 0.0005\n",
      "Iteration: 3348; Percent complete: 83.7%; Average loss: 0.0004\n",
      "Iteration: 3349; Percent complete: 83.7%; Average loss: 0.0005\n",
      "Iteration: 3350; Percent complete: 83.8%; Average loss: 0.0004\n",
      "Iteration: 3351; Percent complete: 83.8%; Average loss: 0.0004\n",
      "Iteration: 3352; Percent complete: 83.8%; Average loss: 0.0004\n",
      "Iteration: 3353; Percent complete: 83.8%; Average loss: 0.0005\n",
      "Iteration: 3354; Percent complete: 83.9%; Average loss: 0.0004\n",
      "Iteration: 3355; Percent complete: 83.9%; Average loss: 0.0004\n",
      "Iteration: 3356; Percent complete: 83.9%; Average loss: 0.0004\n",
      "Iteration: 3357; Percent complete: 83.9%; Average loss: 0.0005\n",
      "Iteration: 3358; Percent complete: 84.0%; Average loss: 0.0004\n",
      "Iteration: 3359; Percent complete: 84.0%; Average loss: 0.0004\n",
      "Iteration: 3360; Percent complete: 84.0%; Average loss: 0.0004\n",
      "Iteration: 3361; Percent complete: 84.0%; Average loss: 0.0004\n",
      "Iteration: 3362; Percent complete: 84.0%; Average loss: 0.0004\n",
      "Iteration: 3363; Percent complete: 84.1%; Average loss: 0.0005\n",
      "Iteration: 3364; Percent complete: 84.1%; Average loss: 0.0004\n",
      "Iteration: 3365; Percent complete: 84.1%; Average loss: 0.0004\n",
      "Iteration: 3366; Percent complete: 84.2%; Average loss: 0.0005\n",
      "Iteration: 3367; Percent complete: 84.2%; Average loss: 0.0004\n",
      "Iteration: 3368; Percent complete: 84.2%; Average loss: 0.0004\n",
      "Iteration: 3369; Percent complete: 84.2%; Average loss: 0.0004\n",
      "Iteration: 3370; Percent complete: 84.2%; Average loss: 0.0004\n",
      "Iteration: 3371; Percent complete: 84.3%; Average loss: 0.0004\n",
      "Iteration: 3372; Percent complete: 84.3%; Average loss: 0.0004\n",
      "Iteration: 3373; Percent complete: 84.3%; Average loss: 0.0004\n",
      "Iteration: 3374; Percent complete: 84.4%; Average loss: 0.0005\n",
      "Iteration: 3375; Percent complete: 84.4%; Average loss: 0.0004\n",
      "Iteration: 3376; Percent complete: 84.4%; Average loss: 0.0004\n",
      "Iteration: 3377; Percent complete: 84.4%; Average loss: 0.0004\n",
      "Iteration: 3378; Percent complete: 84.5%; Average loss: 0.0004\n",
      "Iteration: 3379; Percent complete: 84.5%; Average loss: 0.0004\n",
      "Iteration: 3380; Percent complete: 84.5%; Average loss: 0.0004\n",
      "Iteration: 3381; Percent complete: 84.5%; Average loss: 0.0004\n",
      "Iteration: 3382; Percent complete: 84.5%; Average loss: 0.0004\n",
      "Iteration: 3383; Percent complete: 84.6%; Average loss: 0.0004\n",
      "Iteration: 3384; Percent complete: 84.6%; Average loss: 0.0004\n",
      "Iteration: 3385; Percent complete: 84.6%; Average loss: 0.0004\n",
      "Iteration: 3386; Percent complete: 84.7%; Average loss: 0.0004\n",
      "Iteration: 3387; Percent complete: 84.7%; Average loss: 0.0004\n",
      "Iteration: 3388; Percent complete: 84.7%; Average loss: 0.0004\n",
      "Iteration: 3389; Percent complete: 84.7%; Average loss: 0.0004\n",
      "Iteration: 3390; Percent complete: 84.8%; Average loss: 0.0004\n",
      "Iteration: 3391; Percent complete: 84.8%; Average loss: 0.0004\n",
      "Iteration: 3392; Percent complete: 84.8%; Average loss: 0.0004\n",
      "Iteration: 3393; Percent complete: 84.8%; Average loss: 0.0004\n",
      "Iteration: 3394; Percent complete: 84.9%; Average loss: 0.0004\n",
      "Iteration: 3395; Percent complete: 84.9%; Average loss: 0.0004\n",
      "Iteration: 3396; Percent complete: 84.9%; Average loss: 0.0004\n",
      "Iteration: 3397; Percent complete: 84.9%; Average loss: 0.0004\n",
      "Iteration: 3398; Percent complete: 85.0%; Average loss: 0.0004\n",
      "Iteration: 3399; Percent complete: 85.0%; Average loss: 0.0004\n",
      "Iteration: 3400; Percent complete: 85.0%; Average loss: 0.0004\n",
      "Iteration: 3401; Percent complete: 85.0%; Average loss: 0.0004\n",
      "Iteration: 3402; Percent complete: 85.0%; Average loss: 0.0004\n",
      "Iteration: 3403; Percent complete: 85.1%; Average loss: 0.0004\n",
      "Iteration: 3404; Percent complete: 85.1%; Average loss: 0.0004\n",
      "Iteration: 3405; Percent complete: 85.1%; Average loss: 0.0004\n",
      "Iteration: 3406; Percent complete: 85.2%; Average loss: 0.0004\n",
      "Iteration: 3407; Percent complete: 85.2%; Average loss: 0.0004\n",
      "Iteration: 3408; Percent complete: 85.2%; Average loss: 0.0004\n",
      "Iteration: 3409; Percent complete: 85.2%; Average loss: 0.0004\n",
      "Iteration: 3410; Percent complete: 85.2%; Average loss: 0.0004\n",
      "Iteration: 3411; Percent complete: 85.3%; Average loss: 0.0004\n",
      "Iteration: 3412; Percent complete: 85.3%; Average loss: 0.0004\n",
      "Iteration: 3413; Percent complete: 85.3%; Average loss: 0.0004\n",
      "Iteration: 3414; Percent complete: 85.4%; Average loss: 0.0004\n",
      "Iteration: 3415; Percent complete: 85.4%; Average loss: 0.0004\n",
      "Iteration: 3416; Percent complete: 85.4%; Average loss: 0.0005\n",
      "Iteration: 3417; Percent complete: 85.4%; Average loss: 0.0004\n",
      "Iteration: 3418; Percent complete: 85.5%; Average loss: 0.0004\n",
      "Iteration: 3419; Percent complete: 85.5%; Average loss: 0.0004\n",
      "Iteration: 3420; Percent complete: 85.5%; Average loss: 0.0004\n",
      "Iteration: 3421; Percent complete: 85.5%; Average loss: 0.0004\n",
      "Iteration: 3422; Percent complete: 85.5%; Average loss: 0.0004\n",
      "Iteration: 3423; Percent complete: 85.6%; Average loss: 0.0004\n",
      "Iteration: 3424; Percent complete: 85.6%; Average loss: 0.0004\n",
      "Iteration: 3425; Percent complete: 85.6%; Average loss: 0.0004\n",
      "Iteration: 3426; Percent complete: 85.7%; Average loss: 0.0005\n",
      "Iteration: 3427; Percent complete: 85.7%; Average loss: 0.0004\n",
      "Iteration: 3428; Percent complete: 85.7%; Average loss: 0.0004\n",
      "Iteration: 3429; Percent complete: 85.7%; Average loss: 0.0004\n",
      "Iteration: 3430; Percent complete: 85.8%; Average loss: 0.0004\n",
      "Iteration: 3431; Percent complete: 85.8%; Average loss: 0.0004\n",
      "Iteration: 3432; Percent complete: 85.8%; Average loss: 0.0004\n",
      "Iteration: 3433; Percent complete: 85.8%; Average loss: 0.0004\n",
      "Iteration: 3434; Percent complete: 85.9%; Average loss: 0.0004\n",
      "Iteration: 3435; Percent complete: 85.9%; Average loss: 0.0004\n",
      "Iteration: 3436; Percent complete: 85.9%; Average loss: 0.0004\n",
      "Iteration: 3437; Percent complete: 85.9%; Average loss: 0.0004\n",
      "Iteration: 3438; Percent complete: 86.0%; Average loss: 0.0004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3439; Percent complete: 86.0%; Average loss: 0.0004\n",
      "Iteration: 3440; Percent complete: 86.0%; Average loss: 0.0004\n",
      "Iteration: 3441; Percent complete: 86.0%; Average loss: 0.0004\n",
      "Iteration: 3442; Percent complete: 86.1%; Average loss: 0.0004\n",
      "Iteration: 3443; Percent complete: 86.1%; Average loss: 0.0005\n",
      "Iteration: 3444; Percent complete: 86.1%; Average loss: 0.0004\n",
      "Iteration: 3445; Percent complete: 86.1%; Average loss: 0.0003\n",
      "Iteration: 3446; Percent complete: 86.2%; Average loss: 0.0004\n",
      "Iteration: 3447; Percent complete: 86.2%; Average loss: 0.0004\n",
      "Iteration: 3448; Percent complete: 86.2%; Average loss: 0.0004\n",
      "Iteration: 3449; Percent complete: 86.2%; Average loss: 0.0004\n",
      "Iteration: 3450; Percent complete: 86.2%; Average loss: 0.0004\n",
      "Iteration: 3451; Percent complete: 86.3%; Average loss: 0.0004\n",
      "Iteration: 3452; Percent complete: 86.3%; Average loss: 0.0003\n",
      "Iteration: 3453; Percent complete: 86.3%; Average loss: 0.0004\n",
      "Iteration: 3454; Percent complete: 86.4%; Average loss: 0.0004\n",
      "Iteration: 3455; Percent complete: 86.4%; Average loss: 0.0004\n",
      "Iteration: 3456; Percent complete: 86.4%; Average loss: 0.0004\n",
      "Iteration: 3457; Percent complete: 86.4%; Average loss: 0.0004\n",
      "Iteration: 3458; Percent complete: 86.5%; Average loss: 0.0004\n",
      "Iteration: 3459; Percent complete: 86.5%; Average loss: 0.0004\n",
      "Iteration: 3460; Percent complete: 86.5%; Average loss: 0.0004\n",
      "Iteration: 3461; Percent complete: 86.5%; Average loss: 0.0004\n",
      "Iteration: 3462; Percent complete: 86.6%; Average loss: 0.0004\n",
      "Iteration: 3463; Percent complete: 86.6%; Average loss: 0.0004\n",
      "Iteration: 3464; Percent complete: 86.6%; Average loss: 0.0004\n",
      "Iteration: 3465; Percent complete: 86.6%; Average loss: 0.0004\n",
      "Iteration: 3466; Percent complete: 86.7%; Average loss: 0.0004\n",
      "Iteration: 3467; Percent complete: 86.7%; Average loss: 0.0004\n",
      "Iteration: 3468; Percent complete: 86.7%; Average loss: 0.0004\n",
      "Iteration: 3469; Percent complete: 86.7%; Average loss: 0.0004\n",
      "Iteration: 3470; Percent complete: 86.8%; Average loss: 0.0004\n",
      "Iteration: 3471; Percent complete: 86.8%; Average loss: 0.0004\n",
      "Iteration: 3472; Percent complete: 86.8%; Average loss: 0.0004\n",
      "Iteration: 3473; Percent complete: 86.8%; Average loss: 0.0005\n",
      "Iteration: 3474; Percent complete: 86.9%; Average loss: 0.0004\n",
      "Iteration: 3475; Percent complete: 86.9%; Average loss: 0.0004\n",
      "Iteration: 3476; Percent complete: 86.9%; Average loss: 0.0004\n",
      "Iteration: 3477; Percent complete: 86.9%; Average loss: 0.0004\n",
      "Iteration: 3478; Percent complete: 87.0%; Average loss: 0.0004\n",
      "Iteration: 3479; Percent complete: 87.0%; Average loss: 0.0004\n",
      "Iteration: 3480; Percent complete: 87.0%; Average loss: 0.0004\n",
      "Iteration: 3481; Percent complete: 87.0%; Average loss: 0.0004\n",
      "Iteration: 3482; Percent complete: 87.1%; Average loss: 0.0004\n",
      "Iteration: 3483; Percent complete: 87.1%; Average loss: 0.0004\n",
      "Iteration: 3484; Percent complete: 87.1%; Average loss: 0.0004\n",
      "Iteration: 3485; Percent complete: 87.1%; Average loss: 0.0004\n",
      "Iteration: 3486; Percent complete: 87.2%; Average loss: 0.0004\n",
      "Iteration: 3487; Percent complete: 87.2%; Average loss: 0.0004\n",
      "Iteration: 3488; Percent complete: 87.2%; Average loss: 0.0004\n",
      "Iteration: 3489; Percent complete: 87.2%; Average loss: 0.0004\n",
      "Iteration: 3490; Percent complete: 87.2%; Average loss: 0.0004\n",
      "Iteration: 3491; Percent complete: 87.3%; Average loss: 0.0004\n",
      "Iteration: 3492; Percent complete: 87.3%; Average loss: 0.0004\n",
      "Iteration: 3493; Percent complete: 87.3%; Average loss: 0.0004\n",
      "Iteration: 3494; Percent complete: 87.4%; Average loss: 0.0004\n",
      "Iteration: 3495; Percent complete: 87.4%; Average loss: 0.0004\n",
      "Iteration: 3496; Percent complete: 87.4%; Average loss: 0.0004\n",
      "Iteration: 3497; Percent complete: 87.4%; Average loss: 0.0004\n",
      "Iteration: 3498; Percent complete: 87.5%; Average loss: 0.0004\n",
      "Iteration: 3499; Percent complete: 87.5%; Average loss: 0.0004\n",
      "Iteration: 3500; Percent complete: 87.5%; Average loss: 0.0004\n",
      "Iteration: 3501; Percent complete: 87.5%; Average loss: 0.0004\n",
      "Iteration: 3502; Percent complete: 87.5%; Average loss: 0.0004\n",
      "Iteration: 3503; Percent complete: 87.6%; Average loss: 0.0004\n",
      "Iteration: 3504; Percent complete: 87.6%; Average loss: 0.0004\n",
      "Iteration: 3505; Percent complete: 87.6%; Average loss: 0.0004\n",
      "Iteration: 3506; Percent complete: 87.6%; Average loss: 0.0004\n",
      "Iteration: 3507; Percent complete: 87.7%; Average loss: 0.0004\n",
      "Iteration: 3508; Percent complete: 87.7%; Average loss: 0.0004\n",
      "Iteration: 3509; Percent complete: 87.7%; Average loss: 0.0004\n",
      "Iteration: 3510; Percent complete: 87.8%; Average loss: 0.0004\n",
      "Iteration: 3511; Percent complete: 87.8%; Average loss: 0.0004\n",
      "Iteration: 3512; Percent complete: 87.8%; Average loss: 0.0004\n",
      "Iteration: 3513; Percent complete: 87.8%; Average loss: 0.0003\n",
      "Iteration: 3514; Percent complete: 87.8%; Average loss: 0.0004\n",
      "Iteration: 3515; Percent complete: 87.9%; Average loss: 0.0004\n",
      "Iteration: 3516; Percent complete: 87.9%; Average loss: 0.0003\n",
      "Iteration: 3517; Percent complete: 87.9%; Average loss: 0.0004\n",
      "Iteration: 3518; Percent complete: 87.9%; Average loss: 0.0004\n",
      "Iteration: 3519; Percent complete: 88.0%; Average loss: 0.0004\n",
      "Iteration: 3520; Percent complete: 88.0%; Average loss: 0.0004\n",
      "Iteration: 3521; Percent complete: 88.0%; Average loss: 0.0004\n",
      "Iteration: 3522; Percent complete: 88.0%; Average loss: 0.0004\n",
      "Iteration: 3523; Percent complete: 88.1%; Average loss: 0.0004\n",
      "Iteration: 3524; Percent complete: 88.1%; Average loss: 0.0004\n",
      "Iteration: 3525; Percent complete: 88.1%; Average loss: 0.0004\n",
      "Iteration: 3526; Percent complete: 88.1%; Average loss: 0.0004\n",
      "Iteration: 3527; Percent complete: 88.2%; Average loss: 0.0004\n",
      "Iteration: 3528; Percent complete: 88.2%; Average loss: 0.0004\n",
      "Iteration: 3529; Percent complete: 88.2%; Average loss: 0.0003\n",
      "Iteration: 3530; Percent complete: 88.2%; Average loss: 0.0003\n",
      "Iteration: 3531; Percent complete: 88.3%; Average loss: 0.0004\n",
      "Iteration: 3532; Percent complete: 88.3%; Average loss: 0.0003\n",
      "Iteration: 3533; Percent complete: 88.3%; Average loss: 0.0004\n",
      "Iteration: 3534; Percent complete: 88.3%; Average loss: 0.0004\n",
      "Iteration: 3535; Percent complete: 88.4%; Average loss: 0.0004\n",
      "Iteration: 3536; Percent complete: 88.4%; Average loss: 0.0004\n",
      "Iteration: 3537; Percent complete: 88.4%; Average loss: 0.0004\n",
      "Iteration: 3538; Percent complete: 88.4%; Average loss: 0.0004\n",
      "Iteration: 3539; Percent complete: 88.5%; Average loss: 0.0004\n",
      "Iteration: 3540; Percent complete: 88.5%; Average loss: 0.0004\n",
      "Iteration: 3541; Percent complete: 88.5%; Average loss: 0.0004\n",
      "Iteration: 3542; Percent complete: 88.5%; Average loss: 0.0004\n",
      "Iteration: 3543; Percent complete: 88.6%; Average loss: 0.0004\n",
      "Iteration: 3544; Percent complete: 88.6%; Average loss: 0.0004\n",
      "Iteration: 3545; Percent complete: 88.6%; Average loss: 0.0004\n",
      "Iteration: 3546; Percent complete: 88.6%; Average loss: 0.0004\n",
      "Iteration: 3547; Percent complete: 88.7%; Average loss: 0.0004\n",
      "Iteration: 3548; Percent complete: 88.7%; Average loss: 0.0004\n",
      "Iteration: 3549; Percent complete: 88.7%; Average loss: 0.0004\n",
      "Iteration: 3550; Percent complete: 88.8%; Average loss: 0.0004\n",
      "Iteration: 3551; Percent complete: 88.8%; Average loss: 0.0004\n",
      "Iteration: 3552; Percent complete: 88.8%; Average loss: 0.0004\n",
      "Iteration: 3553; Percent complete: 88.8%; Average loss: 0.0004\n",
      "Iteration: 3554; Percent complete: 88.8%; Average loss: 0.0004\n",
      "Iteration: 3555; Percent complete: 88.9%; Average loss: 0.0004\n",
      "Iteration: 3556; Percent complete: 88.9%; Average loss: 0.0004\n",
      "Iteration: 3557; Percent complete: 88.9%; Average loss: 0.0004\n",
      "Iteration: 3558; Percent complete: 88.9%; Average loss: 0.0004\n",
      "Iteration: 3559; Percent complete: 89.0%; Average loss: 0.0004\n",
      "Iteration: 3560; Percent complete: 89.0%; Average loss: 0.0004\n",
      "Iteration: 3561; Percent complete: 89.0%; Average loss: 0.0004\n",
      "Iteration: 3562; Percent complete: 89.0%; Average loss: 0.0004\n",
      "Iteration: 3563; Percent complete: 89.1%; Average loss: 0.0004\n",
      "Iteration: 3564; Percent complete: 89.1%; Average loss: 0.0004\n",
      "Iteration: 3565; Percent complete: 89.1%; Average loss: 0.0004\n",
      "Iteration: 3566; Percent complete: 89.1%; Average loss: 0.0004\n",
      "Iteration: 3567; Percent complete: 89.2%; Average loss: 0.0004\n",
      "Iteration: 3568; Percent complete: 89.2%; Average loss: 0.0004\n",
      "Iteration: 3569; Percent complete: 89.2%; Average loss: 0.0004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3570; Percent complete: 89.2%; Average loss: 0.0004\n",
      "Iteration: 3571; Percent complete: 89.3%; Average loss: 0.0004\n",
      "Iteration: 3572; Percent complete: 89.3%; Average loss: 0.0004\n",
      "Iteration: 3573; Percent complete: 89.3%; Average loss: 0.0004\n",
      "Iteration: 3574; Percent complete: 89.3%; Average loss: 0.0004\n",
      "Iteration: 3575; Percent complete: 89.4%; Average loss: 0.0004\n",
      "Iteration: 3576; Percent complete: 89.4%; Average loss: 0.0004\n",
      "Iteration: 3577; Percent complete: 89.4%; Average loss: 0.0004\n",
      "Iteration: 3578; Percent complete: 89.5%; Average loss: 0.0004\n",
      "Iteration: 3579; Percent complete: 89.5%; Average loss: 0.0004\n",
      "Iteration: 3580; Percent complete: 89.5%; Average loss: 0.0004\n",
      "Iteration: 3581; Percent complete: 89.5%; Average loss: 0.0004\n",
      "Iteration: 3582; Percent complete: 89.5%; Average loss: 0.0004\n",
      "Iteration: 3583; Percent complete: 89.6%; Average loss: 0.0004\n",
      "Iteration: 3584; Percent complete: 89.6%; Average loss: 0.0004\n",
      "Iteration: 3585; Percent complete: 89.6%; Average loss: 0.0004\n",
      "Iteration: 3586; Percent complete: 89.6%; Average loss: 0.0004\n",
      "Iteration: 3587; Percent complete: 89.7%; Average loss: 0.0004\n",
      "Iteration: 3588; Percent complete: 89.7%; Average loss: 0.0004\n",
      "Iteration: 3589; Percent complete: 89.7%; Average loss: 0.0004\n",
      "Iteration: 3590; Percent complete: 89.8%; Average loss: 0.0004\n",
      "Iteration: 3591; Percent complete: 89.8%; Average loss: 0.0004\n",
      "Iteration: 3592; Percent complete: 89.8%; Average loss: 0.0004\n",
      "Iteration: 3593; Percent complete: 89.8%; Average loss: 0.0004\n",
      "Iteration: 3594; Percent complete: 89.8%; Average loss: 0.0003\n",
      "Iteration: 3595; Percent complete: 89.9%; Average loss: 0.0004\n",
      "Iteration: 3596; Percent complete: 89.9%; Average loss: 0.0004\n",
      "Iteration: 3597; Percent complete: 89.9%; Average loss: 0.0004\n",
      "Iteration: 3598; Percent complete: 90.0%; Average loss: 0.0004\n",
      "Iteration: 3599; Percent complete: 90.0%; Average loss: 0.0004\n",
      "Iteration: 3600; Percent complete: 90.0%; Average loss: 0.0004\n",
      "Iteration: 3601; Percent complete: 90.0%; Average loss: 0.0004\n",
      "Iteration: 3602; Percent complete: 90.0%; Average loss: 0.0004\n",
      "Iteration: 3603; Percent complete: 90.1%; Average loss: 0.0003\n",
      "Iteration: 3604; Percent complete: 90.1%; Average loss: 0.0004\n",
      "Iteration: 3605; Percent complete: 90.1%; Average loss: 0.0004\n",
      "Iteration: 3606; Percent complete: 90.1%; Average loss: 0.0004\n",
      "Iteration: 3607; Percent complete: 90.2%; Average loss: 0.0004\n",
      "Iteration: 3608; Percent complete: 90.2%; Average loss: 0.0004\n",
      "Iteration: 3609; Percent complete: 90.2%; Average loss: 0.0003\n",
      "Iteration: 3610; Percent complete: 90.2%; Average loss: 0.0003\n",
      "Iteration: 3611; Percent complete: 90.3%; Average loss: 0.0004\n",
      "Iteration: 3612; Percent complete: 90.3%; Average loss: 0.0004\n",
      "Iteration: 3613; Percent complete: 90.3%; Average loss: 0.0004\n",
      "Iteration: 3614; Percent complete: 90.3%; Average loss: 0.0003\n",
      "Iteration: 3615; Percent complete: 90.4%; Average loss: 0.0004\n",
      "Iteration: 3616; Percent complete: 90.4%; Average loss: 0.0004\n",
      "Iteration: 3617; Percent complete: 90.4%; Average loss: 0.0004\n",
      "Iteration: 3618; Percent complete: 90.5%; Average loss: 0.0003\n",
      "Iteration: 3619; Percent complete: 90.5%; Average loss: 0.0003\n",
      "Iteration: 3620; Percent complete: 90.5%; Average loss: 0.0004\n",
      "Iteration: 3621; Percent complete: 90.5%; Average loss: 0.0003\n",
      "Iteration: 3622; Percent complete: 90.5%; Average loss: 0.0004\n",
      "Iteration: 3623; Percent complete: 90.6%; Average loss: 0.0004\n",
      "Iteration: 3624; Percent complete: 90.6%; Average loss: 0.0004\n",
      "Iteration: 3625; Percent complete: 90.6%; Average loss: 0.0003\n",
      "Iteration: 3626; Percent complete: 90.6%; Average loss: 0.0004\n",
      "Iteration: 3627; Percent complete: 90.7%; Average loss: 0.0004\n",
      "Iteration: 3628; Percent complete: 90.7%; Average loss: 0.0004\n",
      "Iteration: 3629; Percent complete: 90.7%; Average loss: 0.0004\n",
      "Iteration: 3630; Percent complete: 90.8%; Average loss: 0.0004\n",
      "Iteration: 3631; Percent complete: 90.8%; Average loss: 0.0004\n",
      "Iteration: 3632; Percent complete: 90.8%; Average loss: 0.0004\n",
      "Iteration: 3633; Percent complete: 90.8%; Average loss: 0.0004\n",
      "Iteration: 3634; Percent complete: 90.8%; Average loss: 0.0004\n",
      "Iteration: 3635; Percent complete: 90.9%; Average loss: 0.0004\n",
      "Iteration: 3636; Percent complete: 90.9%; Average loss: 0.0004\n",
      "Iteration: 3637; Percent complete: 90.9%; Average loss: 0.0003\n",
      "Iteration: 3638; Percent complete: 91.0%; Average loss: 0.0004\n",
      "Iteration: 3639; Percent complete: 91.0%; Average loss: 0.0003\n",
      "Iteration: 3640; Percent complete: 91.0%; Average loss: 0.0003\n",
      "Iteration: 3641; Percent complete: 91.0%; Average loss: 0.0003\n",
      "Iteration: 3642; Percent complete: 91.0%; Average loss: 0.0003\n",
      "Iteration: 3643; Percent complete: 91.1%; Average loss: 0.0003\n",
      "Iteration: 3644; Percent complete: 91.1%; Average loss: 0.0003\n",
      "Iteration: 3645; Percent complete: 91.1%; Average loss: 0.0003\n",
      "Iteration: 3646; Percent complete: 91.1%; Average loss: 0.0004\n",
      "Iteration: 3647; Percent complete: 91.2%; Average loss: 0.0003\n",
      "Iteration: 3648; Percent complete: 91.2%; Average loss: 0.0003\n",
      "Iteration: 3649; Percent complete: 91.2%; Average loss: 0.0003\n",
      "Iteration: 3650; Percent complete: 91.2%; Average loss: 0.0003\n",
      "Iteration: 3651; Percent complete: 91.3%; Average loss: 0.0003\n",
      "Iteration: 3652; Percent complete: 91.3%; Average loss: 0.0003\n",
      "Iteration: 3653; Percent complete: 91.3%; Average loss: 0.0003\n",
      "Iteration: 3654; Percent complete: 91.3%; Average loss: 0.0004\n",
      "Iteration: 3655; Percent complete: 91.4%; Average loss: 0.0004\n",
      "Iteration: 3656; Percent complete: 91.4%; Average loss: 0.0004\n",
      "Iteration: 3657; Percent complete: 91.4%; Average loss: 0.0003\n",
      "Iteration: 3658; Percent complete: 91.5%; Average loss: 0.0003\n",
      "Iteration: 3659; Percent complete: 91.5%; Average loss: 0.0004\n",
      "Iteration: 3660; Percent complete: 91.5%; Average loss: 0.0003\n",
      "Iteration: 3661; Percent complete: 91.5%; Average loss: 0.0004\n",
      "Iteration: 3662; Percent complete: 91.5%; Average loss: 0.0003\n",
      "Iteration: 3663; Percent complete: 91.6%; Average loss: 0.0004\n",
      "Iteration: 3664; Percent complete: 91.6%; Average loss: 0.0003\n",
      "Iteration: 3665; Percent complete: 91.6%; Average loss: 0.0004\n",
      "Iteration: 3666; Percent complete: 91.6%; Average loss: 0.0004\n",
      "Iteration: 3667; Percent complete: 91.7%; Average loss: 0.0004\n",
      "Iteration: 3668; Percent complete: 91.7%; Average loss: 0.0003\n",
      "Iteration: 3669; Percent complete: 91.7%; Average loss: 0.0003\n",
      "Iteration: 3670; Percent complete: 91.8%; Average loss: 0.0003\n",
      "Iteration: 3671; Percent complete: 91.8%; Average loss: 0.0003\n",
      "Iteration: 3672; Percent complete: 91.8%; Average loss: 0.0003\n",
      "Iteration: 3673; Percent complete: 91.8%; Average loss: 0.0003\n",
      "Iteration: 3674; Percent complete: 91.8%; Average loss: 0.0003\n",
      "Iteration: 3675; Percent complete: 91.9%; Average loss: 0.0003\n",
      "Iteration: 3676; Percent complete: 91.9%; Average loss: 0.0003\n",
      "Iteration: 3677; Percent complete: 91.9%; Average loss: 0.0003\n",
      "Iteration: 3678; Percent complete: 92.0%; Average loss: 0.0003\n",
      "Iteration: 3679; Percent complete: 92.0%; Average loss: 0.0003\n",
      "Iteration: 3680; Percent complete: 92.0%; Average loss: 0.0004\n",
      "Iteration: 3681; Percent complete: 92.0%; Average loss: 0.0004\n",
      "Iteration: 3682; Percent complete: 92.0%; Average loss: 0.0004\n",
      "Iteration: 3683; Percent complete: 92.1%; Average loss: 0.0003\n",
      "Iteration: 3684; Percent complete: 92.1%; Average loss: 0.0003\n",
      "Iteration: 3685; Percent complete: 92.1%; Average loss: 0.0003\n",
      "Iteration: 3686; Percent complete: 92.2%; Average loss: 0.0003\n",
      "Iteration: 3687; Percent complete: 92.2%; Average loss: 0.0003\n",
      "Iteration: 3688; Percent complete: 92.2%; Average loss: 0.0004\n",
      "Iteration: 3689; Percent complete: 92.2%; Average loss: 0.0003\n",
      "Iteration: 3690; Percent complete: 92.2%; Average loss: 0.0003\n",
      "Iteration: 3691; Percent complete: 92.3%; Average loss: 0.0003\n",
      "Iteration: 3692; Percent complete: 92.3%; Average loss: 0.0003\n",
      "Iteration: 3693; Percent complete: 92.3%; Average loss: 0.0003\n",
      "Iteration: 3694; Percent complete: 92.3%; Average loss: 0.0003\n",
      "Iteration: 3695; Percent complete: 92.4%; Average loss: 0.0003\n",
      "Iteration: 3696; Percent complete: 92.4%; Average loss: 0.0003\n",
      "Iteration: 3697; Percent complete: 92.4%; Average loss: 0.0004\n",
      "Iteration: 3698; Percent complete: 92.5%; Average loss: 0.0003\n",
      "Iteration: 3699; Percent complete: 92.5%; Average loss: 0.0004\n",
      "Iteration: 3700; Percent complete: 92.5%; Average loss: 0.0004\n",
      "Iteration: 3701; Percent complete: 92.5%; Average loss: 0.0004\n",
      "Iteration: 3702; Percent complete: 92.5%; Average loss: 0.0004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3703; Percent complete: 92.6%; Average loss: 0.0003\n",
      "Iteration: 3704; Percent complete: 92.6%; Average loss: 0.0003\n",
      "Iteration: 3705; Percent complete: 92.6%; Average loss: 0.0004\n",
      "Iteration: 3706; Percent complete: 92.7%; Average loss: 0.0004\n",
      "Iteration: 3707; Percent complete: 92.7%; Average loss: 0.0004\n",
      "Iteration: 3708; Percent complete: 92.7%; Average loss: 0.0003\n",
      "Iteration: 3709; Percent complete: 92.7%; Average loss: 0.0003\n",
      "Iteration: 3710; Percent complete: 92.8%; Average loss: 0.0003\n",
      "Iteration: 3711; Percent complete: 92.8%; Average loss: 0.0003\n",
      "Iteration: 3712; Percent complete: 92.8%; Average loss: 0.0004\n",
      "Iteration: 3713; Percent complete: 92.8%; Average loss: 0.0003\n",
      "Iteration: 3714; Percent complete: 92.8%; Average loss: 0.0004\n",
      "Iteration: 3715; Percent complete: 92.9%; Average loss: 0.0003\n",
      "Iteration: 3716; Percent complete: 92.9%; Average loss: 0.0003\n",
      "Iteration: 3717; Percent complete: 92.9%; Average loss: 0.0003\n",
      "Iteration: 3718; Percent complete: 93.0%; Average loss: 0.0003\n",
      "Iteration: 3719; Percent complete: 93.0%; Average loss: 0.0003\n",
      "Iteration: 3720; Percent complete: 93.0%; Average loss: 0.0003\n",
      "Iteration: 3721; Percent complete: 93.0%; Average loss: 0.0003\n",
      "Iteration: 3722; Percent complete: 93.0%; Average loss: 0.0003\n",
      "Iteration: 3723; Percent complete: 93.1%; Average loss: 0.0003\n",
      "Iteration: 3724; Percent complete: 93.1%; Average loss: 0.0003\n",
      "Iteration: 3725; Percent complete: 93.1%; Average loss: 0.0003\n",
      "Iteration: 3726; Percent complete: 93.2%; Average loss: 0.0003\n",
      "Iteration: 3727; Percent complete: 93.2%; Average loss: 0.0003\n",
      "Iteration: 3728; Percent complete: 93.2%; Average loss: 0.0003\n",
      "Iteration: 3729; Percent complete: 93.2%; Average loss: 0.0004\n",
      "Iteration: 3730; Percent complete: 93.2%; Average loss: 0.0003\n",
      "Iteration: 3731; Percent complete: 93.3%; Average loss: 0.0003\n",
      "Iteration: 3732; Percent complete: 93.3%; Average loss: 0.0003\n",
      "Iteration: 3733; Percent complete: 93.3%; Average loss: 0.0003\n",
      "Iteration: 3734; Percent complete: 93.3%; Average loss: 0.0003\n",
      "Iteration: 3735; Percent complete: 93.4%; Average loss: 0.0003\n",
      "Iteration: 3736; Percent complete: 93.4%; Average loss: 0.0003\n",
      "Iteration: 3737; Percent complete: 93.4%; Average loss: 0.0003\n",
      "Iteration: 3738; Percent complete: 93.5%; Average loss: 0.0003\n",
      "Iteration: 3739; Percent complete: 93.5%; Average loss: 0.0004\n",
      "Iteration: 3740; Percent complete: 93.5%; Average loss: 0.0003\n",
      "Iteration: 3741; Percent complete: 93.5%; Average loss: 0.0004\n",
      "Iteration: 3742; Percent complete: 93.5%; Average loss: 0.0003\n",
      "Iteration: 3743; Percent complete: 93.6%; Average loss: 0.0003\n",
      "Iteration: 3744; Percent complete: 93.6%; Average loss: 0.0003\n",
      "Iteration: 3745; Percent complete: 93.6%; Average loss: 0.0003\n",
      "Iteration: 3746; Percent complete: 93.7%; Average loss: 0.0003\n",
      "Iteration: 3747; Percent complete: 93.7%; Average loss: 0.0003\n",
      "Iteration: 3748; Percent complete: 93.7%; Average loss: 0.0003\n",
      "Iteration: 3749; Percent complete: 93.7%; Average loss: 0.0003\n",
      "Iteration: 3750; Percent complete: 93.8%; Average loss: 0.0003\n",
      "Iteration: 3751; Percent complete: 93.8%; Average loss: 0.0003\n",
      "Iteration: 3752; Percent complete: 93.8%; Average loss: 0.0004\n",
      "Iteration: 3753; Percent complete: 93.8%; Average loss: 0.0003\n",
      "Iteration: 3754; Percent complete: 93.8%; Average loss: 0.0003\n",
      "Iteration: 3755; Percent complete: 93.9%; Average loss: 0.0003\n",
      "Iteration: 3756; Percent complete: 93.9%; Average loss: 0.0003\n",
      "Iteration: 3757; Percent complete: 93.9%; Average loss: 0.0003\n",
      "Iteration: 3758; Percent complete: 94.0%; Average loss: 0.0003\n",
      "Iteration: 3759; Percent complete: 94.0%; Average loss: 0.0003\n",
      "Iteration: 3760; Percent complete: 94.0%; Average loss: 0.0003\n",
      "Iteration: 3761; Percent complete: 94.0%; Average loss: 0.0003\n",
      "Iteration: 3762; Percent complete: 94.0%; Average loss: 0.0003\n",
      "Iteration: 3763; Percent complete: 94.1%; Average loss: 0.0003\n",
      "Iteration: 3764; Percent complete: 94.1%; Average loss: 0.0003\n",
      "Iteration: 3765; Percent complete: 94.1%; Average loss: 0.0003\n",
      "Iteration: 3766; Percent complete: 94.2%; Average loss: 0.0003\n",
      "Iteration: 3767; Percent complete: 94.2%; Average loss: 0.0003\n",
      "Iteration: 3768; Percent complete: 94.2%; Average loss: 0.0003\n",
      "Iteration: 3769; Percent complete: 94.2%; Average loss: 0.0003\n",
      "Iteration: 3770; Percent complete: 94.2%; Average loss: 0.0003\n",
      "Iteration: 3771; Percent complete: 94.3%; Average loss: 0.0004\n",
      "Iteration: 3772; Percent complete: 94.3%; Average loss: 0.0004\n",
      "Iteration: 3773; Percent complete: 94.3%; Average loss: 0.0003\n",
      "Iteration: 3774; Percent complete: 94.3%; Average loss: 0.0003\n",
      "Iteration: 3775; Percent complete: 94.4%; Average loss: 0.0003\n",
      "Iteration: 3776; Percent complete: 94.4%; Average loss: 0.0003\n",
      "Iteration: 3777; Percent complete: 94.4%; Average loss: 0.0003\n",
      "Iteration: 3778; Percent complete: 94.5%; Average loss: 0.0003\n",
      "Iteration: 3779; Percent complete: 94.5%; Average loss: 0.0003\n",
      "Iteration: 3780; Percent complete: 94.5%; Average loss: 0.0003\n",
      "Iteration: 3781; Percent complete: 94.5%; Average loss: 0.0003\n",
      "Iteration: 3782; Percent complete: 94.5%; Average loss: 0.0003\n",
      "Iteration: 3783; Percent complete: 94.6%; Average loss: 0.0003\n",
      "Iteration: 3784; Percent complete: 94.6%; Average loss: 0.0003\n",
      "Iteration: 3785; Percent complete: 94.6%; Average loss: 0.0003\n",
      "Iteration: 3786; Percent complete: 94.7%; Average loss: 0.0003\n",
      "Iteration: 3787; Percent complete: 94.7%; Average loss: 0.0003\n",
      "Iteration: 3788; Percent complete: 94.7%; Average loss: 0.0003\n",
      "Iteration: 3789; Percent complete: 94.7%; Average loss: 0.0003\n",
      "Iteration: 3790; Percent complete: 94.8%; Average loss: 0.0003\n",
      "Iteration: 3791; Percent complete: 94.8%; Average loss: 0.0003\n",
      "Iteration: 3792; Percent complete: 94.8%; Average loss: 0.0003\n",
      "Iteration: 3793; Percent complete: 94.8%; Average loss: 0.0003\n",
      "Iteration: 3794; Percent complete: 94.8%; Average loss: 0.0003\n",
      "Iteration: 3795; Percent complete: 94.9%; Average loss: 0.0003\n",
      "Iteration: 3796; Percent complete: 94.9%; Average loss: 0.0003\n",
      "Iteration: 3797; Percent complete: 94.9%; Average loss: 0.0003\n",
      "Iteration: 3798; Percent complete: 95.0%; Average loss: 0.0003\n",
      "Iteration: 3799; Percent complete: 95.0%; Average loss: 0.0003\n",
      "Iteration: 3800; Percent complete: 95.0%; Average loss: 0.0003\n",
      "Iteration: 3801; Percent complete: 95.0%; Average loss: 0.0003\n",
      "Iteration: 3802; Percent complete: 95.0%; Average loss: 0.0003\n",
      "Iteration: 3803; Percent complete: 95.1%; Average loss: 0.0003\n",
      "Iteration: 3804; Percent complete: 95.1%; Average loss: 0.0003\n",
      "Iteration: 3805; Percent complete: 95.1%; Average loss: 0.0003\n",
      "Iteration: 3806; Percent complete: 95.2%; Average loss: 0.0003\n",
      "Iteration: 3807; Percent complete: 95.2%; Average loss: 0.0003\n",
      "Iteration: 3808; Percent complete: 95.2%; Average loss: 0.0003\n",
      "Iteration: 3809; Percent complete: 95.2%; Average loss: 0.0003\n",
      "Iteration: 3810; Percent complete: 95.2%; Average loss: 0.0003\n",
      "Iteration: 3811; Percent complete: 95.3%; Average loss: 0.0003\n",
      "Iteration: 3812; Percent complete: 95.3%; Average loss: 0.0003\n",
      "Iteration: 3813; Percent complete: 95.3%; Average loss: 0.0003\n",
      "Iteration: 3814; Percent complete: 95.3%; Average loss: 0.0003\n",
      "Iteration: 3815; Percent complete: 95.4%; Average loss: 0.0003\n",
      "Iteration: 3816; Percent complete: 95.4%; Average loss: 0.0003\n",
      "Iteration: 3817; Percent complete: 95.4%; Average loss: 0.0003\n",
      "Iteration: 3818; Percent complete: 95.5%; Average loss: 0.0003\n",
      "Iteration: 3819; Percent complete: 95.5%; Average loss: 0.0003\n",
      "Iteration: 3820; Percent complete: 95.5%; Average loss: 0.0003\n",
      "Iteration: 3821; Percent complete: 95.5%; Average loss: 0.0003\n",
      "Iteration: 3822; Percent complete: 95.5%; Average loss: 0.0003\n",
      "Iteration: 3823; Percent complete: 95.6%; Average loss: 0.0003\n",
      "Iteration: 3824; Percent complete: 95.6%; Average loss: 0.0003\n",
      "Iteration: 3825; Percent complete: 95.6%; Average loss: 0.0003\n",
      "Iteration: 3826; Percent complete: 95.7%; Average loss: 0.0003\n",
      "Iteration: 3827; Percent complete: 95.7%; Average loss: 0.0003\n",
      "Iteration: 3828; Percent complete: 95.7%; Average loss: 0.0003\n",
      "Iteration: 3829; Percent complete: 95.7%; Average loss: 0.0003\n",
      "Iteration: 3830; Percent complete: 95.8%; Average loss: 0.0003\n",
      "Iteration: 3831; Percent complete: 95.8%; Average loss: 0.0003\n",
      "Iteration: 3832; Percent complete: 95.8%; Average loss: 0.0003\n",
      "Iteration: 3833; Percent complete: 95.8%; Average loss: 0.0003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3834; Percent complete: 95.9%; Average loss: 0.0003\n",
      "Iteration: 3835; Percent complete: 95.9%; Average loss: 0.0003\n",
      "Iteration: 3836; Percent complete: 95.9%; Average loss: 0.0003\n",
      "Iteration: 3837; Percent complete: 95.9%; Average loss: 0.0003\n",
      "Iteration: 3838; Percent complete: 96.0%; Average loss: 0.0003\n",
      "Iteration: 3839; Percent complete: 96.0%; Average loss: 0.0003\n",
      "Iteration: 3840; Percent complete: 96.0%; Average loss: 0.0003\n",
      "Iteration: 3841; Percent complete: 96.0%; Average loss: 0.0003\n",
      "Iteration: 3842; Percent complete: 96.0%; Average loss: 0.0003\n",
      "Iteration: 3843; Percent complete: 96.1%; Average loss: 0.0003\n",
      "Iteration: 3844; Percent complete: 96.1%; Average loss: 0.0003\n",
      "Iteration: 3845; Percent complete: 96.1%; Average loss: 0.0003\n",
      "Iteration: 3846; Percent complete: 96.2%; Average loss: 0.0003\n",
      "Iteration: 3847; Percent complete: 96.2%; Average loss: 0.0003\n",
      "Iteration: 3848; Percent complete: 96.2%; Average loss: 0.0003\n",
      "Iteration: 3849; Percent complete: 96.2%; Average loss: 0.0003\n",
      "Iteration: 3850; Percent complete: 96.2%; Average loss: 0.0003\n",
      "Iteration: 3851; Percent complete: 96.3%; Average loss: 0.0003\n",
      "Iteration: 3852; Percent complete: 96.3%; Average loss: 0.0003\n",
      "Iteration: 3853; Percent complete: 96.3%; Average loss: 0.0003\n",
      "Iteration: 3854; Percent complete: 96.4%; Average loss: 0.0003\n",
      "Iteration: 3855; Percent complete: 96.4%; Average loss: 0.0003\n",
      "Iteration: 3856; Percent complete: 96.4%; Average loss: 0.0003\n",
      "Iteration: 3857; Percent complete: 96.4%; Average loss: 0.0003\n",
      "Iteration: 3858; Percent complete: 96.5%; Average loss: 0.0003\n",
      "Iteration: 3859; Percent complete: 96.5%; Average loss: 0.0003\n",
      "Iteration: 3860; Percent complete: 96.5%; Average loss: 0.0003\n",
      "Iteration: 3861; Percent complete: 96.5%; Average loss: 0.0003\n",
      "Iteration: 3862; Percent complete: 96.5%; Average loss: 0.0003\n",
      "Iteration: 3863; Percent complete: 96.6%; Average loss: 0.0003\n",
      "Iteration: 3864; Percent complete: 96.6%; Average loss: 0.0003\n",
      "Iteration: 3865; Percent complete: 96.6%; Average loss: 0.0003\n",
      "Iteration: 3866; Percent complete: 96.7%; Average loss: 0.0003\n",
      "Iteration: 3867; Percent complete: 96.7%; Average loss: 0.0003\n",
      "Iteration: 3868; Percent complete: 96.7%; Average loss: 0.0003\n",
      "Iteration: 3869; Percent complete: 96.7%; Average loss: 0.0003\n",
      "Iteration: 3870; Percent complete: 96.8%; Average loss: 0.0003\n",
      "Iteration: 3871; Percent complete: 96.8%; Average loss: 0.0003\n",
      "Iteration: 3872; Percent complete: 96.8%; Average loss: 0.0003\n",
      "Iteration: 3873; Percent complete: 96.8%; Average loss: 0.0003\n",
      "Iteration: 3874; Percent complete: 96.9%; Average loss: 0.0003\n",
      "Iteration: 3875; Percent complete: 96.9%; Average loss: 0.0003\n",
      "Iteration: 3876; Percent complete: 96.9%; Average loss: 0.0003\n",
      "Iteration: 3877; Percent complete: 96.9%; Average loss: 0.0003\n",
      "Iteration: 3878; Percent complete: 97.0%; Average loss: 0.0003\n",
      "Iteration: 3879; Percent complete: 97.0%; Average loss: 0.0003\n",
      "Iteration: 3880; Percent complete: 97.0%; Average loss: 0.0003\n",
      "Iteration: 3881; Percent complete: 97.0%; Average loss: 0.0003\n",
      "Iteration: 3882; Percent complete: 97.0%; Average loss: 0.0003\n",
      "Iteration: 3883; Percent complete: 97.1%; Average loss: 0.0003\n",
      "Iteration: 3884; Percent complete: 97.1%; Average loss: 0.0003\n",
      "Iteration: 3885; Percent complete: 97.1%; Average loss: 0.0003\n",
      "Iteration: 3886; Percent complete: 97.2%; Average loss: 0.0003\n",
      "Iteration: 3887; Percent complete: 97.2%; Average loss: 0.0003\n",
      "Iteration: 3888; Percent complete: 97.2%; Average loss: 0.0003\n",
      "Iteration: 3889; Percent complete: 97.2%; Average loss: 0.0003\n",
      "Iteration: 3890; Percent complete: 97.2%; Average loss: 0.0003\n",
      "Iteration: 3891; Percent complete: 97.3%; Average loss: 0.0003\n",
      "Iteration: 3892; Percent complete: 97.3%; Average loss: 0.0003\n",
      "Iteration: 3893; Percent complete: 97.3%; Average loss: 0.0003\n",
      "Iteration: 3894; Percent complete: 97.4%; Average loss: 0.0003\n",
      "Iteration: 3895; Percent complete: 97.4%; Average loss: 0.0003\n",
      "Iteration: 3896; Percent complete: 97.4%; Average loss: 0.0003\n",
      "Iteration: 3897; Percent complete: 97.4%; Average loss: 0.0003\n",
      "Iteration: 3898; Percent complete: 97.5%; Average loss: 0.0003\n",
      "Iteration: 3899; Percent complete: 97.5%; Average loss: 0.0003\n",
      "Iteration: 3900; Percent complete: 97.5%; Average loss: 0.0003\n",
      "Iteration: 3901; Percent complete: 97.5%; Average loss: 0.0003\n",
      "Iteration: 3902; Percent complete: 97.5%; Average loss: 0.0003\n",
      "Iteration: 3903; Percent complete: 97.6%; Average loss: 0.0003\n",
      "Iteration: 3904; Percent complete: 97.6%; Average loss: 0.0003\n",
      "Iteration: 3905; Percent complete: 97.6%; Average loss: 0.0003\n",
      "Iteration: 3906; Percent complete: 97.7%; Average loss: 0.0003\n",
      "Iteration: 3907; Percent complete: 97.7%; Average loss: 0.0003\n",
      "Iteration: 3908; Percent complete: 97.7%; Average loss: 0.0003\n",
      "Iteration: 3909; Percent complete: 97.7%; Average loss: 0.0003\n",
      "Iteration: 3910; Percent complete: 97.8%; Average loss: 0.0003\n",
      "Iteration: 3911; Percent complete: 97.8%; Average loss: 0.0003\n",
      "Iteration: 3912; Percent complete: 97.8%; Average loss: 0.0003\n",
      "Iteration: 3913; Percent complete: 97.8%; Average loss: 0.0003\n",
      "Iteration: 3914; Percent complete: 97.9%; Average loss: 0.0003\n",
      "Iteration: 3915; Percent complete: 97.9%; Average loss: 0.0003\n",
      "Iteration: 3916; Percent complete: 97.9%; Average loss: 0.0003\n",
      "Iteration: 3917; Percent complete: 97.9%; Average loss: 0.0003\n",
      "Iteration: 3918; Percent complete: 98.0%; Average loss: 0.0003\n",
      "Iteration: 3919; Percent complete: 98.0%; Average loss: 0.0003\n",
      "Iteration: 3920; Percent complete: 98.0%; Average loss: 0.0003\n",
      "Iteration: 3921; Percent complete: 98.0%; Average loss: 0.0003\n",
      "Iteration: 3922; Percent complete: 98.0%; Average loss: 0.0003\n",
      "Iteration: 3923; Percent complete: 98.1%; Average loss: 0.0003\n",
      "Iteration: 3924; Percent complete: 98.1%; Average loss: 0.0003\n",
      "Iteration: 3925; Percent complete: 98.1%; Average loss: 0.0003\n",
      "Iteration: 3926; Percent complete: 98.2%; Average loss: 0.0003\n",
      "Iteration: 3927; Percent complete: 98.2%; Average loss: 0.0003\n",
      "Iteration: 3928; Percent complete: 98.2%; Average loss: 0.0003\n",
      "Iteration: 3929; Percent complete: 98.2%; Average loss: 0.0003\n",
      "Iteration: 3930; Percent complete: 98.2%; Average loss: 0.0003\n",
      "Iteration: 3931; Percent complete: 98.3%; Average loss: 0.0003\n",
      "Iteration: 3932; Percent complete: 98.3%; Average loss: 0.0003\n",
      "Iteration: 3933; Percent complete: 98.3%; Average loss: 0.0003\n",
      "Iteration: 3934; Percent complete: 98.4%; Average loss: 0.0003\n",
      "Iteration: 3935; Percent complete: 98.4%; Average loss: 0.0003\n",
      "Iteration: 3936; Percent complete: 98.4%; Average loss: 0.0003\n",
      "Iteration: 3937; Percent complete: 98.4%; Average loss: 0.0003\n",
      "Iteration: 3938; Percent complete: 98.5%; Average loss: 0.0003\n",
      "Iteration: 3939; Percent complete: 98.5%; Average loss: 0.0003\n",
      "Iteration: 3940; Percent complete: 98.5%; Average loss: 0.0003\n",
      "Iteration: 3941; Percent complete: 98.5%; Average loss: 0.0003\n",
      "Iteration: 3942; Percent complete: 98.6%; Average loss: 0.0003\n",
      "Iteration: 3943; Percent complete: 98.6%; Average loss: 0.0003\n",
      "Iteration: 3944; Percent complete: 98.6%; Average loss: 0.0003\n",
      "Iteration: 3945; Percent complete: 98.6%; Average loss: 0.0003\n",
      "Iteration: 3946; Percent complete: 98.7%; Average loss: 0.0003\n",
      "Iteration: 3947; Percent complete: 98.7%; Average loss: 0.0003\n",
      "Iteration: 3948; Percent complete: 98.7%; Average loss: 0.0003\n",
      "Iteration: 3949; Percent complete: 98.7%; Average loss: 0.0003\n",
      "Iteration: 3950; Percent complete: 98.8%; Average loss: 0.0003\n",
      "Iteration: 3951; Percent complete: 98.8%; Average loss: 0.0003\n",
      "Iteration: 3952; Percent complete: 98.8%; Average loss: 0.0003\n",
      "Iteration: 3953; Percent complete: 98.8%; Average loss: 0.0003\n",
      "Iteration: 3954; Percent complete: 98.9%; Average loss: 0.0003\n",
      "Iteration: 3955; Percent complete: 98.9%; Average loss: 0.0003\n",
      "Iteration: 3956; Percent complete: 98.9%; Average loss: 0.0003\n",
      "Iteration: 3957; Percent complete: 98.9%; Average loss: 0.0003\n",
      "Iteration: 3958; Percent complete: 99.0%; Average loss: 0.0003\n",
      "Iteration: 3959; Percent complete: 99.0%; Average loss: 0.0003\n",
      "Iteration: 3960; Percent complete: 99.0%; Average loss: 0.0003\n",
      "Iteration: 3961; Percent complete: 99.0%; Average loss: 0.0003\n",
      "Iteration: 3962; Percent complete: 99.1%; Average loss: 0.0003\n",
      "Iteration: 3963; Percent complete: 99.1%; Average loss: 0.0003\n",
      "Iteration: 3964; Percent complete: 99.1%; Average loss: 0.0003\n",
      "Iteration: 3965; Percent complete: 99.1%; Average loss: 0.0003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3966; Percent complete: 99.2%; Average loss: 0.0003\n",
      "Iteration: 3967; Percent complete: 99.2%; Average loss: 0.0003\n",
      "Iteration: 3968; Percent complete: 99.2%; Average loss: 0.0003\n",
      "Iteration: 3969; Percent complete: 99.2%; Average loss: 0.0003\n",
      "Iteration: 3970; Percent complete: 99.2%; Average loss: 0.0003\n",
      "Iteration: 3971; Percent complete: 99.3%; Average loss: 0.0003\n",
      "Iteration: 3972; Percent complete: 99.3%; Average loss: 0.0003\n",
      "Iteration: 3973; Percent complete: 99.3%; Average loss: 0.0003\n",
      "Iteration: 3974; Percent complete: 99.4%; Average loss: 0.0003\n",
      "Iteration: 3975; Percent complete: 99.4%; Average loss: 0.0003\n",
      "Iteration: 3976; Percent complete: 99.4%; Average loss: 0.0003\n",
      "Iteration: 3977; Percent complete: 99.4%; Average loss: 0.0003\n",
      "Iteration: 3978; Percent complete: 99.5%; Average loss: 0.0003\n",
      "Iteration: 3979; Percent complete: 99.5%; Average loss: 0.0003\n",
      "Iteration: 3980; Percent complete: 99.5%; Average loss: 0.0003\n",
      "Iteration: 3981; Percent complete: 99.5%; Average loss: 0.0003\n",
      "Iteration: 3982; Percent complete: 99.6%; Average loss: 0.0003\n",
      "Iteration: 3983; Percent complete: 99.6%; Average loss: 0.0003\n",
      "Iteration: 3984; Percent complete: 99.6%; Average loss: 0.0003\n",
      "Iteration: 3985; Percent complete: 99.6%; Average loss: 0.0003\n",
      "Iteration: 3986; Percent complete: 99.7%; Average loss: 0.0003\n",
      "Iteration: 3987; Percent complete: 99.7%; Average loss: 0.0003\n",
      "Iteration: 3988; Percent complete: 99.7%; Average loss: 0.0003\n",
      "Iteration: 3989; Percent complete: 99.7%; Average loss: 0.0003\n",
      "Iteration: 3990; Percent complete: 99.8%; Average loss: 0.0003\n",
      "Iteration: 3991; Percent complete: 99.8%; Average loss: 0.0003\n",
      "Iteration: 3992; Percent complete: 99.8%; Average loss: 0.0003\n",
      "Iteration: 3993; Percent complete: 99.8%; Average loss: 0.0003\n",
      "Iteration: 3994; Percent complete: 99.9%; Average loss: 0.0003\n",
      "Iteration: 3995; Percent complete: 99.9%; Average loss: 0.0003\n",
      "Iteration: 3996; Percent complete: 99.9%; Average loss: 0.0003\n",
      "Iteration: 3997; Percent complete: 99.9%; Average loss: 0.0003\n",
      "Iteration: 3998; Percent complete: 100.0%; Average loss: 0.0003\n",
      "Iteration: 3999; Percent complete: 100.0%; Average loss: 0.0003\n",
      "Iteration: 4000; Percent complete: 100.0%; Average loss: 0.0003\n"
     ]
    }
   ],
   "source": [
    "# Configure training/optimization\n",
    "clip = 50.0\n",
    "teacher_forcing_ratio = 1.0\n",
    "learning_rate = 0.0001\n",
    "decoder_learning_ratio = 5.0\n",
    "n_iteration = 4000\n",
    "print_every = 1\n",
    "save_every = 500\n",
    "\n",
    "# Ensure dropout layers are in train mode\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "# Initialize optimizers\n",
    "print('Building optimizers ...')\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
    "if loadFilename:\n",
    "    encoder_optimizer.load_state_dict(encoder_optimizer_sd)\n",
    "    decoder_optimizer.load_state_dict(decoder_optimizer_sd)\n",
    "\n",
    "\n",
    "# Run training iterations\n",
    "print(\"Starting Training!\")\n",
    "trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "           embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n",
    "           print_every, save_every, clip, corpus_name, loadFilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Evaluation\n",
    "~~~~~~~~~~~~~~\n",
    "\n",
    "To chat with your model, run the following block.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> cook chicken\n",
      "Bot: type macaroni recommend thi recip get minut recip\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    877\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    879\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    466\u001b[0m         \"\"\"\n\u001b[0;32m--> 467\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-3de5b829fbba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Begin chatting (uncomment and run the following line to begin)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mevaluateInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearcher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-697ba0b24fe3>\u001b[0m in \u001b[0;36mevaluateInput\u001b[0;34m(encoder, decoder, searcher, voc)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m# Get input sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0minput_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'> '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;31m# Check if it is quit case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minput_sentence\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'q'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minput_sentence\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'quit'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    851\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m         )\n\u001b[1;32m    855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    884\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set dropout layers to eval mode\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "# Initialize search module\n",
    "searcher = GreedySearchDecoder(encoder, decoder)\n",
    "\n",
    "# Begin chatting (uncomment and run the following line to begin)\n",
    "evaluateInput(encoder, decoder, searcher, voc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "----------\n",
    "\n",
    "That’s all for this one, folks. Congratulations, you now know the\n",
    "fundamentals to building a generative chatbot model! If you’re\n",
    "interested, you can try tailoring the chatbot’s behavior by tweaking the\n",
    "model and training parameters and customizing the data that you train\n",
    "the model on.\n",
    "\n",
    "Check out the other tutorials for more cool deep learning applications\n",
    "in PyTorch!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/Batch_3648643_batch_results_rob/test_step_query_text.csv'\n",
    "targetname = 'data/Batch_3648643_batch_results_rob/test_step_query_target.csv'\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "# Initialize search module\n",
    "searcher = GreedySearchDecoder(encoder, decoder)\n",
    "\n",
    "# Begin chatting (uncomment and run the following line to begin)\n",
    "text, target, responses = evaluateFile(encoder, decoder, searcher, voc, filename=filename, targetname=targetname)\n",
    "\n",
    "with open('data/Batch_3648643_batch_results_rob/test_step_query_predict.csv', 'wt') as f:\n",
    "    for l in responses:\n",
    "        f.write('{}\\n'.format(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BLEU = 1.05, 3.2/1.0/0.8/0.5 (BP=1.000, ratio=1.192, hyp_len=348, ref_len=292)\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "res = os.popen('perl multi_bleu.perl data/Batch_3648643_batch_results_rob/test_step_query_target.csv < data/Batch_3648643_batch_results_rob/test_step_query_predict.csv')\n",
    "res.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "step_query\n",
      "TARGET:\n",
      "information\n",
      "PREDICT:\n",
      "none later later recip\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "5 would need ask question becaus understand step\n",
      "TARGET:\n",
      "none\n",
      "PREDICT:\n",
      "long blend hand use mixer also dri\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "bake dish layer 2 cup corn chip singl layer top 1 cup chees spoon beef mixtur chees top remain chees corn chip substitut\n",
      "TARGET:\n",
      "substitut corn chip gluten free option\n",
      "PREDICT:\n",
      "step clear pear snugli pear snugli mayb exact dish\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "pan one add cut piec boil potato aloo methi quick beginn recip\n",
      "TARGET:\n",
      "better phrase thi step like next add cut piec boil potato first pan mayb detail separ step like next cut boil potato finish boil add potato pan one\n",
      "PREDICT:\n",
      "heat stove way get nice brown effect\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "mix ingredi togeth bake bake muffin\n",
      "TARGET:\n",
      "bake muffin\n",
      "PREDICT:\n",
      "snow powder anoth work powder sugar\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "place fill popsicl mold care freezer allow freez 30 minut none\n",
      "TARGET:\n",
      "none\n",
      "PREDICT:\n",
      "none way get nice brown effect\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "hardli ani gravi left chicken caramelis char part even sizzl serv carmel char\n",
      "TARGET:\n",
      "bare ani liquid present sound sizzl done\n",
      "PREDICT:\n",
      "serv way cut would easier understand also show item\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "swordfish come saut pan divid sauc four warm dinner plate place one piec fish plate squeez lemon piec fish serv hot swordfish cook divis\n",
      "TARGET:\n",
      "inform fish divis\n",
      "PREDICT:\n",
      "oliv oil heat enough thin roll easili pan\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "mix butter brown sugar fluffi add b egg vanilla extract rum mix well add egg one time make pie fill\n",
      "TARGET:\n",
      "add egg togeth one time\n",
      "PREDICT:\n",
      "specfic space instruct detail mixer also help\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "season swordfish salt pepper heat larg saut pan medium high heat add 1 4 cup oliv oil veri hot add swordfish cook side golden brown 3 4 minut per side set asid paper towel absorb ani excess oil know oil hot enough\n",
      "TARGET:\n",
      "addit info know pan oil hot enough\n",
      "PREDICT:\n",
      "e clear cook like put boil hot\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "heat sipp xocol add goldschlag garnish whip cream make royal ambassador xocai healthi sip xocol\n",
      "TARGET:\n",
      "specfic space instruct detail\n",
      "PREDICT:\n",
      "specfic space instruct detail ingredi allow\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "heat oil medium saut onion 5 minut add garlic ginger saut 5 minut add clove cardamom cayenn coriand cinnamon stick peppercorn stir saut 2 minut add two tablespoon water vinegar cherri honey salt bring boil cook 2 minut reduc heat medium low cover allow mixtur simmer 30 35 minut stir occasion mixtur goopi thick still wateri increas heat uncov burn liquid veri thick add lemon zest stir mixtur cook addit 5 minut common spice substitut\n",
      "TARGET:\n",
      "spice substitut\n",
      "PREDICT:\n",
      "long roughli garlic saut overli brown get minut brown\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "allow brisket come room temp hour befor prepar preheat oven 325 separ scatter onion larg bake dish roast pan set brisket fat side top onion add beer pan ani marinad cling plastic wrap cover seal foil tightli brais oven meat fall apart tender 5 hour begin check 4 hour meat liter fall apart stick fork done set oven broil broil 5 10 minut top develop crispi crust crispi crust meat explain\n",
      "TARGET:\n",
      "consid crispi crust meat\n",
      "PREDICT:\n",
      "full bake dish least minut side\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "blend ingredi togeth food processor long blend ingredi\n",
      "TARGET:\n",
      "amount time blend\n",
      "PREDICT:\n",
      "blend combin two ingredi hand blender use electr mixer also\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "slice squash length wise place face casserol dish 1 4 water bottom bake 30 minut squash tender cool bit touch squash scoop seed scoop squash flesh bowl set asid need\n",
      "TARGET:\n",
      "step veri clear\n",
      "PREDICT:\n",
      "think explain way cut would easier understand also show item\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "enjoy queri replac ingredi\n",
      "TARGET:\n",
      "mayb much oliv oil bake dish\n",
      "PREDICT:\n",
      "long blend hand ingredi blender use\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "larg heavi bottom skillet heat oil depth oil hot burn add chicken skillet make sure crowd pan fri chicken turn thong brown evenli 10 13 minut heavi bottom skillet info\n",
      "TARGET:\n",
      "heavi doe skillet need\n",
      "PREDICT:\n",
      "specfic space instruct detail ingredi allow\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "sauc mix combin yogurt mayonnais chive pour tortilla fill turkey meatbal tortilla wrap\n",
      "TARGET:\n",
      "vegeta\n",
      "PREDICT:\n",
      "best utensil use combin dri ingredi item squeez\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "make well ball dough fill 1 tbsp stuf pinch open shut form cone shape packet sure none fill expos melt make mess fri steam usual golden brown color\n",
      "TARGET:\n",
      "doe golden brown mean\n",
      "PREDICT:\n",
      "specfic space instruct detail ingredi spice clean\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "asparagu foil bake sheet put much asparagu like bake sheet drizzl oliv oil gener amount salt pepper salt pepper would think bake oven al dent tast none\n",
      "TARGET:\n",
      "none\n",
      "PREDICT:\n",
      "doe make sour sweet ball one anoth\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "saut pan medium heat add butter oliv oil garlic onc garlic fragrant slightli soften stir flour smooth cook flour minut saut garlic fragrant\n",
      "TARGET:\n",
      "long doe take garlic becom fragrant\n",
      "PREDICT:\n",
      "doe slightli char get nice brown get\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "spoon mixtur 6 lightli greas use cook spray medium size muffin pan 12 mini muffin pan bake 20 25 minut cook test skewer test muffin done\n",
      "TARGET:\n",
      "spray greas 6 muffin tin pan 12 minni pan spoon mixtur fill muffin space 2 3rd full make sure skewer clean remov test\n",
      "PREDICT:\n",
      "tell eggplant fulli cook get minut direct tell us\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "add whip fresh top cream cream mixtur hand whisk mix well add dissolv gelatin lastli fold 20g crush oreo cooki rubber spatula consist befor ad ingredi make cheesecak\n",
      "TARGET:\n",
      "long mix befor ad ingredi\n",
      "PREDICT:\n",
      "much orang pineappl mixer also goe tomato\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "2 add remain ingredi keep boil anoth 10 minut reduc heat low simmer slightli uncov stir occasion 45 minut beef tender brand rice work best slow cook spici beef\n",
      "TARGET:\n",
      "boil rice time take thi step save time\n",
      "PREDICT:\n",
      "temperatur set dutch oven way get nice brown\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "heat oil pan saut garlic onion transluc saute onion transluc pictur\n",
      "TARGET:\n",
      "onion clear brown burnt\n",
      "PREDICT:\n",
      "long doe take roughli onion becom transluc get\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "peel chop carrot potato fine chop onion fine chop onion hack\n",
      "TARGET:\n",
      "blend onion chop set blender\n",
      "PREDICT:\n",
      "cool doe hand ingredi prevent also\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "larg glass bake pan mix togeth flour 1 tablespoon salt ½ tablespoon pepper paprika cornstarch mix well googl\n",
      "TARGET:\n",
      "much flour\n",
      "PREDICT:\n",
      "long blend pear ingredi doe know make cooki\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "chop parsley leav toss clam chop parsley toss clam\n",
      "TARGET:\n",
      "chop parsley small bit toss clam bowl\n",
      "PREDICT:\n",
      "none later mixer also recip\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "heat ghee margarin heavi bottom skillet medium heat add jaggeri palm sugar coconut sesam seed stir constantli jaggeri sugar melt becom sticki set asid allow fill mixtur cook 30 minut googl\n",
      "TARGET:\n",
      "long stir\n",
      "PREDICT:\n",
      "use margarin sunsitut butter get nice brown\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "bake 35 minut intern temperatur read 165 degre cover thigh lightli bast mixtur everi ten minut cook tri use coconut oil bake chicken\n",
      "TARGET:\n",
      "chicken crispi juici state chicken onc fulli cook\n",
      "PREDICT:\n",
      "long refridger pan electr mixer also say\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "turn heat stir grate chees basil season salt pepper tast creami artichok pasta\n",
      "TARGET:\n",
      "grate chees heat still remov pasta add ingredi\n",
      "PREDICT:\n",
      "would help say candi look like take cracker oven brown\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "blender blitz togeth soak bread tomato green pepper garlic oliv oil blend soak bread\n",
      "TARGET:\n",
      "get solid stuff blend without burn blender\n",
      "PREDICT:\n",
      "long doe take roughli onion becom transluc mixer\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "preheat oven 325 preheat oven\n",
      "TARGET:\n",
      "use middl dial oven preheat make sure noth oven befor\n",
      "PREDICT:\n",
      "use oven hand way nice brown\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "fri 4 strip bacon set asid worcestershir sauc substitut low carb burger\n",
      "TARGET:\n",
      "worcestershir sauc ferment condiment made base vinegar flavor anchovi molass tamarind onion garlic season\n",
      "PREDICT:\n",
      "use margarin sunsitut butter get nice brown\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "2 next day preheat oven 160c greas 20cm round tin line greaseproof paper cream butter sugar togeth light fluffi slowli add egg beat slowli addit fold flour cinnamon lemon zest cream butter techniqu\n",
      "TARGET:\n",
      "doe cream butter mean\n",
      "PREDICT:\n",
      "step clear hand also ingredi flour sugar cocoa\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "anoth medium size bowl combin cream chees ½ cup sugar use electr mixer low speed smooth add 1 egg vanilla continu mix well combin pour cream chees mixtur evenli hot crust pour lemon fill cream chees layer doe cream chees mixtur need set\n",
      "TARGET:\n",
      "let cream chees layer set\n",
      "PREDICT:\n",
      "long doe take roughli onion becom transluc electr\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "add remain oil skillet oil shimmer add potato season salt pepper cook stir potato golden brown undersid 5 minut stir corn beef cook onion kale use back spatula press hash compact drizzl cream evenli hash cook undisturb 5 minut turn hash spatula full time press cook anoth 5 minut undisturb repeat thi one time hash pretti well brown thi point serv hash top egg recip corn beef hash kale\n",
      "TARGET:\n",
      "recip quit detail quantiti ingredi time respect\n",
      "PREDICT:\n",
      "combin video show onion prevent stick bottom pan\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "sprinkl chees stir melt long doe chicken take cook medium heat\n",
      "TARGET:\n",
      "approxim time take\n",
      "PREDICT:\n",
      "may help fold chees befor stack egg ensur less melt\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "add chorizo bilbao carrot green pea tomato sauc kasubha liver spread think recip food good worth\n",
      "TARGET:\n",
      "ingredi list way prepar food\n",
      "PREDICT:\n",
      "long averag might take bone broth start simmer\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "trim bit fat thigh place larg sauc pot peel onion halv add pot take hand full parsley trim end bit throw cut leav celeri along two three stalk halv throw add herb bouquet well lastli add water cover ingredi inch bring boil let simmer least hour half two hour may need chicken fall bone remov may want season salt pepper need\n",
      "TARGET:\n",
      "step clear want\n",
      "PREDICT:\n",
      "long refridger soak slice grind toast spice clean\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "place pineappl banana peach agav coconut water turmer ice kitchen blender blend high 1 minut stir occasion complet blend serv right away agav substitut\n",
      "TARGET:\n",
      "substitut honey agav\n",
      "PREDICT:\n",
      "ani garnish accept electr mixer also dri ingredi\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "add hummu broccoli kale wrap put anoth layer hummu top befor add avocado scallion kale broccoli avocado hummu wrap\n",
      "TARGET:\n",
      "mani cup oh hummu unclear\n",
      "PREDICT:\n",
      "use margarin sunsitut butter way get nice brown\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "hot oil fri meatbal golden brown place meatbal paper towel remov excess fat best way heat tortilla befor eat\n",
      "TARGET:\n",
      "help heat fri pan first add oil flick drop water sizzl evapor immedi add oil oil heat thoroughli second\n",
      "PREDICT:\n",
      "temperatur reduc way get nice brown effect\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "remov tray oven drain peach arrang almond past bake 8 10 minut pastri ha risen side golden make peach pastri\n",
      "TARGET:\n",
      "chop peach befor arrang pastri\n",
      "PREDICT:\n",
      "specfic space instruct detail mixer also goe\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "3 medium high heat add 1 tablespoon butter 2 tablespoon oliv oil add chicken singl layer cook lightli brown side 3 5 minut per side remov chicken skillet loos cover aluminum foil arereadi season chicken locat buy\n",
      "TARGET:\n",
      "buy season chicken groceri store\n",
      "PREDICT:\n",
      "e oven brown sugar butter baker know right\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "cover reduc heat cook medium low 5 minut rice milk stir reduc heat make rice pud\n",
      "TARGET:\n",
      "stir dure thi time\n",
      "PREDICT:\n",
      "specfic space instruct detail ingredi also\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEXT:\n",
      "2 expert chef recommend fruit extract bake\n",
      "TARGET:\n",
      "troubl find cooki cutter alway suggest trip local dollar store bread fresh heat oven 350 degre bake 15 minut half sheet pan\n",
      "PREDICT:\n",
      "snow powder anoth work powder sugar\n"
     ]
    }
   ],
   "source": [
    "with open('seq2seq_step_query_pred.txt', 'wt') as f:\n",
    "    for i, (t, g, p) in enumerate(zip(text, target, responses)):\n",
    "        print('\\n\\n\\n')\n",
    "        f.write('\\n\\n\\n')\n",
    "        if len(g) == 0:\n",
    "            g = [None]\n",
    "        print('TEXT:\\n{}\\nTARGET:\\n{}\\nPREDICT:\\n{}'.format(t[0], g[0], p.strip()))\n",
    "        f.write('TEXT:\\n{}\\nTARGET:\\n{}\\nPREDICT:\\n{}'.format(t[0], g[0], p.strip()))\n",
    "#     if i == 100:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['cups packed light brown sugar tablespoons margarine tablespoons vegetable shortening cups dark molasses tablespoon baking soda cup boiling water cups all purpose flour sifted tablespoon ground cloves tablespoons ground ginger tablespoon ground cinnamon'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['image of finished product'],\n",
       " [],\n",
       " [],\n",
       " ['peeled and cut into inch thick rounds bechamel sauce cup butter cups hot milk tablespoons flour eggs cup grated kefalograviera cheese or parm teaspoon salt'],\n",
       " [],\n",
       " ['visualized instruction'],\n",
       " [],\n",
       " ['how the chicken will look like after frying .'],\n",
       " [],\n",
       " ['tell exact amounts of ingredients'],\n",
       " ['place the cookie crusts in the freezer and make the banana ice cream'],\n",
       " ['show a video of this step and show the correct consistency .'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['visualized instructions for clarifying purposes'],\n",
       " ['make the pink coconut cream .'],\n",
       " [],\n",
       " [],\n",
       " ['baking dish'],\n",
       " ['show images or video of this step . suggest turning the oven on or have the assistant turn the oven on to the correct temperature .'],\n",
       " ['whl brie stk butter melted phyllo dough'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['ingredients ounces canned chickpeas rinsed and drained ounces canned coconut milk full fat cup onion diced cups sweet red pepper diced ounces handfuls of fresh spinach tbsp avocado oil for cooking curry spice blend your choice cup water tsp salt i used tbsp medium curry powder tsp garam marsala tsp turmeric tsp red chili flakes'],\n",
       " ['how slices cut'],\n",
       " [],\n",
       " ['cook onions'],\n",
       " [],\n",
       " ['show the best way to mash the bananas .'],\n",
       " ['laptop'],\n",
       " ['find out how to bake fish bun'],\n",
       " ['about minutes .'],\n",
       " [],\n",
       " ['show designs and patterns to make it look nice'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['baking sheet with parchment paper'],\n",
       " [],\n",
       " ['cilantro'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['show a picture on what the marks should look like'],\n",
       " [],\n",
       " [],\n",
       " ['visualized instructions'],\n",
       " [],\n",
       " ['crushed tbsp cream tbsp butter tbsp crushed dried chilli tbsp white vineger'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['suggest alternative ingredient .'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['show video of how to fit dough into dish'],\n",
       " [],\n",
       " ['olives and oregano . simmer on low for minutes .'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['show a video of this step'],\n",
       " ['ingredients ounces canned chickpeas rinsed and drained ounces canned coconut milk full fat cup onion diced cups sweet red pepper diced ounces handfuls of fresh spinach tbsp avocado oil for cooking curry spice blend your choice cup water tsp salt i used tbsp medium curry powder tsp garam marsala tsp turmeric tsp red chili flakes'],\n",
       " [],\n",
       " [],\n",
       " ['suggest an oil substitute .'],\n",
       " ['lrg flat mushrooms grams butter medium onion peeled and chopped clv garlic peeled and washed rashers smoked pack bacon de rinded and diced grams fresh white breadcrumbs grams cheddar cheese grated tablespoon freshly chopped parsley salt and freshly ground black pepper freshly squeezed juice of lemon ml vegetable stock'],\n",
       " ['specify estimated cooling time after cakes are cooked'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['serser'],\n",
       " ['show the recommended dough texture desired by the end of this step'],\n",
       " [],\n",
       " [],\n",
       " ['it should recommend alternate ingredients if the user asks for them .'],\n",
       " ['simmer the white wheat with . litres of water over low heat for at least minutes add pandan leave minutes later till wheat soften . stir in sugar to taste and serve with coconut cream milk .'],\n",
       " [],\n",
       " ['image or video of process'],\n",
       " [],\n",
       " ['crushed teaspoons salt teaspoon dill weed teaspoon coarsely ground pepper lbs . pork and beef cubes mushrooms optional cherry tomatoes optional small cooked potatoes'],\n",
       " [],\n",
       " ['whl brie stk butter melted phyllo dough'],\n",
       " [],\n",
       " [],\n",
       " ['clarify what this means'],\n",
       " [],\n",
       " ['ingredients ounces canned chickpeas rinsed and drained ounces canned coconut milk full fat cup onion diced cups sweet red pepper diced ounces handfuls of fresh spinach tbsp avocado oil for cooking curry spice blend your choice cup water tsp salt i used tbsp medium curry powder tsp garam marsala tsp turmeric tsp red chili flakes'],\n",
       " ['how much water to put in each time and how long to wait in between before adding more'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['we should know what the temperature of the oven should be .'],\n",
       " ['showing picture of cooking'],\n",
       " ['recommend the size of the mixing bowl .'],\n",
       " [],\n",
       " ['visualized instructions for clarifying purposes'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['the best type of veggies to use with the dip .'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['tell the user how much cheese is required to put inside'],\n",
       " ['add a timer for minutes'],\n",
       " [],\n",
       " ['cilantro'],\n",
       " [],\n",
       " [],\n",
       " ['suggest alternative ingredients'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['show a video of this step .'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['improved visualization'],\n",
       " ['add the mixture and stir until combined'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['cilantro'],\n",
       " ['you will need pounds whole pork shoulder tablespoon black pepper tablespoons chili powder tablespoon garlic powder tablespoon paprika teaspoon ground cumin ounces good ale or dark beer cloves garlic chopped'],\n",
       " [],\n",
       " [],\n",
       " ['visualized instructions'],\n",
       " ['a picture of the squash on the baking sheet .'],\n",
       " [],\n",
       " ['tips for preventing burned quinoa may be useful here .'],\n",
       " [],\n",
       " [],\n",
       " ['remove the pot and simmer it on low heat again for another minutes together with pandan leaves'],\n",
       " [],\n",
       " ['show video of how to check the temp of the oil .'],\n",
       " ['provide a timer for the hr in fridge'],\n",
       " [],\n",
       " ['provide a link to this step'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['it should show you how to cut the strawberry fans that you will garnish the cheesecake with .'],\n",
       " [],\n",
       " ['to taste'],\n",
       " [],\n",
       " [],\n",
       " ['freshly ground teaspoon paprika teaspoon celery seed teaspoon hot sauce teaspoon fresh lemon juice tablespoons brown sugar'],\n",
       " [],\n",
       " [],\n",
       " ['you will need pounds whole pork shoulder tablespoon black pepper tablespoons chili powder tablespoon garlic powder tablespoon paprika teaspoon ground cumin ounces good ale or dark beer cloves garlic chopped'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['chop walnuts and a few leaves of herbs'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['optimize the ingredients needed see where to shop for needed ingredients'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['a link to this step'],\n",
       " ['cups oz g blended fresh raspberries'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['show a video of this step'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['the garlic and onions . cook until softened . stir in the tbsp of taco seasoning just to combine .'],\n",
       " ['peeled and cut into inch thick rounds bechamel sauce cup butter cups hot milk tablespoons flour eggs cup grated kefalograviera cheese or parm teaspoon salt'],\n",
       " [],\n",
       " ['visualized instructions'],\n",
       " ['whl brie stk butter melted phyllo dough'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['how you prepare one .'],\n",
       " [],\n",
       " ['a timer should be provided to keep track of the hrs'],\n",
       " ['remove pan from heat and stir in baking soda'],\n",
       " [],\n",
       " [],\n",
       " ['tell the user how much of the top to cut off .'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['once helping out with all the ingredients with the item introduction if needed'],\n",
       " ['so a video would be nice for the user and he won t feel lost duringg this step'],\n",
       " [],\n",
       " [],\n",
       " ['tbps shrimp paste pound ground pork teaspoon hot madras curry powder sprigs of purple basil regular green basil is fine if purple basil stalks of fresh lemongrass each about inches long'],\n",
       " [],\n",
       " ['divided water pound sweet vinegar slaw wholes wheat buns'],\n",
       " [],\n",
       " ['show an instructional video to how to cook the vegetables .'],\n",
       " [],\n",
       " [],\n",
       " ['how to cook perfect bacon .'],\n",
       " [],\n",
       " ['preheat oven to degrees .'],\n",
       " [],\n",
       " [],\n",
       " ['improved visualization'],\n",
       " ['thawed or fresh blueberries quart balsamic vinegar cup sugar inch lime peel cut strips from lime cinnamon stick long'],\n",
       " [],\n",
       " ['softened'],\n",
       " ['how it should appear when properly combined'],\n",
       " ['explain what this means .'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['peeled and sliced into coins large mushrooms caps removed and sliced a large yellow onion cans of white beans drained tsp sage tsp thyme lots of fresh ground black pepper white pepper a shake or two pinch or two of salt olive oil'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['exact number of garlic cloves'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['and reference size of said meatballs .'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['set timer for minutes'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['peeled and sliced into coins large mushrooms caps removed and sliced a large yellow onion cans of white beans drained tsp sage tsp thyme lots of fresh ground black pepper white pepper a shake or two pinch or two of salt olive oil'],\n",
       " [],\n",
       " ['image of the ingredients ?'],\n",
       " ['list each ingredient to mix and how to mix it properly'],\n",
       " ['more specific on time to cook rice .'],\n",
       " [],\n",
       " ['how to tell if your sausage is browned .'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['and possibly recommend the best method .'],\n",
       " [],\n",
       " [],\n",
       " ['a link to this step'],\n",
       " [],\n",
       " ['improved visualization'],\n",
       " [],\n",
       " [],\n",
       " ['info about what consistency to expect'],\n",
       " [],\n",
       " ['show how to cut up the meats .'],\n",
       " [],\n",
       " ['provide different toppings .'],\n",
       " [],\n",
       " [],\n",
       " ['show in a video'],\n",
       " ['kilogram pernil de de cordeiro azeite sal e pimenta berinjelas cebolas roxas cortadas em oregano seco alecrim fresco dentes de alho salsinha grams latas de de tomate pelado vinagre de vinho tinto pimenta chili seca anchovas'],\n",
       " ['plus cup olive oil cup dry vermouth cups crushed tomatoes'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['show how it is done'],\n",
       " ['specific video instructions on how to do this'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['display how to properly mix ingredients'],\n",
       " [],\n",
       " ['etc . fill the mold and freeze for six hours or overnight until firm . you will need a fresh trout . it is very important to use a fresh fish . on a cutting board cut the head off using a sashimi slicer . gut the fish and wash it in cold running water . use your free hand to keep the fish from slipping while you fillet it . keep the blade horizontal and cut just above the skeleton of the fish from head to tail . turn the fish over and cut the second fillet . remove the rib bones from the fillets . remove any remaining bones with tweezers . remove the skin . in a small bowl gently blend vinegar salt and pepper into sour cream set aside . reserve egg to be cut into wedges for garnish chop other egg . in a large bowl combine egg potato meat cottage cheese celery and onion . gently blend in sour cream mixture . cover and chill . garnish with egg wedges . show video of this entire process . mix all ingredients in a small bowl . if not using immediately store in an airtight container or ziplock bag . when crepes are easily handled and malleable remove from refrigerator along with filling . allow it to cool completely pour some of your strawberry and cheeses mixture into it and drizzle with your strawberry syrup juice . place all of the banana ice cream ingredients in a blender and wait for to unthaw a bit . now blend the ingredients until you reach that creamy ice cream consistency . place all of the banana ice cream ingredients in a blender and wait for to unthaw a bit . now blend the ingredients until you reach that creamy ice cream consistency . for the filling cream the butter and shortening slowly add the sugars while beating . add the evaporated milk vanilla and lemon extract . mix on medium speed until completely smooth and fluffy . when the cakes are done and cooled use a tooth pick to make three small holes in the bottom of each one . move the toothpick around the inside of each cake to create space for the filling . using a cake decorator or plastic bag or pastry bag inject each cake with filling through all three holes . mix dry ingredients and add yeast place water onion skins oil salt and pepper in a quart pan . one dozen eggs cup olive oil teaspoon salt teaspoon pepper outer dried browned skins from onions water to cover eggs cover the dough with plastic wrap and allow to rest till double in bulk about hour . after the dough has risen pour out onto a clean flat surface . punch down the dough to release some of the air . devide the dough into pieces and shape each into a round form . place the rounds onto a parchment lined cookie sheet . cover with plastic warp and allow to rise for another minutes . brush the rolls with the remaining eggwash and bake into a preheated f oven for minutes . remove and cool on a wire rack before served . prepare the lemon filling continue cooking for about one minute then remove and transfer to a plate . bake for minutes in the oven at c turning them over half way through bake for minutes in the oven at c turning them over half way through heat a skillet with tablespoons of extra virgin olive oil and saute zucchini until slightly crumbled and golden . add salt and pepper to taste . remove and repeat for other quesadilla . combine chocolate milk and cinnamon in a sauce pan . stir over low heat until smooth and shiny reserve about cup for later . in a large bowl combine wafer crumbs marshmallow and sugar . stir in chocolate mixture . the muffins are great to eat the same day but even better and more moist the day after . i always eat some the first day and more the next day . . . .i mean who can resist freshly baked muffins ? recommend how the muffins should be stored . refrigerator covered ? add white beans and cabbage stirring to combine . saute onion in butter until soft . stir in curry and flour and heat an additional mins . slowly add the milk stirring constantly as sauce thickens . add chopped eggs and heat thru . pour over muffins garnish with parsley or cilantro and serve . curry powder provide video on how to do this step . melt the chocolate over double boiler . add tablespoon of butter and mix until dissolved . all the charm and elegance of the last century with all the comfort and amenities of the next . comments make the poppy seed pastries in advance and store them in the freezer . at serving time just defrost them they will stay crisp and everyone will think they were freshly baked . make extra pastries to follow the purim tradition of sharing shalach manos and give a basket of these delicious confections as gifts to family and friends . show suitable baskets for sale . assembling divide the dough into four pieces and run through the machine adding flour for the icing place the icing sugar in a large bowl . in a pot combine sugar and cornstarch . add in cherry lemon juice and stir until smooth . cook over medium heat stirring until the mixture boils and thickens . remove from heat and let cool . drizzle the chocolate cheesecake with cherry sauce or simply just dust with icing sugar . malzemeleri yogurun . can show video on how to make this food . add bacon to skillet and fry until crisp remove with a slotted spoon and reserve . chill the ramekins in the fridge until the custard is thoroughly set . place tablespoons raisins in each tart . divide syrup mixture among tarts . bake until filling browns and puffs and top appears dry about minutes . transfer racks cool . remove tarts from pans . serve with frozen yogurt . can show how the tarts look like after baking . pour batter into an oiled pyrex pan and put in the oven for minutes or until a knife inserted in the cake comes out clean . show how a pan is properly oiled . show how the knife should look . have the assistant automatically set the timer for the oven or a reminder to check on the cake . use the leftover ranch sauce . make sure the cheese and vegetables are covered or wet with the custard mixture . heat tablespoon of the oil and gently fry the onions and celery until soft . stir in tomatoes and thyme and cook for about minutes to soften tomatoes . place in base of shallow dish . in a small bowl add oatmeal yogurt milk and combine . let it sit for few minutes or several hours in the refrigerator . then add apples banana dried fruits and stir until well combined . top with nuts before serving . in a hot pan add the tvp . cook for minutes then add the mixed spices over top . make sure you incorporate the spices very well into the tvp . let cook for minutes until the liquid has evaporated . explain what tvp is . lazy way to serve let cool slightly then toss in parsley season to taste and serve . deglaze with some chicken broth then add a can of coconut milk some more chicken broth fish sauce cup lime juice cilantro prepare a vegetable stock and keep it aside . the process of making the stock simmer sauce stirring occasionally until slightly thickened . about five minutes . simmer sauce and stir occasionally add the wet ingredients to the dry and mix well . batter will be fairly thick i added a dash of buttermilk at this point because my batter was dry . stir in cool and pulse in a food processor until fine . stir fry for a minute . add cups water and bring to a boil . brush the cake all over with the warmed apricot jam . this recipe yields bagels . . clean and gut the fish remove backbone rinse and drain . remove the seeds and cut the lemons into small pieces . microwave on high for minute or until dip is warm . heating dip allows for the flavors to mesh together . adj seasonings . heat oil in a pan add fennel seeds chopped onion and cook until slightly translucent . www .cremedelacrumb .blogspot .com bring to boil and cook at medium heat for minutes . place vinegar honey salt and roasted garlic in a food processor . puree until garlic is chopped very fine . provide an approximate time that it will take to puree the garlic . this recipe yields servings . make it four servings bring . litres of water to boil in a saucepan used my small endo thermal magic cooker then add in the drain white wheat and let it simmer for about minutes . bring . litres of water to boil in a saucepan used my small endo thermal magic cooker then add in the drain white wheat and let it simmer for about minutes . the bartlett pear is the best to use for liquor making . it is juicy sweet and smooth . avoid one with cuts bruises dark spots or decay . add more water in cup increments if needed . return marshmallow mixture to refrigerator . strain the broth and return it to the stock pot to heat . pour cups gin in a glass . set aside let cool for minutes in a cake pan and then transfer to a cooling rack to cool completely . dissolve the sugar with half a cup of water in a pan over a medium heat . this is one sorbet where i have never found it necessary to use fresh blackcurrants . in fact the frozen ones are better and available all year round . the same applies to raspberries . carefully transfer the baking sheet to the oven . brush the edges with an egg wash the egg white from one egg and place another pasta piece over the top . seal the edges with your fingers a fork or whatever puts a smile on your face . a link to this step in a heated skillet saute sesame oil hijiki carrots age and tofu all completely drained of water . when ingredients have acquired a shiny appearance add dashijiru shoyu sake and mirin . reduce heat to low and cook stirring frequently until liquid has been absorbed . turn off heat and add green beans . combine ingredients in a non reactive bowl . cups finely shredded purple cabbage red pepper seeded and finely diced cup mayonnaise cup whipping cream cup cider or rice wine vinegar teaspoon salt teaspoon black pepper freshly ground teaspoon paprika teaspoon celery seed teaspoon hot sauce teaspoon fresh lemon juice tablespoons brown sugar place dressing in a covered container and refrigerate for several hours stirring occasionally so that the sugar dissolves and the flavors blend . add ching s secret schezwan chutney and toss well . allow to cool then cut or decorate as you desire . enjoy ! remove from the oven and toss with coarse salt . cool . serve with rice and green salad . sprinkle toasted almonds over top of the tvp dish and rice . show how to toast almonds . then add boiled thoor dhaal how to boil thoor dhaal place in the center of the oven and bake for about minutes or until the top is golden brown . remove from the oven and cool completely . garnish with sprigs of fresh mint . blend shortening egg and milk . mix flour baking powder salt and sugar . when skillet is fully heated lift skillet from burner spray with cooking spray then pour cup batter onto the middle of the skillet then turn with your wrist quickly to cover entire bottom of skillet with crepe mixture . preheat oven to f . line a baking sheet with parchment paper or silpat baking mat . cup sugar serve slightly warm or at room temperature garnished with small mounds of whipped cream and chocolate shavings . the quiche should cool down for minutes before it can be sliced . cook for about hour until dark browned and even blackening in places . remove from oven . lower the oven to degrees . you will need pounds whole pork shoulder tablespoon black pepper tablespoons chili powder tablespoon garlic powder tablespoon paprika teaspoon ground cumin ounces good ale or dark beer cloves garlic chopped bake for about minutes . for the tomato onion relish remove skillet from heat and promptly lift fillet from hot liquid using a karamel rengi aldiginda kremayi ekleyin eriyinceye kadar karistirip ocaktan alin ve sogumaya birakin . soguduktan sonra yukarda hazirlanan kremaya ilave edip karistirin . place in serving dish and sprinkle with sauteed sesame seeds . . now add coriander leaves and pour hot water . tomato tsp jeera powder tsp garam masala green chillies bay leaf salt as per taste cup hot water gms mutton chops tsp ginger garlic paste tsp coriander powder whole cardamom cloves cinnamon fresh coriander leaves oil bake for minutes then remove the wax paper with weights and bake for minutes . bake for mins then remove the wax paper add drained tuna stir all together . allow to cook for a few minutes . add drain tuna and stir place in a shallow airtight container drizzle juice over kebabs and sprinkle with mint . cover and chill . in butter lightly brown rice and vermicelli from rice a roni . stir in hot water chicken raisins rice a roni flavor packet and curry powder . cover and simmer minutes . garnish top with peanuts and coconut . servings . clarification drain any fat from meat and top with mushrooms and shredded cheese . turn oven to broil and cook until cheese is melted . brown ground beef drain fat . place in large casserole dish . cover with cream of chicken soup diluted with can water . salt and pepper . place frozen tater tots over top and bake uncovered at degrees for minutes . add cheese and continue to bake minutes more . in a large skillet heat olive oil on medium high . add your cherries and walnuts . add slices of bacon on top . drain peppercorns and rinse under warm water . heat extra butter in small pan add peppercorns and cook minute . remove chicken breasts from baking dish arrange on serving platter . keep warm . reduce pan dripping to tablespoon by simmering over gentle heat for to minutes . add pan dripping to peppercorns along with combined egg yolks cream sour cream and mustard . stir over low heat until sauce saute onions mushrooms sesame seed and garlic in butter until browned . add lemon grass ginger chillies peppercorns and chicken broth bring to boil and cook on moderate heat until reduced by about one half . double wrap each panettone in plastic and store in the refrigerator . bring to room temperature before serving . using a thin pancake turner turn crepe . cook tagliatelle in a large pot of boiling salted water for mins . grams tagliatelle italian flat noodle or spaghetti grams grated parmesan cheese freshly ground black pepper pesto sauce cup fresh sweet basil leaves cloves garlic peeled tablespoons pine nuts lightly toast pine nuts for about mins teaspoon salt milliliters extra virgin olive oil ms water note i used tsp wonderslim to replace the vegetable oil . what on earth is wonderslim ? i use canola oil accessible everywhere . if wondrslim oil is similar to canola oil additional recipes can be found at www .peanutbureau .ca . add spinach and cook for minute ingredients ounces canned chickpeas rinsed and drained ounces canned coconut milk full fat cup onion diced cups sweet red pepper diced ounces handfuls of fresh spinach tbsp avocado oil for cooking curry spice blend your choice cup water tsp salt i used tbsp medium curry powder tsp garam marsala tsp turmeric tsp red chili flakes dried apples pears and prunes are cooked in water until they are soft . carefully combine the flour with the wet mix . display how to properly mix and what it should look like in a large bowl combine the sugar ginger nutmeg cinnamon salt and baking soda . mix well . cup sugar cover and chill dough about hour or until easy to handle . i did mine over night but thats not necessary . heat a tablespoon of butter in a non stick pan then toast sandwich on both sides until golden brown . in a salad bowl combine the apples walnuts celery and raisins . roast it on a medium flame for five minutes . mix together thoroughly the flour baking powder cheddar cheese and spinach . tastes like champagne . bots white grape juice lrg bottle club soda lrgs bottle up heat a medium skillet to medium with one tablespoon of olive oil . serve with chips or veggies preferably cold . if you can t wait eat it right away ! drizzle teaspoon olive oil over top of garlic wrap tightly in foil and place in oven on separate baking sheet for minutes . add curry powder and paprika and stir to coat the chicken or mushrooms . add the curry powder and paprika to give it the tast with an electric mixer cream butter both sugars . add eggs one at a time . add applesauce and pumpkin and then flour mixture beating until just combined . fill cupcake liners about three quarters full . bake approximately minutes but check frequently after minutes . cool completely . to show a demo of how to do add half of the white chocolate into the bottom of the tin foil lined pan . spread evenly with an offset spatula . let harden . to speed up the process place in the fridge for about minutes or until it has set up . show a video of this step and show the correct consistency . cut chicken on the diagonal into thick strips about two inches wide . how the chicken will look after cutting after that mix the bean sprouts and cucumber in a bowl and season well before filling the bean curd tofu pouches . or beef with the meat magic . place meats in a heavy pot and let sit while you dice up the onion . add the onion spices soup base . add enough water to cover . cook on medium heat until meat is easily removed from bones . strain reserving juice . show video of the following step . heat the oil in a casserole and brown the meat all over in batches until it has a good colour . remove and set aside pre heat wok or ordinary pan with coocking oil or olive oil mix all ingredients together and store in an air tight container . cut the onion in slices . to serve scoop into serving dishes or into the individual dishes . serve hot with noodles or rice . pour batter into baking pan and set inside a larger baking pan . add enough hot water to the large baking pan to reach half way up the sides of the smaller baking pan . pour the batter into baking pan blend the molasses eggs and vanilla into the butter mixture until it becomes a uniform color . might be good to show what color yield servings . whisk together powdered sugar orange zest and orange juice until smooth fry in olive oil they should talk about the duration of frying or if said food needs to be flipped . cut rounds with a cookie cutter . put approx . tsp jam in the center and fold to form a semi circle . advance prep peel and cube the potatoes and cook until fork tender . mash . set aside . mediums onions finely chopped cup unsalted butter cups cooked and mashed potatoes see note cup creme fraiche salt pepper set the sauce aside in a bowl and place in the fridge to chill . wash the rice well . in a pan put the rice water and salt . bring it to a boil . lower the heat . cover and cook till the rice is soft and the water is absorbed . stir in the coconut milk . simmer till the coconut milk is absorbed and the rice is very soft and creamy . cool slightly and turn out into a flat dish . level the sides and top with a knife . when cold cut kiribath into diamond shapes . can be served as the main course with the accompaniments suggested above . soak pipis in water for hours to remove sand . sprinkle the chopped coriander leaves and mix well remove from the fire and keep it aside . bake for minutes squeeze lemon and set aside . put sugar in a glass . add ice water stirring until sugar is dissolved . add lemon juice and pour over crushed ice . decorations heat remaining oil and quickly fry the tuna steaks to brown on each side . place tuna steaks on top of vegetables season then pour over white wine . cover . bake at degrees for to minutes until fish is tender . top off with ice approx of the pitcher to make the crust combine flour sugar and salt in a large bowl . add butter and combine until mixture resembles coarse meal . add ice water and mix until mixture just begins to hold together . for the dough beat the butter with the salt and sugar until light . add the flavorings and beat until smooth . add eggs then continue beating until the mixture is emulsified and smooth and looks like buttercream . if the mixture remains curdled warm the bottom of the mixing bowl in a pan of warm water for a second or two and continue beating rewarm the bowl as necessary until the mixture is smooth . add one third of the flour and mix in then another eggs . repeat with another third of the flour the last eggs and the last third of the flour . beat ground beef may be used instead of ground chicken . drizzle some oil on the grill and the fish in a separate bowl whisk together the egg ricotta and oil . remove keep warm . in same pan melt tablespoons butter over medium heat . saute shallots shortly then add the mushrooms and garlic . remove keep warm in same pan melt tablespoons butter over medium heat saute shallots shortly then add the mushrooms and garlic same procedure for veg . manchurian with gravy or dry but instead of using only cauliflower use finely chopped minced vegetables and bind with some cornflour or bread crumbs and make small lumps the size of a pingpong ball . place fruit cut side down on the grill and cook for minutes or until warmed through . large grapefruit ruby red or standard tablespoons canola oil tablespoon brown sugar reduce heat and whisk in cheese stirring constantly until melted and fully incorporated . show what this looks like . transfer the pasta to a large bowl mix in the mushrooms and coat with the herb dressing . preheat the oven to degrees . add citrus juice and cover tightly with foil . cover the pan and cook for hour on very low heat . cover the pan and cook for hour on very low heat . set up a work surface with a bowl of water a pastry brush and a flat area covered in wax or parchment paper to rest your tortellinis . video on the steps to do this . put a little olive oil in a pan . add red onion and cook minute . add crushed garlic i always have on hand the kind in a jar cooked sliced chicken breasts and some dried oregano . heat to minutes then add to sliced roma tomatoes and heat until chicken starts to darken . tips on how to slice an onion thinly or without crying once your onions broccoli and chicken are cooked and your cheeses grated please grate your own there are very few instances when pre grated is okay ! huge huge flavor and texture difference for the price . it s time to make your sauce . this sauce is essentially a flavored roux . a roux is a cooked mixture of fat and flour and many sauces and gravies begin with one . master a roux and you are halfway to making a delicious sauce . colored sugar can be used for decoration . pancakes drop batter by cups onto a hot greased griddle . grill flank steak over medium heat for minutes per side until desired doneness minutes dependent on how thick the steak is will be medium to medium rare . measurements of thickness of steak to now how much to vary cooking time by to achieve the right cooking of the steak . also maybe mention the hand trick for showing how firm the different levels of steak cookedness are . topping to enclose and steam tamales proceed according to directions in basic tamales . reduce heat and continue stirring until pudding coats has thickened to desired consistency it should easily coat the back of a wooden spoon . place into the oven and bake for minutes or until done . preheat oven to thread cantaloupe honeydew and watermelon chunks alternately onto each of inch skewers . place the balls onto a baking try lined with grease proof paper and flatten them out into circles . leave approx cm of space between each cookie . pour strained custard over the top of the bread . using a spatula gently press down on bread slices so they soak up custard . place dish in a large roasting pan add enough warm water to pan to come halfway up the sides of the baking dish . using your hands or a large spoon mix bowl contents until uniformly blended . tbps shrimp paste pound ground pork teaspoon hot madras curry powder sprigs of purple basil regular green basil is fine if purple basil stalks of fresh lemongrass each about inches long tbsp . hemp hearts in a non stick frying pan heat the vegetable oil over medium heat and sear for minutes each side until golden brown . now add maida suji baking powder to the milk powder and mix well . then add khoya butter ghee egg and saffron threads and mix well to make a thick batter . make small balls from this batter malli in urdu . and keep aside . this recipe yields large haystacks . glaze divide the circle of puff pastry and lay the crescents cocottine obtained in trying to form a basket leaving out of the container part of the sheet to form the crunchy bits . divide the circle of puff pantry this is how you roll . enjoy ! toss the dressing with the apple nut mixture . serve the salad over lettuce leaves . set garlic aside to cool . add wine beef broth bay leaf garlic and thyme . simmer covered for minutes stirring frequently . transfer to plastic container and place in the freezer for hours before serving . add in the zucchini and mushrooms mix in another tablespoon of olive oil and mix well with the potatoes and sweet potatoes . roast for another minutes . make sure the veggies have nice caramelization . what caramelization looks like . combine the rest of the ingredients in a separate bowl and add chicken . preheat the oven to f . cut the squash in half lengthwise and scoop out the seeds and stringy center . oil each half gently with olive oil or cooking spray put face down on a cookie sheet and bake until tender about minutes . a timer let remind you evr mins plunge the tomatoes into boiling water for seconds . remove with a slotted spoon transfer to a bowl of iced water . remove from the water slip off their skins . chop the tomatoes set aside . in a large pot saute the mustard seeds in the oil over a medium heat until they begin to sputter pop . add the garlic bay leaf turmeric rice stirring until the rice becomes translucent minutes . add the tomatoes reduce the heat to a simmer for minutes . add the broth bring back to a boil remove from the heat add the cilantro allow it to steam covered for minutes . remove the bay leaf fluff with a fork stirring in the cilantro . a way to stop the oil spitting everywhere . note onion are numbers medium size stir in the beans parsley lemon juice the remaining butter teaspoon salt and teaspoon pepper . cook until heated through to minutes . serve with the grains cook until mixture begins to thicken approximately minutes . stir in remaining herbs spices chicken and half of the cheese . show proper thickness of mixture heat oil in medium skillet . add onion and garlic and saute on medium high heat until onion is transparent . add remaining ingredients and simmer for min . remove from heat . in quart saucepan saute onion in butter until tender . stir in flour mustard salt and pepper until blended . stir in cups milk and salmon liquid mixture and worcestershire sauce . cook stirring constantly until milk mixture boils and thickens . step recipe is about what i remember the spices being that we added to the cooked red beans hence this coconut condiment added to some nice red beans and served over rice should be excellent with the addition of some added chiles o course . when oil begins to smoke add scallops . be careful ! i used long grilling tongs these babies splatter and that oil is h o t hot ! this recipe yields servings . quickly mix together using a large spoon spatula or your hands first approach the shrimp . i bought the frozen variety but feel free to buy fresh if you d like . thaw the shrimp peel and de vein . i like to remove the entire tail but you may choose to keep it . cook on high heat until it boils then lower the heat and simmer for at least minutes or longer until the beef is tender . cook in a saucepan until just starting to boil and set aside to cool . next chop up the chiles garlic and onion in the processor . then add the vinegar cumin lime juice tequila and the cooled tomatillo chayote mixture . hit the high speed button on the food processor and let it go until the whole mess is sauce . it s really green a little tart and hotter than hades ! pour ml pints of the cream into a saucepan and add the vanilla pods and orange rinds . bring to the boil and once boiling reduce the heat and simmer until reduced by . take out the rinds and pods and scrape the inside of the pods into the cream . assistant should go through each part individually . even though this is listed as a single step it s rather long and complicated and needs to be broken up . add butter parsley and season with pepper put together the meat grinder attachment and sausage stuffer piece and insert it into the head of the mixer . tighten well . show a video of this step . in a soup pot heat glugs of olive oil over med low heat add c c o g until translucent about minutes . tips for making a perfect recipe . prepare crust . sprinkle gelatin over water to soften . mix sugar cornstarch and salt in top of double boiler . gradually stir in eggnog . clarify what a double boiler is . say how to prepare the crust . the original recipe notes that the base can be thickened by adding a few boiled potatoes . add a few boiled potatoes remove the pot from stove and place it into the magic cooker cover and let the wheat continue to cook through using the heat from the pot . remove the pot from stove and place it into the magic cooker cover and let the wheat continue to cook through using the heat from the pot . add in the baking powder flour and ground cinnamon . stir until everything is combined . bring just to a slow boil stirring occasionally then remove from heat . chill the cake for another hours . stir fry onions and garlic until cooks place in the oven and bake for about minutes until the duck is golden and the juices run clear . butter the shiny side of a piece of aluminum foil and fit it butter side down tightly against the frozen crust . put the tart pan on a baking sheet and bake for minutes . preheat the oven to f . skin the pheasant and remove all the meat . chop into fairly small pieces and place in a bowl . how to skin pheasant directions fry bacon until crispy in a large non stick frying pan . set bacon aside to drain . add onions to bacon grease except one tablespoon . add diced potatoes mix with the onions . add chives parsley garlic and salt and pepper stirring well between each addition . when thoroughly mixed pour potatoes in a bowl lined with a paper towel . scramble eggs in same pan . when eggs are almost set add potato mixture and crumbled bacon mix thoroughly . all seasonings are optional . experiment with the recipe to find the combination for you . eggs may be served separately with the potato bacon mi reduce oven temperature to degrees f degrees c . in a mixing bowl whisk together wine chicken broth and remaining tablespoons of oil pour over hens . continue roasting about minutes longer or until hens are golden brown and juices run clear . baste with pan juices every minutes . place pie crust in a deep dish glass pie plate and crimp edges . achaari murg is ready store in an airtight container . peel and cube your potatoes then place in a large pot drain strawberries reserve syrup . dissolve jello and add reserved juice . chill to partially set beat until light and fluffy . stir in whipped cream and chill until spreadable . transfer cups of mixture and add strawberries . split cake into layers and frost with mixture . chill until serving time . wash and pat dry chicken . place chicken breast side up in a low roasting pan . rub chicken with fresh bay leaves and then rub piri piri sauce all over the chicken . place the pork in the middle rack of the oven . these are usually served as a pickle or relish . green peppers cup white wine vinegar tablespoons water cup olive oil bay leaf teaspoon salt teaspoon sugar peppercorns bruised cloves garlic peeled place dough onto a lightly floured surface and quickly and gently knead . combine mango onion garlic and chiles into the avocado mixture . when onions are slightly browned add butter berbere tomato paste and remaining spices . stir well add cup water stir . don t add too much water at this point because once the chicken has been added the amount of liquid will increase . if time allows let simmer to minutes . cook together until the shrimp just begin to pink . this can happen quickly depending on the size of your shrimp . rub chicken breasts with salt and pepper . beat in melted butter . continue to add broth occasionally and stir until rice is cooked the way you would with any risotto . time limit for the rice to cook . don t assume someone knows time limit of risotto . on the work surface open the boned lamb out to make as close to a rectangle as you can carefully trim off as much of the fat as possible and dispose of it . show video of this process . cook spinach according to the directions on package and drain . drain the artichokes and chop them . mix the artichokes and spinach with the remaining ingredients . put in greased quart dish and bake at degrees for minutes . serve with tortilla chips . also good served with sour cream and salsa on the side . the assistant should recommended more instructions in cooking . once beet water has cooled to room temperature add the vinegar honey salt pepper cinnamon and cloves . stir well . in a large bowl mix all the vegetables and the thyme sprigs together . add the olive oil and honey . salt and pepper . roast in oven at degrees for about minutes or until vegetables are tender stirring occasionally . prepare the veggie queso dip ahead of time . suggesting video serve warm with creme fraiche which balances really well with the sweetness of the tart or a good vanilla ice cream . drop from tip of a teaspoon onto well oiled cookie sheets to make inch rounds or spoon into well oiled inch molds . if syrup hardens while shaping drops heat slowly until just melted . serve with wedges of lime . coat fish thoroughly with seasonings . mix sour cream sugar and vanilla . spoon on top of cooled cheesecake and bake for another minutes . sprinkle with cinnamon optional . how much sugar needed for cream note this recipe is excellent for freezing . audio is only required . drain in paper towel . repeat with the rest of the dough . serve with crostini bread crackers or veggie sticks . this dip is to be served luke warm to room temperature . so if it sits out for a while that s ok . but if you d prefer you can serve it warm hot . best type of veggies to dip it in . disregard the directions on the box of cake mix instead beat the egg whites until stiff . combine them with the cake mix and water and beat until thoroughly blended about minutes . pour the batter into the molds fillng each one about inch . bake for about minutes or until the cake is golden brown and a toothpick stuck in the center comes out clean . combine all ingredients into a blender on high . combine dry ingredients in a mixing bowl . spray both sides of fish thoroughly with vegetable spray . redcurrant granita mango granita coffee granita mix together all ingredients and knead . place in large greased bowl let rise until double then punch down and knead slightly again . place in large bread pans greased and rise again . bake at degrees for hour . brush tops of loaves with butter when removed from oven . how long to knead to make the cream place butter and shortening in a mixing bowl and at low speed gradually beat in the sugar and vanilla . turn the mixer on high and beat for to minutes until filling is light and fluffy . if needs clarification a link to be provided so that if we ask clarify then we have a option to follow the link and learn . variation spoon dessert topping over prepared pudding fresh fruit or pound cake . after minutes increase the oven temp . to f . and continue to bake for an additional minutes . in a large dutch oven saute bacon for minutes over medium high heat . with a slotted spoon remove bacon and set aside . boil the taro for an hour or until it is what it looks like over cooked soak gelatin in cup water for minutes heat it up in a microwave for minute . let it sit for minutes the gelatin water will become completely clear . pour into pie shell . puree fruit with powdered sugar and xocai activ . mix in egg yolk and cream . blend well . chill . churn in ice cream maker . serves a demonstration video heat oil in a wok and deep fry the samosa till it becomes light brown on both the sides . suggest exact time limit . for a large loaf pan bake for minutes . cups flour teaspoons baking powder teaspoon soda teaspoon salt cup sugar cup shortning eggs beaten cup bananas mashed cup chopped walnuts optional transfer peppers to plastic wrap or bag . close the bag or seal with plastic wrap and let peppers steam and cool . pulse together flour sugar salt powder in bowl of food processor . now make the peanut dipping sauce . set the dough aside and cover it with plastic food wrap . let the dough sit for min . place baguette slices on baking sheet and bake until golden and crispy about minutes . pour chocolate peanut butter mixture over chow mein noodles and stir in marshmallows . gently combine . pour the batter mixture over chow mein noodles and stir in marshmallows . gently combine . in a bowl mix all of the chocolate cookie crust ingredients together until well combined . it helps if you mix the ingredients with your hands too . in a mini cupcake pan place the mini cupcake liners inside and press the chocolate crust on the bottom of the liners . in a bowl mix all of the chocolate cookie crust ingredients together until well combined . it helps if you mix the ingredients with your hands too . in a mini cupcake pan place the mini cupcake liners inside and press the chocolate crust on the bottom of the liners . cook frozen mixed berries and tablespoons sugar in a heavy medium saucepan over medium heat until mixture resembles jam and is reduced to cup stirring frequently about minutes . cool jam mixture . sprinkle the nonpareils on top of the chocolate . don t tap it again otherwise your sprinkles will sink down in . place into the fridge to chill . this will take about hour . show an image of this step . to assemble peel mushroom caps and break in pieces . add oyster crabs and wine cover and let stand one hour . melt butter add first mixture and cook eight minutes . add flour and cook two minutes . season with salt cayenne and nutmeg then add heavy cream . just before serving add egg yolks slightly beaten and brandy . show a website with this recipe . discard end slices of loaf . spread cup ml butter evenly over one side of each bread slice . arrange six of the bread slices buttered side up in a single layer on the bottom of prepared dish . cut a seventh slice in half and wedge in among other slices to fill the bottom of the dish sprinkle half of the apricots evenly over the top . repeat with remaining seven bread slices and apricots for a second layer set aside . remove from pans and cool on rack . stir and allow cooking until the liquid is dry . stir the food combine egg substitute buttermilk oatmeal molasses oil . mix cornstarch and flour into milk . mix well . add to cooking vegetables . toss in peas . show how to properly mix ingredients heat oil in big pot and fry onion and garlic for minute . then add the chicken and continue cooking for minutes . add all the spices . stir everything together for a few minutes . let cook until chicken is tender . add the rest of the ingredients . adjust seasoning and serve with steamed rice . how to cook the rice stir fry the chinese barbecued pork and the scallions for minute . add your spices provide alternative spices . in a pan add water and sugar and heat till boil . after few boils turn off flame add rose essences and keep aside this sugar syrup . line your pan with aluminum foil or use disposable pans add gruyere and parmesan cheeses stir until melted . season to taste with salt and pepper . use hot . if making up to day ahead let cool then cover and chill reheat in a microwave safe bowl in a microwave oven at full power for about minute . do not reboil after adding egg yolk . on each serving plate place a pear half at the o clock position fanning it across the plate . divide the prosciutto into portions and drape one portion across the middle of each serving plate covering the top half of the pear fan . garnish each plate with cup dressed greens placed in the o clock position above the prosciutto . show example preheat oven to degrees . makes quart . makes quart . in a bowl whisk the flour baking powder baking soda cinnamon and salt . place the steaks in a dish and add half of the cognac . let it soak each steaks on both sides for a minute or so . slice the chicken add and mix set aside for later use .']]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
